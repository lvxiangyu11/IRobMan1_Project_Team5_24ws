{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb0fd4c1-97e3-4984-a270-edddc5a05230",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Python Path:\n",
      "\n",
      "/opt/ros_ws/devel/lib/python3/dist-packages\n",
      "/opt/ros/noetic/lib/python3/dist-packages\n",
      "/usr/lib/python38.zip\n",
      "/usr/lib/python3.8\n",
      "/usr/lib/python3.8/lib-dynload\n",
      "/usr/local/lib/python3.8/dist-packages\n",
      "/usr/lib/python3/dist-packages\n",
      "/opt/ros_ws/src/franka_zed_gazebo/scripts/mycode/3_move\n",
      "/opt/ros_ws/src/franka_zed_gazebo/scripts/mycode/1_getPointCloud\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 获取当前工作目录（用于替代 __file__）\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "target_path1 = os.path.abspath(os.path.join(current_dir, '../3_move'))\n",
    "target_path2 = os.path.abspath(os.path.join(current_dir, '../1_getPointCloud'))\n",
    "\n",
    "# 将路径添加到 sys.path\n",
    "if target_path1 not in sys.path:\n",
    "    sys.path.append(target_path1)\n",
    "    \n",
    "if target_path2 not in sys.path:\n",
    "    sys.path.append(target_path2)\n",
    "    \n",
    "# 检查路径是否添加成功\n",
    "print(\"Current Python Path:\")\n",
    "print(\"\\n\".join(sys.path))\n",
    "\n",
    "from ImageRecognizer import ImageRecognizer\n",
    "image_recognizer = ImageRecognizer(top_dir=\"/opt/ros_ws/src/franka_zed_gazebo/scripts/mycode/2_perception/cubes/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed72673e-cc5b-4fc5-8942-e6652c917234",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "def matrix_to_rpy_and_translation(matrix):\n",
    "    \"\"\"\n",
    "    从4x4变换矩阵中提取RPY（Roll, Pitch, Yaw）和位移信息，并返回一个列表形式。\n",
    "    \n",
    "    参数:\n",
    "        matrix: 4x4变换矩阵 (numpy.ndarray)\n",
    "        \n",
    "    返回:\n",
    "        result: 一个包含 [roll, pitch, yaw, x, y, z] 的列表\n",
    "    \"\"\"\n",
    "    if matrix.shape != (4, 4):\n",
    "        raise ValueError(\"输入必须是一个 4x4 矩阵\")\n",
    "    \n",
    "    # 提取旋转矩阵和位移\n",
    "    rotation_matrix = matrix[:3, :3]\n",
    "    translation = matrix[:3, 3]\n",
    "    \n",
    "    # 创建旋转矩阵的副本，避免只读内存问题\n",
    "    rotation_matrix = np.array(rotation_matrix)\n",
    "    \n",
    "    # 使用scipy转换为RPY角\n",
    "    r = R.from_matrix(rotation_matrix)\n",
    "    roll, pitch, yaw = r.as_euler('xyz', degrees=False)\n",
    "    \n",
    "    # 返回结果\n",
    "    return [roll, pitch, yaw], translation.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c575264-32a4-4fc0-9469-5ce80c9a98fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "[INFO] [1738446030.235295, 0.000000]: Waiting for data...\n",
      "[INFO] [1738446030.299417, 1180.437000]: Received image message.\n",
      "[INFO] [1738446030.432956, 1180.523000]: Received point cloud data.\n",
      "[INFO] [1738446032.918463, 1182.918000]: Color range - Min: [0.10196078 0.10196078 0.10196078], Max: [0.75294118 0.63921569 0.60784314]\n",
      "[INFO] [1738446032.920388, 1182.920000]: Requesting transform from world to left_camera_link_optical...\n",
      "[INFO] [1738446032.922082, 1182.921000]: Transform found: header: \n",
      "  seq: 0\n",
      "  stamp: \n",
      "    secs: 1182\n",
      "    nsecs: 904000000\n",
      "  frame_id: \"world\"\n",
      "child_frame_id: \"left_camera_link_optical\"\n",
      "transform: \n",
      "  translation: \n",
      "    x: 0.2101908974433102\n",
      "    y: -0.05995218790817051\n",
      "    z: 0.5593812660809546\n",
      "  rotation: \n",
      "    x: 0.6595352526379784\n",
      "    y: 0.6596871799401207\n",
      "    z: 0.2548095667738362\n",
      "    w: 0.2547511723838362\n",
      "[INFO] [1738446033.268975, 1183.256000]: Transformed point cloud saved to /opt/ros_ws/src/franka_zed_gazebo/scripts/mycode/2_perception/mesh/zed_point_cloud_world3.ply\n",
      "[INFO] [1738446033.513191, 1183.459000]: Waiting for move_group action server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[ WARN] [1738446033.549419178]: Link zed2_holder has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [1738446034.766567, 1183.469000]: Constraints added: z > 0.01\n",
      "[INFO] [1738446034.771908, 1184.659000]: MoveRobot initialized successfully.\n",
      "[INFO] [1738446034.791416, 1184.659000]: Waiting for gripper action servers...\n",
      "[INFO] [1738446035.049771, 1184.931000]: Gripper action servers ready.\n"
     ]
    }
   ],
   "source": [
    "from save_point_cloud import PointCloudSaver\n",
    "import open3d as o3d\n",
    "import rospy\n",
    "point_cloud_saver = PointCloudSaver()\n",
    "\n",
    "# 等待数据准备\n",
    "rospy.loginfo(\"Waiting for data...\")\n",
    "rospy.sleep(1)  # 等待话题数据发布\n",
    "\n",
    "# 保存点云\n",
    "world_file = \"/opt/ros_ws/src/franka_zed_gazebo/scripts/mycode/2_perception/mesh/zed_point_cloud_world3.ply\"\n",
    "point_cloud_saver.save_point_clouds(world_file)\n",
    "\n",
    "\n",
    "from PickAndPlace import PickAndPlace\n",
    "pick_place = PickAndPlace(approach_distance=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ebdb0eb-9e99-4745-88a8-52bfcc7225d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "def filter_point_cloud_by_depth_and_range(point_cloud, depth_threshold=0.005, range=[0.001, -0.8, 1, 1.6]):\n",
    "    \"\"\"\n",
    "    读取点云文件并过滤掉深度低于指定阈值和超出检测范围的点。\n",
    "\n",
    "    Args:\n",
    "        point_cloud (o3d.geometry.PointCloud): 点云对象。\n",
    "        depth_threshold (float): 深度阈值，低于该值的点将被过滤。\n",
    "        range (list): 过滤范围，包含 [x, y, w, h]。\n",
    "        \n",
    "    Returns:\n",
    "        o3d.geometry.PointCloud: 过滤后的点云对象。\n",
    "    \"\"\"\n",
    "\n",
    "    # 获取点云的点坐标\n",
    "    points = np.asarray(point_cloud.points)\n",
    "\n",
    "    # 过滤深度小于阈值的点\n",
    "    filtered_points = points[points[:, 2] >= depth_threshold]\n",
    "\n",
    "    # 根据范围过滤点 (x, y, w, h) -> 左上角和宽高\n",
    "    x, y, w, h = range\n",
    "    filtered_points = filtered_points[\n",
    "        (filtered_points[:, 0] >= x) & (filtered_points[:, 0] <= x + w) &\n",
    "        (filtered_points[:, 1] >= y) & (filtered_points[:, 1] <= y + h)\n",
    "    ]\n",
    "\n",
    "    # 创建新的点云对象\n",
    "    filtered_point_cloud = o3d.geometry.PointCloud()\n",
    "    filtered_point_cloud.points = o3d.utility.Vector3dVector(filtered_points)\n",
    "\n",
    "    # 保留颜色信息（如果存在）\n",
    "    if point_cloud.has_colors():\n",
    "        colors = np.asarray(point_cloud.colors)\n",
    "        filtered_colors = colors[points[:, 2] >= depth_threshold]\n",
    "        filtered_point_cloud.colors = o3d.utility.Vector3dVector(filtered_colors)\n",
    "\n",
    "    return filtered_point_cloud\n",
    "\n",
    "def filter_point_cloud_by_depth(point_cloud, depth_threshold=0.005):\n",
    "    \"\"\"\n",
    "    读取点云文件并过滤掉深度低于指定阈值的点。\n",
    "\n",
    "    Args:\n",
    "        ply_path (str): 点云文件的路径。\n",
    "        depth_threshold (float): 深度阈值，低于该值的点将被过滤。\n",
    "\n",
    "    Returns:\n",
    "        o3d.geometry.PointCloud: 过滤后的点云对象。\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # 获取点云的点坐标\n",
    "    points = np.asarray(point_cloud.points)\n",
    "\n",
    "    # 过滤深度小于阈值的点\n",
    "    filtered_points = points[points[:, 2] >= depth_threshold]\n",
    "\n",
    "    # 创建新的点云对象\n",
    "    filtered_point_cloud = o3d.geometry.PointCloud()\n",
    "    filtered_point_cloud.points = o3d.utility.Vector3dVector(filtered_points)\n",
    "\n",
    "    # 保留颜色信息（如果存在）\n",
    "    if point_cloud.has_colors():\n",
    "        colors = np.asarray(point_cloud.colors)\n",
    "        filtered_colors = colors[points[:, 2] >= depth_threshold]\n",
    "        filtered_point_cloud.colors = o3d.utility.Vector3dVector(filtered_colors)\n",
    "\n",
    "    return filtered_point_cloud\n",
    "\n",
    "zed_ply_path = \"mesh/zed_point_cloud_world3.ply\"\n",
    "\n",
    "coordinate_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "    size=0.1,  # 坐标轴大小，可以根据需要调整\n",
    "    origin=[0, 0, 0]  # 坐标轴的原点\n",
    ")\n",
    "\n",
    "# 读取点云文件\n",
    "point_cloud = o3d.io.read_point_cloud(zed_ply_path)\n",
    "if not point_cloud.has_points():\n",
    "    raise ValueError(f\"Failed to read point cloud from {zed_ply_path}\")\n",
    "filtered_point_cloud = filter_point_cloud_by_depth_and_range(point_cloud, depth_threshold=0.005, range=[0.001, -0.8, 1, 1.6])\n",
    "o3d.visualization.draw_geometries([filtered_point_cloud, coordinate_frame], window_name=\"Filtered Point Cloud\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9883e9d-4bce-412e-ad0a-224f0121b514",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxLayer: 1\n"
     ]
    }
   ],
   "source": [
    "def calculate_max_layer(filtered_point_cloud, layer_height=0.04):\n",
    "    \"\"\"\n",
    "    计算点云的最高层数 (MaxLayer)，基于 z 轴最大值，使用四舍五入计算。\n",
    "\n",
    "    Args:\n",
    "        filtered_point_cloud (o3d.geometry.PointCloud): 已过滤的点云对象。\n",
    "        layer_height (float): 每一层的高度，默认值为 0.04。\n",
    "\n",
    "    Returns:\n",
    "        int: 最高层数 (MaxLayer)。\n",
    "    \"\"\"\n",
    "    # 提取点云的 z 轴最大值\n",
    "    points = np.asarray(filtered_point_cloud.points)\n",
    "    z_max = np.max(points[:, 2])\n",
    "\n",
    "    # 计算最高层数，严格四舍五入\n",
    "    max_layer = int(np.floor(z_max / layer_height + 0.5))\n",
    "\n",
    "    return max_layer\n",
    "\n",
    "# 示例调用\n",
    "max_layer = calculate_max_layer(filtered_point_cloud, layer_height=0.04)\n",
    "print(f\"MaxLayer: {max_layer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88fe104e-b675-4313-93a1-417cdc00c8cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "def register_and_filter(pointcloud, mesh, voxel_size=0.01):\n",
    "    # 转换mesh为点云\n",
    "    if isinstance(mesh, o3d.geometry.TriangleMesh):\n",
    "        mesh_pointcloud = mesh.sample_points_uniformly(number_of_points=1000)\n",
    "    elif isinstance(mesh, o3d.geometry.PointCloud):\n",
    "        mesh_pointcloud = copy.deepcopy(mesh)\n",
    "    \n",
    "    # 下采样点云并计算特征\n",
    "    def preprocess_point_cloud(pcd, voxel_size):\n",
    "        pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "        pcd_down.estimate_normals(\n",
    "            search_param=o3d.geometry.KDTreeSearchParamHybrid(\n",
    "                radius=voxel_size*2, \n",
    "                max_nn=30\n",
    "            )\n",
    "        )\n",
    "        pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "            pcd_down,\n",
    "            search_param=o3d.geometry.KDTreeSearchParamHybrid(\n",
    "                radius=voxel_size*5, \n",
    "                max_nn=100\n",
    "            )\n",
    "        )\n",
    "        return pcd_down, pcd_fpfh\n",
    "\n",
    "    # 粗配准\n",
    "    def execute_global_registration(source_down, target_down, source_fpfh, target_fpfh, voxel_size):\n",
    "        distance_threshold = voxel_size * 1.5\n",
    "        result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "            source_down, target_down, source_fpfh, target_fpfh, True,\n",
    "            distance_threshold,\n",
    "            o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "            4,\n",
    "            [\n",
    "                o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "                o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "            ],\n",
    "            o3d.pipelines.registration.RANSACConvergenceCriteria(4000000, 500)\n",
    "        )\n",
    "        return result\n",
    "\n",
    "    # 精配准\n",
    "    def refine_registration(source, target, initial_transformation, voxel_size):\n",
    "        distance_threshold = voxel_size * 1  # 减小阈值提高精度\n",
    "        result = o3d.pipelines.registration.registration_icp(\n",
    "            source, target, distance_threshold, initial_transformation,\n",
    "            o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "            o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=1000000)\n",
    "        )\n",
    "        return result\n",
    "\n",
    "    # 执行点云预处理\n",
    "    source_down, source_fpfh = preprocess_point_cloud(mesh_pointcloud, voxel_size)\n",
    "    target_down, target_fpfh = preprocess_point_cloud(pointcloud, voxel_size)\n",
    "\n",
    "    # 执行配准\n",
    "    coarse_result = execute_global_registration(source_down, target_down, source_fpfh, target_fpfh, voxel_size)\n",
    "    refined_result = refine_registration(mesh_pointcloud, pointcloud, coarse_result.transformation, voxel_size)\n",
    "\n",
    "    # 变换网格点云\n",
    "    transform = refined_result.transformation\n",
    "    transformed_mesh_pointcloud = mesh_pointcloud.transform(transform)\n",
    "\n",
    "    # 创建包围盒\n",
    "    oriented_bounding_box = transformed_mesh_pointcloud.get_oriented_bounding_box()\n",
    "    center = oriented_bounding_box.center\n",
    "    extent = oriented_bounding_box.extent\n",
    "    rotation_matrix = oriented_bounding_box.R\n",
    "\n",
    "    # 扩展包围盒\n",
    "    margin = voxel_size\n",
    "    expanded_extent = extent + 0.5 * margin\n",
    "    expanded_bounding_box = o3d.geometry.OrientedBoundingBox(\n",
    "        center=center,\n",
    "        extent=expanded_extent,\n",
    "        R=rotation_matrix\n",
    "    )\n",
    "\n",
    "    # 过滤点云\n",
    "    indices_inside_box = expanded_bounding_box.get_point_indices_within_bounding_box(pointcloud.points)\n",
    "    indices_outside_box = list(set(range(len(pointcloud.points))) - set(indices_inside_box))\n",
    "\n",
    "    # 分离点云\n",
    "    remaining_pointcloud = pointcloud.select_by_index(indices_outside_box)\n",
    "    deleted_pointcloud = pointcloud.select_by_index(indices_inside_box)\n",
    "\n",
    "    return transform, remaining_pointcloud, deleted_pointcloud, refined_result.fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97050aea-fb60-4b73-b5ee-14d1b5891787",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 读取cube\n",
    "# 定义文件路径\n",
    "cube_obj_path = \"mesh/cube_0.obj\"\n",
    "zed_ply_path = \"mesh/zed_point_cloud_world3.ply\"\n",
    "\n",
    "# 读取 cube_0.obj 点云\n",
    "cube_mesh = o3d.io.read_triangle_mesh(cube_obj_path)\n",
    "cube_mesh.compute_vertex_normals()  # 计算法线以便更好显示\n",
    "# cube_point_cloud = cube_mesh.sample_points_uniformly(number_of_points=50000)  # 转为点云\n",
    "# cube_point_cloud = cube_mesh.sample_points_poisson_disk(number_of_points=1000)\n",
    "\n",
    "# 去掉cube下半部分，防止z轴翻转\n",
    "# cube_point_cloud = filter_point_cloud_by_depth(cube_point_cloud, depth_threshold=-0.015)\n",
    "# o3d.visualization.draw_geometries([cube_point_cloud])\n",
    "\n",
    "\n",
    "coordinate_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "    size=0.1,  # 坐标轴大小，可以根据需要调整\n",
    "    origin=[0, 0, 0]  # 坐标轴的原点\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54f3fe34-f397-4e76-8452-b24a6cf4e9f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_transform_z_axis_alignment(transform, tolerance=0.1):\n",
    "    \"\"\"\n",
    "    检查 transform 的 Z 轴是否与世界坐标系的 Z 轴平行。\n",
    "    允许一定的容差范围内，判断是否平行或反向平行。\n",
    "    参数:\n",
    "    - transform: 4x4 转换矩阵\n",
    "    - tolerance: 判断的容差范围，默认 0.1\n",
    "    返回:\n",
    "    - True: 如果 Z 轴平行或反向平行\n",
    "    - False: 如果 Z 轴不平行\n",
    "    - 修正后的\n",
    "    \"\"\"\n",
    "    z_axis = np.array([0, 0, 1])  # 世界坐标系的 Z 轴\n",
    "    transform_z_axis = transform[:3, 2]  # 获取 transform 的 Z 轴（即旋转矩阵的第三列）\n",
    "\n",
    "    # 计算 transform Z 轴与世界坐标系 Z 轴的夹角\n",
    "    dot_product = np.dot(transform_z_axis, z_axis)\n",
    "    # 计算夹角的余弦值，如果接近 1 或 -1，表示平行或反向平行\n",
    "    if np.abs(dot_product) > (1 - tolerance):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def align_transform_z_axis(transform):\n",
    "    \"\"\"\n",
    "    如果 transform 的 Z 轴与世界坐标系 Z 轴反向平行，\n",
    "    则通过绕 X 轴旋转 180 度（np.pi）来翻转 Z 轴方向。\n",
    "    \n",
    "    参数:\n",
    "    - transform: 4x4 转换矩阵\n",
    "    \n",
    "    返回:\n",
    "    - 修正后的 transform 矩阵\n",
    "    \"\"\"\n",
    "    z_axis_world = np.array([0, 0, 1])  # 世界坐标系的 Z 轴\n",
    "    transform_z_axis = transform[:3, 2]  # 获取 transform 的 Z 轴（旋转矩阵的第三列）\n",
    "\n",
    "    # 判断 Z 轴是否与世界坐标系 Z 轴反向平行\n",
    "    if np.dot(transform_z_axis, z_axis_world) < 0:  # Z 轴反向\n",
    "        print(\"修正z轴\")\n",
    "        # 创建绕 X 轴旋转 180 度的旋转矩阵\n",
    "        rotation_matrix = np.eye(4)\n",
    "        rotation_matrix[1, 1] = -1  # 旋转矩阵绕 X 轴旋转 180 度\n",
    "        rotation_matrix[2, 2] = -1  # 旋转矩阵绕 X 轴旋转 180 度\n",
    "        \n",
    "        # 进行矩阵乘法，旋转矩阵应用到原始 transform 上\n",
    "        transform = np.dot(rotation_matrix, transform)\n",
    "\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcefc557-cb74-405f-bc65-51be58aebe8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "def max_downsample_image(image, pool_size=(2, 2)):\n",
    "    \"\"\"\n",
    "    使用最大值池化对图像进行降采样。\n",
    "\n",
    "    Args:\n",
    "        image (numpy.ndarray): 输入彩色图像 (height, width, 3)\n",
    "        pool_size (tuple): 池化窗口大小 (height, width)\n",
    "\n",
    "    Returns:\n",
    "        downsampled_image (numpy.ndarray): 降采样后的图像\n",
    "    \"\"\"\n",
    "    h, w, c = image.shape\n",
    "    ph, pw = pool_size\n",
    "\n",
    "    # 确保图像尺寸是池化窗口的整数倍\n",
    "    h_new = h // ph * ph\n",
    "    w_new = w // pw * pw\n",
    "    image_cropped = image[:h_new, :w_new, :]\n",
    "\n",
    "    # 使用最大池化降采样\n",
    "    downsampled_image = image_cropped.reshape(h_new // ph, ph, w_new // pw, pw, c).max(axis=(1, 3))\n",
    "\n",
    "    return downsampled_image\n",
    "\n",
    "def pointcloud_to_top_view_image_color(pointcloud, voxel_size=0.01, output_image_size=(512, 512)):\n",
    "    \"\"\"\n",
    "    从点云生成正上方的彩色 2D 图像。\n",
    "    \n",
    "    Args:\n",
    "        pointcloud (o3d.geometry.PointCloud): 输入点云\n",
    "        voxel_size (float): 分辨率，用于划分网格\n",
    "        output_image_size (tuple): 输出图像大小 (width, height)\n",
    "    \n",
    "    Returns:\n",
    "        top_view_image (numpy.ndarray): 生成的 2D 彩色图像\n",
    "    \"\"\"\n",
    "    # 获取点云的点坐标和颜色\n",
    "    points = np.asarray(pointcloud.points)\n",
    "    colors = np.asarray(pointcloud.colors) if pointcloud.has_colors() else np.zeros_like(points)\n",
    "\n",
    "    # 提取 x-y 范围\n",
    "    x_min, y_min = np.min(points[:, :2], axis=0)\n",
    "    x_max, y_max = np.max(points[:, :2], axis=0)\n",
    "    print(x_max, y_max)\n",
    "\n",
    "    # 定义网格分辨率\n",
    "    width, height = output_image_size\n",
    "    grid_x = np.linspace(x_min, x_max, width)\n",
    "    grid_y = np.linspace(y_min, y_max, height)\n",
    "\n",
    "    # 初始化 2D 彩色图像\n",
    "    top_view_image = np.zeros((height, width, 3))  # RGB 图像\n",
    "\n",
    "    # 初始化计数矩阵以累积颜色\n",
    "    count_matrix = np.zeros((height, width))\n",
    "\n",
    "    # 遍历点云，将每个点投影到网格上\n",
    "    for point, color in zip(points, colors):\n",
    "        x, y, z = point\n",
    "        # 找到对应的网格索引\n",
    "        x_idx = int((x - x_min) / (x_max - x_min) * (width - 1))\n",
    "        y_idx = int((y - y_min) / (y_max - y_min) * (height - 1))\n",
    "        \n",
    "        # 更新彩色图像和计数矩阵\n",
    "        top_view_image[height - 1 - y_idx, x_idx] += color  # 累加颜色\n",
    "        count_matrix[height - 1 - y_idx, x_idx] += 1\n",
    "\n",
    "    # 平均化颜色值\n",
    "    nonzero_mask = count_matrix > 0\n",
    "    top_view_image[nonzero_mask] /= count_matrix[nonzero_mask, None]\n",
    "\n",
    "    # 将结果归一化到 0-1 范围内\n",
    "    top_view_image = np.clip(top_view_image, 0, 1)\n",
    "\n",
    "    return top_view_image\n",
    "\n",
    "\n",
    "import scipy.ndimage\n",
    "\n",
    "def interpolate_sparse_image(image, dilation_size=(7, 7)):\n",
    "    \"\"\"\n",
    "    对稀疏的彩色图像进行插值填充。\n",
    "    \n",
    "    Args:\n",
    "        image (numpy.ndarray): 输入彩色图像 (height, width, 3)\n",
    "        dilation_size (tuple): 膨胀操作的邻域大小 (height, width)\n",
    "    \n",
    "    Returns:\n",
    "        interpolated_image (numpy.ndarray): 插值后的彩色图像\n",
    "    \"\"\"\n",
    "    interpolated_image = image.copy()\n",
    "    for i in range(3):  # 分别处理 RGB 三个通道\n",
    "        interpolated_image[:, :, i] = scipy.ndimage.morphology.grey_dilation(\n",
    "            image[:, :, i], size=dilation_size\n",
    "        )\n",
    "    return interpolated_image\n",
    "\n",
    "\n",
    "def pointcloud_to_colored_image_with_filling(pointcloud, output_size=(512, 512), voxel_size=0.01):\n",
    "    \"\"\"\n",
    "    从点云生成正上方的彩色 2D 图像，使用高斯滤波填充空白区域。\n",
    "    \n",
    "    Args:\n",
    "        pointcloud (o3d.geometry.PointCloud): 输入点云。\n",
    "        output_size (tuple): 输出图像大小 (width, height)。\n",
    "        voxel_size (float): 网格分辨率，用于划分网格。\n",
    "    \n",
    "    Returns:\n",
    "        top_view_image (numpy.ndarray): 填充后的彩色图像。\n",
    "    \"\"\"\n",
    "    # 获取点云的点坐标和颜色\n",
    "    points = np.asarray(pointcloud.points)\n",
    "    colors = np.asarray(pointcloud.colors) if pointcloud.has_colors() else np.zeros_like(points)\n",
    "\n",
    "    # 提取 x-y 范围\n",
    "    x_min, y_min = np.min(points[:, :2], axis=0)\n",
    "    x_max, y_max = np.max(points[:, :2], axis=0)\n",
    "\n",
    "    # 定义网格分辨率\n",
    "    width, height = output_size\n",
    "    grid_x = np.linspace(x_min, x_max, width)\n",
    "    grid_y = np.linspace(y_min, y_max, height)\n",
    "\n",
    "    # 初始化 2D 彩色图像和计数矩阵\n",
    "    top_view_image = np.zeros((height, width, 3), dtype=np.float32)  # RGB 图像\n",
    "    count_matrix = np.zeros((height, width), dtype=np.float32)\n",
    "\n",
    "    # 遍历点云，将每个点投影到网格上\n",
    "    for point, color in zip(points, colors):\n",
    "        x, y, z = point\n",
    "        # 找到对应的网格索引\n",
    "        x_idx = int((x - x_min) / (x_max - x_min) * (width - 1))\n",
    "        y_idx = int((y - y_min) / (y_max - y_min) * (height - 1))\n",
    "        \n",
    "        # 累积颜色值\n",
    "        top_view_image[height - 1 - y_idx, x_idx] += color  # 累加颜色\n",
    "        count_matrix[height - 1 - y_idx, x_idx] += 1\n",
    "\n",
    "    # 归一化颜色值\n",
    "    nonzero_mask = count_matrix > 0\n",
    "    top_view_image[nonzero_mask] /= count_matrix[nonzero_mask, None]\n",
    "\n",
    "    # 使用高斯滤波填充空白区域\n",
    "    for channel in range(3):  # 对 R/G/B 通道分别处理\n",
    "        top_view_image[:, :, channel] = gaussian_filter(top_view_image[:, :, channel], sigma=2)\n",
    "\n",
    "    # 将图像裁剪到 [0, 1] 范围\n",
    "    top_view_image = np.clip(top_view_image, 0, 1)\n",
    "\n",
    "    return top_view_image\n",
    "\n",
    "def triangle_mesh_to_image(mesh, image_size=(100, 100), fill_radius=1):\n",
    "    \"\"\"\n",
    "    将 TriangleMesh 的顶点投影到 2D 图像上，并通过最大池化生成较小的图像。\n",
    "    确保每个像素点有值。\n",
    "    \n",
    "    Args:\n",
    "        mesh (o3d.geometry.TriangleMesh): 输入三角网格。\n",
    "        image_size (tuple): 输出图像大小 (width, height)。\n",
    "        pool_size (tuple): 池化窗口大小 (height, width)。\n",
    "        fill_radius (int): 每个点影响的邻域半径（像素）。\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: 投影后的 2D 图像（池化后大小）。\n",
    "    \"\"\"\n",
    "    # 获取顶点和颜色\n",
    "    vertices = np.asarray(mesh.vertices)\n",
    "    colors = np.asarray(mesh.vertex_colors) if mesh.has_vertex_colors() else np.ones((len(vertices), 3))\n",
    "\n",
    "    # 提取 x-y 范围\n",
    "    x_min, y_min = vertices[:, 0].min(), vertices[:, 1].min()\n",
    "    x_max, y_max = vertices[:, 0].max(), vertices[:, 1].max()\n",
    "\n",
    "    # 初始化 2D 图像\n",
    "    width, height = image_size\n",
    "    image = np.zeros((height, width, 3), dtype=np.float32)\n",
    "    count_matrix = np.zeros((height, width), dtype=np.int32)  # 用于统计像素值累计次数\n",
    "\n",
    "    # 映射顶点到图像坐标并填充周围像素\n",
    "    for vertex, color in zip(vertices, colors):\n",
    "        x, y = vertex[0], vertex[1]\n",
    "        u = int((x - x_min) / (x_max - x_min) * (width - 1))\n",
    "        v = int((y - y_min) / (y_max - y_min) * (height - 1))\n",
    "\n",
    "        # 填充当前点和周围像素\n",
    "        for du in range(-fill_radius, fill_radius + 1):\n",
    "            for dv in range(-fill_radius, fill_radius + 1):\n",
    "                uu = min(max(u + du, 0), width - 1)\n",
    "                vv = min(max(v + dv, 0), height - 1)\n",
    "                image[vv, uu] += color\n",
    "                count_matrix[vv, uu] += 1\n",
    "\n",
    "    # 平均化每个像素的颜色值\n",
    "    mask = count_matrix > 0\n",
    "    image[mask] /= count_matrix[mask, None]\n",
    "\n",
    "    # 将图像转换为 0-255 的范围\n",
    "    image = (np.clip(image, 0, 1) * 255).astype(np.uint8)\n",
    "\n",
    "    return image\n",
    "\n",
    "def enlarge_points_as_cubes(point_cloud, cube_size=0.0001):\n",
    "    \"\"\"\n",
    "    将点云的每个点替换为一个立方体以增大显示大小。\n",
    "    \n",
    "    Args:\n",
    "        point_cloud (o3d.geometry.PointCloud): 输入点云。\n",
    "        cube_size (float): 立方体的边长。\n",
    "    \n",
    "    Returns:\n",
    "        o3d.geometry.TriangleMesh: 包含所有点的立方体的组合几何体。\n",
    "    \"\"\"\n",
    "    points = np.asarray(point_cloud.points)\n",
    "    colors = np.asarray(point_cloud.colors) if point_cloud.has_colors() else [[1, 0, 0]] * len(points)\n",
    "    mesh = o3d.geometry.TriangleMesh()\n",
    "\n",
    "    for point, color in zip(points, colors):\n",
    "        # 创建一个小立方体并移动到点的位置\n",
    "        cube = o3d.geometry.TriangleMesh.create_box(width=cube_size, height=cube_size, depth=cube_size)\n",
    "        cube.translate(point - np.array([cube_size / 2, cube_size / 2, cube_size / 2]))\n",
    "        cube.paint_uniform_color(color)\n",
    "        mesh += cube  # 将立方体添加到组合网格中\n",
    "\n",
    "    return mesh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9fcf074-462c-450a-921d-b9589f4b627f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import base64\n",
    "import json\n",
    "SYSTEM_PROMPT = \"\"\"Please act as an image recognition agent. \n",
    "You will be given a square face of a block, \n",
    "which is projected from a point cloud. \n",
    "Your task is to recognize the following:\n",
    "\n",
    "Determine if this is a block face.\n",
    "Each face contains only one letter, \n",
    "one pattern (just detect whether it's a pattern, no need to identify the exact pattern), \n",
    "or is blank (only wood texture). \n",
    "Please detect whether it is a letter, \n",
    "a pattern, or blank. \n",
    "Each of these may be rotated. \n",
    "Please analyze all possible rotations in a clockwise direction: 0°, 90°, 180°, and 270°.\n",
    "There might be a circular border around the face. \n",
    "Please detect if this border exists. \n",
    "It's confirmed that the color of the border matches the color of the letter or pattern.\n",
    "The expected output is a JSON in the following format:\n",
    "{\n",
    "    \"check\": true/false, \n",
    "    \"c\": char/\"pattern\"/\"blank\", \n",
    "    \"color\": \"green\"/\"yellow\"/\"red\"/\"blue\"/\"None\", \n",
    "    \"rotation\": 0/90/180/270, \n",
    "    \"circle\": true/false\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "api_key=\"\"\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "def encode_image(image, quality=100):\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')  # Convert to RGB\n",
    "    buffered = BytesIO()\n",
    "    image.save(buffered, format=\"JPEG\", quality=quality) \n",
    "    return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "def gpt4o_analysis(image_path, quality=50):\n",
    "    with Image.open(image_path) as img:\n",
    "        img_b64_str = encode_image(img, quality=quality)\n",
    "    img_type = \"image/jpeg\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": SYSTEM_PROMPT},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:{img_type};base64,{img_b64_str}\"},\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76d4d048-43c7-4a8a-ba1b-9c8e9fadcfa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import rospy\n",
    "import tf\n",
    "import numpy as np\n",
    "from geometry_msgs.msg import TransformStamped\n",
    "\n",
    "class TransformBroadcaster:\n",
    "    def __init__(self):\n",
    "        # 尝试初始化ROS节点，避免多次初始化\n",
    "        try:\n",
    "            rospy.init_node('tf_broadcaster_node')\n",
    "        except rospy.exceptions.ROSException:\n",
    "            pass  # 如果节点已初始化，就不做任何操作\n",
    "\n",
    "        # 创建一个TransformBroadcaster实例\n",
    "        self.br = tf.TransformBroadcaster()\n",
    "\n",
    "        # 假设T是给定的4x4变换矩阵\n",
    "        self.T = np.ones((4, 4))  # 修改为4x4矩阵\n",
    "\n",
    "        # 设置定时器，每100毫秒调用一次broadcast_transform函数\n",
    "        self.timer = rospy.Timer(rospy.Duration(0.1), self.broadcast_transform)\n",
    "\n",
    "        # 存储上次发送的时间戳\n",
    "        self.last_sent_time = None\n",
    "\n",
    "    def broadcast_transform(self, event):\n",
    "        try:\n",
    "            # 从4x4矩阵中提取旋转部分和位移部分\n",
    "            translation = self.T[0:3, 3]  # 位移部分 (x, y, z)\n",
    "            rotation_matrix = self.T[0:3, 0:3]  # 旋转矩阵部分\n",
    "\n",
    "            # 创建一个完整的4x4矩阵，包括旋转矩阵和齐次坐标\n",
    "            full_matrix = np.eye(4)\n",
    "            full_matrix[0:3, 0:3] = rotation_matrix\n",
    "            full_matrix[0:3, 3] = translation\n",
    "\n",
    "            # 创建一个Quaternion（四元数）来表示旋转\n",
    "            quaternion = tf.transformations.quaternion_from_matrix(full_matrix)\n",
    "\n",
    "            # 获取当前时间戳\n",
    "            current_time = rospy.Time.now()\n",
    "\n",
    "            # 判断上次发送的时间戳和当前时间戳是否相同\n",
    "            if self.last_sent_time is None or current_time != self.last_sent_time:\n",
    "                # 发布变换\n",
    "                self.br.sendTransform(\n",
    "                    (translation[0], translation[1], translation[2]),  # 位移部分\n",
    "                    (quaternion[0], quaternion[1], quaternion[2], quaternion[3]),  # 旋转部分（四元数）\n",
    "                    current_time,  # 使用当前时间戳\n",
    "                    \"cube\",  # 子坐标系名称\n",
    "                    \"world\"   # 父坐标系名称\n",
    "                )\n",
    "                # 更新上次发送的时间戳\n",
    "                self.last_sent_time = current_time\n",
    "        except:\n",
    "            pass\n",
    "    def update(self, T):\n",
    "        self.T = T\n",
    "        \n",
    "    def stop(self):\n",
    "        # 停止定时器\n",
    "        self.timer.shutdown()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "155cbbb8-ad8b-4146-a453-4cdaf9afbad5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import *  # 假设你的create_grasp_mesh函数在utils.py中\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "def generate_gripper_from_transform(T: np.ndarray):\n",
    "    \"\"\"\n",
    "    Generates a robotic gripper mesh from a given 4x4 transformation matrix,\n",
    "    with additional rotations around x and y axes.\n",
    "\n",
    "    Args:\n",
    "        T: 4x4 transformation matrix (numpy array).\n",
    "        \n",
    "    Returns:\n",
    "        gripper_meshes: List of meshes representing the gripper.\n",
    "    \"\"\"\n",
    "    # 提取旋转矩阵（3x3）\n",
    "    rotation_matrix = T[:3, :3]\n",
    "\n",
    "    # 提取平移向量\n",
    "    translation = T[:3, 3]\n",
    "\n",
    "    # 设置抓手的中心点位置，通常为平移向量\n",
    "    center_point = translation\n",
    "\n",
    "    # 创建绕x轴旋转 -90 度的旋转矩阵\n",
    "    R_x = np.array([\n",
    "        [1, 0, 0],\n",
    "        [0, np.cos(-np.pi/2), -np.sin(-np.pi/2)],\n",
    "        [0, np.sin(-np.pi/2), np.cos(-np.pi/2)]\n",
    "    ])\n",
    "\n",
    "    # 创建绕y轴旋转 90 度的旋转矩阵\n",
    "    R_y = np.array([\n",
    "        [np.cos(np.pi/2), 0, np.sin(np.pi/2)],\n",
    "        [0, 1, 0],\n",
    "        [-np.sin(np.pi/2), 0, np.cos(np.pi/2)]\n",
    "    ])\n",
    "    \n",
    "    R_z = np.array([\n",
    "        [0, -1, 0],\n",
    "        [1, 0, 0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    # 组合旋转矩阵，先绕 x 轴旋转，再绕 y 轴旋转\n",
    "    combined_rotation = R_z @ rotation_matrix @ R_x \n",
    "\n",
    "    # 调用 create_grasp_mesh 函数生成抓手\n",
    "    gripper_meshes = create_grasp_mesh(\n",
    "        center_point=center_point, \n",
    "        rotation_matrix=combined_rotation,\n",
    "        width=0.3\n",
    "    )\n",
    "    # 调用 create_grasp_mesh 函数生成抓手\n",
    "    gripper_meshes_rotate = create_grasp_mesh(\n",
    "        center_point=center_point, \n",
    "        rotation_matrix=rotation_matrix @ R_x,\n",
    "        width=0.3\n",
    "    )\n",
    "\n",
    "    return gripper_meshes, gripper_meshes_rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47315293-9f5e-4dd0-a1aa-9efab7885c1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 测试代码：传入一个4x4变换矩阵\n",
    "# T = np.array([\n",
    "#     [1, 0, 0, 0.1],  # 旋转矩阵和位移\n",
    "#     [0, 1, 0, 0.2],\n",
    "#     [0, 0, 1, 0.3],\n",
    "#     [0, 0, 0, 1]\n",
    "# ])\n",
    "\n",
    "# # 调用生成抓手的函数\n",
    "# gripper_meshes,_ = generate_gripper_from_transform(T)\n",
    "\n",
    "# # 可视化生成的抓手\n",
    "# o3d.visualization.draw_geometries(gripper_meshes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8067b9a2-8d15-4f9e-9842-e1d6815c3d34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_grasp_collision(\n",
    "    grasp_meshes: Sequence[o3d.geometry.TriangleMesh],\n",
    "    object_pcd: o3d.geometry.TriangleMesh,\n",
    "    num_colisions: int = 10,\n",
    "    tolerance: float = 0.00001\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Checks for collisions between a gripper grasp pose and target object\n",
    "    using point cloud sampling.\n",
    "\n",
    "    Args:\n",
    "        grasp_meshes: List of mesh geometries representing the gripper components\n",
    "        object_mesh: Triangle mesh of the target object\n",
    "        num_collisions: Threshold on how many points to check\n",
    "        tolerance: Distance threshold for considering a collision (in meters)\n",
    "\n",
    "    Returns:\n",
    "        bool: True if collision detected between gripper and object, False otherwise\n",
    "    \"\"\"\n",
    "    # Combine gripper meshes\n",
    "    combined_gripper = o3d.geometry.TriangleMesh()\n",
    "    for mesh in grasp_meshes:\n",
    "        combined_gripper += mesh  # 合并抓手的多个网格\n",
    "\n",
    "    # Sample points from both meshes\n",
    "    num_points = 5000  # 在抓手和目标物体上采样5000个点\n",
    "    #######################TODO#######################\n",
    "    # 从抓手和物体网格上均匀采样点云\n",
    "    gripper_pcd = combined_gripper.sample_points_uniformly(number_of_points=num_points)\n",
    "    gripper_points = np.asarray(gripper_pcd.points)  # 抓手点云的点坐标\n",
    "    object_points = np.asarray(object_pcd.points)  # 目标物体点云的点坐标\n",
    "    ##################################################\n",
    "    \n",
    "    # Build KDTree for object points\n",
    "    is_collision = False\n",
    "    #######################TODO#######################\n",
    "    collision_count = 0\n",
    "    # 为目标物体的点云建立KDTree\n",
    "    object_kdtree = o3d.geometry.KDTreeFlann(object_pcd)\n",
    "    for gripper_point in gripper_points:\n",
    "        # 对每个抓手点，寻找目标物体点云中距离最近的点\n",
    "        _, _, distances = object_kdtree.search_knn_vector_3d(gripper_point, 1)  # 查找最近邻点\n",
    "        \n",
    "        # 如果最近邻点的距离小于容忍度，则认为发生了碰撞\n",
    "        if distances[0] <= tolerance:\n",
    "            collision_count += 1\n",
    "            \n",
    "            # 如果已找到足够多的碰撞，提前退出\n",
    "            if collision_count >= num_colisions:\n",
    "                is_collision = True\n",
    "                break\n",
    "    #######################TODO#######################\n",
    "\n",
    "    return is_collision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348b83d4-ff09-4bbd-a7f0-b5a606c423ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "修正z轴\n",
      "0\n",
      "[[ 0.28272347  0.95274896  0.11107144  0.66224817]\n",
      " [ 0.9573439  -0.28748078  0.02911126  0.1067175 ]\n",
      " [ 0.05966662  0.09810313 -0.99338596  0.02356703]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "[0.6622481657023725, 0.10671749765282747, 0.12356702936480202] [3.0431555331870936, -0.05970208174629432, 1.2836379774283022]\n",
      "1\n",
      "[[ 0.9386297  -0.33113964  0.09654443  0.65746055]\n",
      " [-0.338963   -0.93735518  0.08043225  0.0069874 ]\n",
      " [ 0.06386212 -0.10822109 -0.9920735   0.02386614]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "[0.6574605484139476, 0.006987400331036689, 0.12386614379861192] [-3.0329365288089, -0.06390560921314759, -0.3465514847821302]\n",
      "2\n",
      "[[-0.36815655 -0.92507584  0.09324934  0.66777058]\n",
      " [-0.92303237  0.37569498  0.08285246 -0.12358298]\n",
      " [-0.11167812 -0.05556949 -0.99218951  0.02364203]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "[0.6677705814829037, -0.12358297911852398, 0.12364202765491623] [-3.0856441756738135, 0.11191157285288855, -1.9503156888391855]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[ WARN] [1738446291.202801125, 1429.155000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_leftfinger (parent panda_hand) at time 1429.155000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446291.202871053, 1429.155000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_rightfinger (parent panda_hand) at time 1429.155000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446291.202900839, 1429.155000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link1 (parent panda_link0) at time 1429.155000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446291.202929417, 1429.155000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link2 (parent panda_link1) at time 1429.155000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446291.203003883, 1429.155000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link3 (parent panda_link2) at time 1429.155000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446291.203077019, 1429.155000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link4 (parent panda_link3) at time 1429.155000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446291.203136095, 1429.155000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link5 (parent panda_link4) at time 1429.155000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446291.203193352, 1429.155000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link6 (parent panda_link5) at time 1429.155000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446291.203312946, 1429.155000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link7 (parent panda_link6) at time 1429.155000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446291.204219784, 1429.157000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_leftfinger (parent panda_hand) at time 1429.155000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446291.204281685, 1429.157000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_rightfinger (parent panda_hand) at time 1429.155000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446291.204315591, 1429.157000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link1 (parent panda_link0) at time 1429.155000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446291.204345625, 1429.157000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link2 (parent panda_link1) at time 1429.155000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446291.204374085, 1429.157000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link3 (parent panda_link2) at time 1429.155000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446291.204402842, 1429.157000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link4 (parent panda_link3) at time 1429.155000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446291.204473554, 1429.157000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link5 (parent panda_link4) at time 1429.155000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446291.204500722, 1429.157000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link6 (parent panda_link5) at time 1429.155000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446291.204525389, 1429.157000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link7 (parent panda_link6) at time 1429.155000 according to authority /robot_state_publisher\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[[-0.448777   -0.88786865  0.10143203  0.49961683]\n",
      " [-0.88652092  0.45662513  0.07466026  0.12321303]\n",
      " [-0.11260492 -0.05641581 -0.99203699  0.02350443]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "[0.4996168301389752, 0.12321303368516129, 0.12350442843596698] [-3.08478518483137, 0.11284425580257573, -2.0394096878766286]\n",
      "4\n",
      "[[-0.05307939  0.99754863  0.04559943  0.63841648]\n",
      " [ 0.99620409  0.0497424   0.07143608  0.15865927]\n",
      " [ 0.06899274  0.04921812 -0.99640232  0.02371556]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "[0.6384164815912345, 0.15865927056380613, 0.12371555583769553] [3.0922369360658863, -0.06904759326043908, 1.6240276379968328]\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[ WARN] [1738446322.661372212, 1458.753000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_leftfinger (parent panda_hand) at time 1458.753000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446322.661425357, 1458.753000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_rightfinger (parent panda_hand) at time 1458.753000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446322.661443755, 1458.753000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link1 (parent panda_link0) at time 1458.753000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446322.661460346, 1458.753000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link2 (parent panda_link1) at time 1458.753000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446322.661475981, 1458.753000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link3 (parent panda_link2) at time 1458.753000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446322.661491502, 1458.753000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link4 (parent panda_link3) at time 1458.753000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446322.661507134, 1458.753000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link5 (parent panda_link4) at time 1458.753000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446322.661522795, 1458.753000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link6 (parent panda_link5) at time 1458.753000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446322.661612273, 1458.753000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link7 (parent panda_link6) at time 1458.753000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446322.662472855, 1458.759000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_leftfinger (parent panda_hand) at time 1458.753000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446322.662505729, 1458.759000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_rightfinger (parent panda_hand) at time 1458.753000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446322.662528247, 1458.759000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link1 (parent panda_link0) at time 1458.753000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446322.662548944, 1458.759000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link2 (parent panda_link1) at time 1458.753000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446322.662568344, 1458.759000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link3 (parent panda_link2) at time 1458.753000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446322.662586632, 1458.759000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link4 (parent panda_link3) at time 1458.753000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446322.662606269, 1458.759000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link5 (parent panda_link4) at time 1458.753000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446322.662625819, 1458.759000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link6 (parent panda_link5) at time 1458.753000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446322.662830741, 1458.759000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link7 (parent panda_link6) at time 1458.753000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446327.850491655, 1463.551000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_leftfinger (parent panda_hand) at time 1463.551000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446327.850551863, 1463.551000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_rightfinger (parent panda_hand) at time 1463.551000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446327.850570702, 1463.551000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link1 (parent panda_link0) at time 1463.551000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446327.850586831, 1463.551000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link2 (parent panda_link1) at time 1463.551000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446327.850602508, 1463.551000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link3 (parent panda_link2) at time 1463.551000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446327.850618144, 1463.551000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link4 (parent panda_link3) at time 1463.551000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446327.850633665, 1463.552000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link5 (parent panda_link4) at time 1463.551000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446327.850648717, 1463.552000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link6 (parent panda_link5) at time 1463.551000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446327.850676037, 1463.553000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link7 (parent panda_link6) at time 1463.551000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446327.853845893, 1463.556000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_leftfinger (parent panda_hand) at time 1463.551000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446327.854030639, 1463.556000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_rightfinger (parent panda_hand) at time 1463.551000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446327.854140791, 1463.556000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link1 (parent panda_link0) at time 1463.551000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446327.854239416, 1463.556000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link2 (parent panda_link1) at time 1463.551000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446327.854260704, 1463.556000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link3 (parent panda_link2) at time 1463.551000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446327.854281236, 1463.556000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link4 (parent panda_link3) at time 1463.551000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446327.854301035, 1463.556000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link5 (parent panda_link4) at time 1463.551000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446327.854319954, 1463.556000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link6 (parent panda_link5) at time 1463.551000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446327.854339446, 1463.556000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link7 (parent panda_link6) at time 1463.551000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446331.511724546, 1466.859000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_leftfinger (parent panda_hand) at time 1466.854000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446331.512645032, 1466.860000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_rightfinger (parent panda_hand) at time 1466.854000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446331.512685429, 1466.860000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link1 (parent panda_link0) at time 1466.854000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446331.512703478, 1466.860000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link2 (parent panda_link1) at time 1466.854000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446331.512720371, 1466.860000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link3 (parent panda_link2) at time 1466.854000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446331.512737004, 1466.860000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link4 (parent panda_link3) at time 1466.854000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446331.512753678, 1466.860000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link5 (parent panda_link4) at time 1466.854000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446331.512769434, 1466.860000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link6 (parent panda_link5) at time 1466.854000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446331.512785376, 1466.860000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link7 (parent panda_link6) at time 1466.854000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446331.513603240, 1466.860000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_leftfinger (parent panda_hand) at time 1466.854000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446331.513648265, 1466.860000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_rightfinger (parent panda_hand) at time 1466.854000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446331.513673821, 1466.860000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link1 (parent panda_link0) at time 1466.854000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446331.513695417, 1466.860000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link2 (parent panda_link1) at time 1466.854000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446331.513715144, 1466.860000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link3 (parent panda_link2) at time 1466.854000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446331.513735680, 1466.860000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link4 (parent panda_link3) at time 1466.854000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446331.513755102, 1466.860000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link5 (parent panda_link4) at time 1466.854000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446331.513775039, 1466.860000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link6 (parent panda_link5) at time 1466.854000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446331.513795019, 1466.860000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link7 (parent panda_link6) at time 1466.854000 according to authority /robot_state_publisher\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[ WARN] [1738446353.243198455, 1486.908000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_leftfinger (parent panda_hand) at time 1486.904000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446353.243243342, 1486.908000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_rightfinger (parent panda_hand) at time 1486.904000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446353.243262532, 1486.908000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link1 (parent panda_link0) at time 1486.904000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446353.243280095, 1486.908000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link2 (parent panda_link1) at time 1486.904000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446353.243296989, 1486.908000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link3 (parent panda_link2) at time 1486.904000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446353.243314870, 1486.908000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link4 (parent panda_link3) at time 1486.904000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446353.243331291, 1486.908000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link5 (parent panda_link4) at time 1486.904000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446353.243347656, 1486.908000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link6 (parent panda_link5) at time 1486.904000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446353.243364317, 1486.908000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link7 (parent panda_link6) at time 1486.904000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446353.244845015, 1486.908000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_leftfinger (parent panda_hand) at time 1486.904000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446353.244903613, 1486.908000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_rightfinger (parent panda_hand) at time 1486.904000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446353.244999592, 1486.908000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link1 (parent panda_link0) at time 1486.904000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446353.245026858, 1486.908000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link2 (parent panda_link1) at time 1486.904000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446353.245048327, 1486.908000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link3 (parent panda_link2) at time 1486.904000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446353.245069684, 1486.908000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link4 (parent panda_link3) at time 1486.904000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446353.245095865, 1486.908000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link5 (parent panda_link4) at time 1486.904000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446353.245116080, 1486.908000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link6 (parent panda_link5) at time 1486.904000 according to authority /robot_state_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1738446353.245135971, 1486.908000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame panda_link7 (parent panda_link6) at time 1486.904000 according to authority /robot_state_publisher\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "try:\n",
    "    broadcaster\n",
    "except NameError:\n",
    "    broadcaster = TransformBroadcaster()           \n",
    "    \n",
    "    \n",
    "def pointcloud_process(point_cloud, slice_tolerance=0.005):\n",
    "    '''\n",
    "        识别点云中的cubes\n",
    "        returns:\n",
    "            [\n",
    "                json,\n",
    "                T\n",
    "            ]\n",
    "    '''\n",
    "    orignal_point_cloud = copy.deepcopy(point_cloud)\n",
    "    T = []\n",
    "    remaining_pointcloud_count = 10000\n",
    "    countdown = 50\n",
    "    # 使用 open3d 可视化点云\n",
    "    # o3d.visualization.draw_geometries([layer_point_cloud], window_name=f\"Layer {layer} (Z range: {z_min:.4f} to {z_max:.4f})\")\n",
    "    movecount = 0\n",
    "    while remaining_pointcloud_count > 50 and countdown > 0:\n",
    "        cube_point_cloud = cube_mesh.sample_points_uniformly(number_of_points=50000) \n",
    "        cube_point_cloud = filter_point_cloud_by_depth(cube_point_cloud, depth_threshold=-0.01)\n",
    "        transform, remaining_pointcloud, deleted_pointcloud, fitness = register_and_filter(point_cloud, cube_point_cloud)\n",
    "        remaining_pointcloud_count = len(remaining_pointcloud.points)\n",
    "        # return transform, remaining_pointcloud, deleted_pointcloud\n",
    "        if fitness > 0.01:\n",
    "            countdown = countdown - 1\n",
    "        # print(fitness)\n",
    "        if check_transform_z_axis_alignment(transform) and fitness>0.70 and np.array_equal(transform, align_transform_z_axis(transform)):\n",
    "        # if fitness > 0.70:\n",
    "            print(movecount)\n",
    "            \n",
    "\n",
    "            broadcaster.update(transform)\n",
    "            cube_coordinate_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "                size=0.1,  # 坐标轴大小，可以根据需要调整\n",
    "                origin=[0, 0, 0]  # 坐标轴的原点\n",
    "            )\n",
    "            theta = np.radians(45)  # 将角度转换为弧度\n",
    "            transform_matrix_x_180 = np.array([\n",
    "                [1, 0, 0, 0],\n",
    "                [0, -1, 0, 0],\n",
    "                [0, 0, -1, 0],\n",
    "                [0, 0, 0, 1]\n",
    "            ])\n",
    "            transform_matrix_z_90 = np.array([\n",
    "                [0, -1, 0, 0],\n",
    "                [1, 0, 0, 0],\n",
    "                [0, 0, 1, 0],\n",
    "                [0, 0, 0, 1]\n",
    "            ])\n",
    "            graps_transform = transform @ transform_matrix_x_180\n",
    "            graps_transform_rotate = transform @ transform_matrix_x_180 @ transform_matrix_z_90\n",
    "                        # o3d.visualization.draw_geometries([coordinate_frame, remaining_pointcloud], window_name=\"remaining_pointcloud\")\n",
    "            cube_point_cloud_transormed = copy.deepcopy(deleted_pointcloud)\n",
    "            cube_point_cloud_transormed = cube_point_cloud_transormed.transform(np.linalg.inv(graps_transform))\n",
    "            cube_point_cloud_transormed_cubes = enlarge_points_as_cubes(cube_point_cloud_transormed)\n",
    "\n",
    "            cube_top_image = triangle_mesh_to_image(cube_point_cloud_transormed_cubes, image_size=(100, 100))\n",
    "            cube_top_image = (cube_top_image / cube_top_image.max() * 255).astype(np.uint8)\n",
    "            grasp_coordinate_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "                size=0.1,  # 坐标轴大小，可以根据需要调整\n",
    "                origin=[0, 0, 0]  # 坐标轴的原点\n",
    "            )\n",
    "            grasp_mesh, gripper_meshes_rotate = generate_gripper_from_transform(graps_transform)\n",
    "            # 应用变换矩阵到坐标系\n",
    "            grasp_coordinate_frame.transform(graps_transform)\n",
    "            grasp_final_matrix = None\n",
    "            if check_grasp_collision(grasp_mesh, orignal_point_cloud):\n",
    "                # 如果碰撞\n",
    "                grasp_mesh = []\n",
    "            else:\n",
    "                grasp_final_matrix = graps_transform\n",
    "            if check_grasp_collision(gripper_meshes_rotate, orignal_point_cloud):\n",
    "                gripper_meshes_rotate = []\n",
    "            else:\n",
    "                grasp_final_matrix = graps_transform_rotate\n",
    "                \n",
    "            # o3d.visualization.draw_geometries(grasp_mesh+gripper_meshes_rotate+[grasp_coordinate_frame, deleted_pointcloud, coordinate_frame], window_name=\"deleted_pointcloud\")\n",
    "            o3d.visualization.draw_geometries(grasp_mesh+gripper_meshes_rotate+[grasp_coordinate_frame, remaining_pointcloud, coordinate_frame], window_name=\"deleted_pointcloud\")\n",
    "            # o3d.visualization.draw_geometries([grasp_coordinate_frame, remaining_pointcloud, coordinate_frame], window_name=\"remaining_pointcloud\")\n",
    "            if grasp_final_matrix is not None: # 可以移动\n",
    "                countdown = 50\n",
    "                print(grasp_final_matrix)\n",
    "                movecount += 1\n",
    "                pick_rpy, pick_pos = matrix_to_rpy_and_translation(grasp_final_matrix)\n",
    "                pick_pos_ = [a + b for a, b in zip(pick_pos, [0, 0, 0.10])]\n",
    "                pick_rpy = [a + b for a, b in zip(pick_rpy, [0, 0, 0])]\n",
    "                # pick_place.move(pick_pos_, pick_rpy)\n",
    "                print(pick_pos_, pick_rpy)\n",
    "                # cube_top_image = point_cloud_to_image(cube_point_cloud_transormed)\n",
    "                plt.imsave(f\"test_{movecount}.png\", cube_top_image)\n",
    "                plt.show()\n",
    "                point_cloud = remaining_pointcloud\n",
    "                # TODO: 识别第一个面\n",
    "            \n",
    "                T.append(grasp_final_matrix)\n",
    "        else:\n",
    "            cube_point_cloud = cube_mesh.sample_points_uniformly(number_of_points=50000)\n",
    "            cube_point_cloud = filter_point_cloud_by_depth(cube_point_cloud, depth_threshold=-0.01)\n",
    "    print(T)\n",
    "    return T\n",
    "            \n",
    "Ts = pointcloud_process(filtered_point_cloud)\n",
    "broadcaster.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a266f54-a76e-4263-8be7-958b208f8df2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ts.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0ff91c9-6108-48f9-8132-1d623b646c89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import copy\n",
    "\n",
    "def generate_pascal_triangle_transforms(t, T):\n",
    "    \"\"\"\n",
    "    生成杨辉三角形的变换矩阵列表\n",
    "    每个cube的中心位置作为Transform矩阵的平移部分\n",
    "    \"\"\"\n",
    "    level = 1\n",
    "    total = 1\n",
    "    while total < t:\n",
    "        level += 1\n",
    "        total += level\n",
    "\n",
    "    transforms = []\n",
    "    cube_size = 0.045  # 4.5厘米\n",
    "    spacing_xy = cube_size * 1.3  # 增大间距为cube尺寸的2倍\n",
    "    spacing_z = cube_size * 1.3   # 垂直方向也使用相同的间距\n",
    "\n",
    "    current_pos = 0\n",
    "    for row in range(level-1, -1, -1):\n",
    "        for col in range(row + 1):\n",
    "            if current_pos >= t:\n",
    "                break\n",
    "\n",
    "            center_x = 0\n",
    "            center_y = (col - row/2) * spacing_xy\n",
    "            center_z = (level - 1 - row) * spacing_z\n",
    "\n",
    "            # 创建局部变换矩阵\n",
    "            local_transform = np.eye(4)\n",
    "            local_transform[:3, 3] = [center_x, center_y, center_z]\n",
    "\n",
    "            # 将局部变换与T变换组合\n",
    "            transform = np.dot(T, local_transform)\n",
    "            transforms.append(transform)\n",
    "            current_pos += 1\n",
    "\n",
    "        if current_pos >= t:\n",
    "            break\n",
    "\n",
    "    return transforms\n",
    "\n",
    "def create_coordinate_frame(size=0.1, transform=None):\n",
    "    frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=size)\n",
    "    if transform is not None:\n",
    "        frame.transform(transform)\n",
    "    return frame\n",
    "\n",
    "def visualize_pascal_triangle(transforms, T):\n",
    "    # 创建以原点为中心的cube\n",
    "    cube = o3d.geometry.TriangleMesh.create_box(\n",
    "        width=0.045,\n",
    "        height=0.045, \n",
    "        depth=0.045\n",
    "    )\n",
    "    # 将cube移动到以原点为中心\n",
    "    cube.translate([-0.045/2, -0.045/2, -0.045/2])\n",
    "    cube.compute_vertex_normals()\n",
    "\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.create_window()\n",
    "\n",
    "    # 添加世界坐标系\n",
    "    world_frame = create_coordinate_frame(size=0.2)\n",
    "    vis.add_geometry(world_frame)\n",
    "\n",
    "    # 添加T坐标系\n",
    "    t_frame = create_coordinate_frame(size=0.2, transform=T)\n",
    "    vis.add_geometry(t_frame)\n",
    "\n",
    "    # 添加所有的cubes和它们的局部坐标系\n",
    "    for transform in transforms:\n",
    "        # 添加cube\n",
    "        cube_copy = copy.deepcopy(cube)\n",
    "        cube_copy.transform(transform)\n",
    "        vis.add_geometry(cube_copy)\n",
    "        \n",
    "        # 添加局部坐标系\n",
    "        local_frame = create_coordinate_frame(size=0.05, transform=transform)\n",
    "        vis.add_geometry(local_frame)\n",
    "\n",
    "    opt = vis.get_render_option()\n",
    "    opt.background_color = np.asarray([0.5, 0.5, 0.5])\n",
    "\n",
    "    ctr = vis.get_view_control()\n",
    "    ctr.set_zoom(0.2)  # 调整缩放以适应更大的间距\n",
    "    ctr.set_front([-0.8, -0.5, 0.5])\n",
    "    ctr.set_lookat([0, 0, 0])\n",
    "    ctr.set_up([0, 0, 1])\n",
    "\n",
    "    vis.run()\n",
    "    vis.destroy_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67d90518-6b07-4d34-9b10-13a9a97c7c26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t = Ts.__len__()\n",
    "# 创建T矩阵（示例：绕Z轴旋转45度并平移）\n",
    "T = np.eye(4)\n",
    "theta = 0\n",
    "T[:3, :3] = np.array([\n",
    "    [np.cos(theta), -np.sin(theta), 0],\n",
    "    [np.sin(theta), np.cos(theta), 0],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "T[:3, 3] = [0.3, 0.00, 0]\n",
    "\n",
    "aim_transforms = generate_pascal_triangle_transforms(t, T)\n",
    "visualize_pascal_triangle(aim_transforms, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed7bf932-3c72-44a4-90b3-559ba899174c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.     ,  0.     ,  0.     ,  0.3    ],\n",
       "        [ 0.     ,  1.     ,  0.     , -0.08775],\n",
       "        [ 0.     ,  0.     ,  1.     ,  0.     ],\n",
       "        [ 0.     ,  0.     ,  0.     ,  1.     ]]),\n",
       " array([[ 1.     ,  0.     ,  0.     ,  0.3    ],\n",
       "        [ 0.     ,  1.     ,  0.     , -0.02925],\n",
       "        [ 0.     ,  0.     ,  1.     ,  0.     ],\n",
       "        [ 0.     ,  0.     ,  0.     ,  1.     ]]),\n",
       " array([[1.     , 0.     , 0.     , 0.3    ],\n",
       "        [0.     , 1.     , 0.     , 0.02925],\n",
       "        [0.     , 0.     , 1.     , 0.     ],\n",
       "        [0.     , 0.     , 0.     , 1.     ]]),\n",
       " array([[1.     , 0.     , 0.     , 0.3    ],\n",
       "        [0.     , 1.     , 0.     , 0.08775],\n",
       "        [0.     , 0.     , 1.     , 0.     ],\n",
       "        [0.     , 0.     , 0.     , 1.     ]]),\n",
       " array([[ 1.    ,  0.    ,  0.    ,  0.3   ],\n",
       "        [ 0.    ,  1.    ,  0.    , -0.0585],\n",
       "        [ 0.    ,  0.    ,  1.    ,  0.0585],\n",
       "        [ 0.    ,  0.    ,  0.    ,  1.    ]]),\n",
       " array([[1.    , 0.    , 0.    , 0.3   ],\n",
       "        [0.    , 1.    , 0.    , 0.    ],\n",
       "        [0.    , 0.    , 1.    , 0.0585],\n",
       "        [0.    , 0.    , 0.    , 1.    ]]),\n",
       " array([[1.    , 0.    , 0.    , 0.3   ],\n",
       "        [0.    , 1.    , 0.    , 0.0585],\n",
       "        [0.    , 0.    , 1.    , 0.0585],\n",
       "        [0.    , 0.    , 0.    , 1.    ]])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aim_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcf7d104-3c62-454c-8cdc-25427abc1061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.02356293, -0.99765066,  0.06432689,  0.47735672],\n",
       "        [-0.99274428,  0.03093919,  0.11619619,  0.21245784],\n",
       "        [-0.11791343, -0.06112223, -0.99114101,  0.02388084],\n",
       "        [ 0.        ,  0.        ,  0.        ,  1.        ]]),\n",
       " array([[ 0.99447172, -0.08130697,  0.06644673,  0.66230582],\n",
       "        [-0.08530394, -0.99456438,  0.05970699, -0.06282686],\n",
       "        [ 0.06123096, -0.06504508, -0.99600196,  0.02387568],\n",
       "        [ 0.        ,  0.        ,  0.        ,  1.        ]]),\n",
       " None,\n",
       " None,\n",
       " array([[ 0.68728117, -0.72603016,  0.02290867,  0.58679754],\n",
       "        [-0.72621931, -0.68608984,  0.04343101, -0.05999204],\n",
       "        [-0.01581482, -0.04648603, -0.99879374,  0.0234341 ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  1.        ]]),\n",
       " array([[ 0.89476662,  0.44179445, -0.06488731,  0.42350064],\n",
       "        [ 0.43539054, -0.89543784, -0.09287707, -0.17528289],\n",
       "        [-0.09913512,  0.05485198, -0.99356101,  0.02363525],\n",
       "        [ 0.        ,  0.        ,  0.        ,  1.        ]]),\n",
       " array([[ 0.95711764,  0.26600864,  0.11473982,  0.53096324],\n",
       "        [ 0.27060217, -0.96233402, -0.02622408, -0.16029772],\n",
       "        [ 0.1034422 ,  0.05614837, -0.99304938,  0.02358536],\n",
       "        [ 0.        ,  0.        ,  0.        ,  1.        ]])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8276ec04-7fa0-42e1-ae1c-32d03f30fbd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [1738445264.324909, 443.964000]: Constraints added: z > 0.01\n",
      "[INFO] [1738445272.458261, 451.303000]: Move successful to position: [0.41751312482108505, -0.10281985287884411, 0.1538095059150344] and RPY: [-3.084823854135849, 0.0779248664214982, -1.9425954541971386]\n",
      "[INFO] [1738445272.460598, 451.305000]: Path constraints cleared.\n",
      "[INFO] [1738445272.463523, 451.307000]: Constraints added: z > 0.01\n",
      "[INFO] [1738445277.704084, 456.000000]: Move successful to position: [0.6262249892502877, 0.05828912622826529, 0.15390757595687973] and RPY: [-3.0859377581362177, -0.1044128801822406, -0.9361854402889149]\n",
      "[INFO] [1738445277.705751, 456.002000]: Path constraints cleared.\n",
      "[INFO] [1738445277.707323, 456.004000]: Constraints added: z > 0.01\n",
      "[INFO] [1738445288.347846, 466.466000]: Move successful to position: [0.5072222527549072, 0.0822752672671685, 0.1538526837511258] and RPY: [3.020229784583657, -0.08142750582347369, 1.4727985707947566]\n",
      "[INFO] [1738445288.349183, 466.467000]: Path constraints cleared.\n",
      "[INFO] [1738445288.350303, 466.468000]: Constraints added: z > 0.01\n",
      "[INFO] [1738445297.085944, 474.998000]: Move successful to position: [0.5981306108622482, 0.1998056337336869, 0.15394051530729763] and RPY: [-3.0826866745393207, 0.11024283345341845, -2.343274653937249]\n",
      "[INFO] [1738445297.087265, 475.000000]: Path constraints cleared.\n",
      "[INFO] [1738445297.088294, 475.001000]: Constraints added: z > 0.01\n",
      "[INFO] [1738445301.297623, 479.132000]: Move successful to position: [0.628887173024223, -0.22110862661016456, 0.15356406608272644] and RPY: [3.0862031328288038, 0.10630545455090679, 2.4136750412883057]\n",
      "[INFO] [1738445301.299009, 479.134000]: Path constraints cleared.\n",
      "[INFO] [1738445301.300159, 479.135000]: Constraints added: z > 0.01\n",
      "[INFO] [1738445319.573946, 497.059000]: Path constraints cleared.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m pick_pos_ \u001b[38;5;241m=\u001b[39m [a \u001b[38;5;241m+\u001b[39m b \u001b[38;5;28;01mfor\u001b[39;00m a, b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(pick_pos, [\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0.13\u001b[39m])]\n\u001b[1;32m      4\u001b[0m pick_rpy \u001b[38;5;241m=\u001b[39m [a \u001b[38;5;241m+\u001b[39m b \u001b[38;5;28;01mfor\u001b[39;00m a, b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(pick_rpy, [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m])]\n\u001b[0;32m----> 5\u001b[0m \u001b[43mpick_place\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpick_pos_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpick_rpy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/ros_ws/src/franka_zed_gazebo/scripts/mycode/3_move/PickAndPlace.py:66\u001b[0m, in \u001b[0;36mPickAndPlace.move\u001b[0;34m(self, position, rpy)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmove\u001b[39m(\u001b[38;5;28mself\u001b[39m, position, rpy):\n\u001b[1;32m     65\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"根据目标位置和姿态移动机器人\"\"\"\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrobot_mover\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrpy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/ros_ws/src/franka_zed_gazebo/scripts/mycode/3_move/mymove.py:136\u001b[0m, in \u001b[0;36mMoveRobot.move\u001b[0;34m(self, position, rpy)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmove_group\u001b[38;5;241m.\u001b[39mset_max_acceleration_scaling_factor(\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmove_group\u001b[38;5;241m.\u001b[39mset_pose_target(pose_goal)\n\u001b[0;32m--> 136\u001b[0m success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove_group\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m success:\n\u001b[1;32m    139\u001b[0m     rospy\u001b[38;5;241m.\u001b[39mlogerr(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMove planning or execution failed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/ros/noetic/lib/python3/dist-packages/moveit_commander/move_group.py:615\u001b[0m, in \u001b[0;36mMoveGroupCommander.go\u001b[0;34m(self, joints, wait)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_joint_value_target(joints)\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m--> 615\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_g\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_g\u001b[38;5;241m.\u001b[39masync_move()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for T in Ts:\n",
    "    pick_rpy, pick_pos = matrix_to_rpy_and_translation(T)\n",
    "    pick_pos_ = [a + b for a, b in zip(pick_pos, [0.0, 0, 0.13])]\n",
    "    pick_rpy = [a + b for a, b in zip(pick_rpy, [0, 0, 0])]\n",
    "    pick_place.move(pick_pos_, pick_rpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1ff911-c41c-4330-be82-95130ec626fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for T in aim_transforms:\n",
    "    transform_matrix_x_180 = np.array([\n",
    "        [1, 0, 0, 0],\n",
    "        [0, -1, 0, 0],\n",
    "        [0, 0, -1, 0],\n",
    "        [0, 0, 0, 1]\n",
    "    ])\n",
    "    transform_matrix_z_90 = np.array([\n",
    "        [0, -1, 0, 0],\n",
    "        [1, 0, 0, 0],\n",
    "        [0, 0, 1, 0],\n",
    "        [0, 0, 0, 1]\n",
    "    ])\n",
    "    pick_rpy, pick_pos = matrix_to_rpy_and_translation(T@transform_matrix_x_180@transform_matrix_z_90)\n",
    "    pick_pos_ = [a + b for a, b in zip(pick_pos, [0.0, 0, 0.13])]\n",
    "    pick_rpy = [a + b for a, b in zip(pick_rpy, [0, 0, 0])]\n",
    "    pick_place.move(pick_pos_, pick_rpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da6b4027-9a96-484e-b6b0-c423c42cd075",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [1738445893.567840, 1046.643000]: Sending open goal: width: 0.08\n",
      "speed: 0.1\n",
      "[INFO] [1738445893.662070, 1046.756000]: Gripper opened successfully.\n",
      "[INFO] [1738445894.664125, 1047.711000]: Constraints added: z > 0.01\n",
      "[INFO] [1738445903.145364, 1056.017000]: Move successful to position: [0.4773567162398947, 0.21245783830850953, 0.3248808372980487] and RPY: [-3.0800021024885065, 0.11818838663218356, -1.5945270186832077]\n",
      "[INFO] [1738445903.146765, 1056.018000]: Path constraints cleared.\n",
      "[INFO] [1738445903.348535, 1056.180000]: Constraints added: z > 0.01\n",
      "[INFO] [1738445908.597959, 1061.341000]: Move successful to position: [0.4773567162398947, 0.21245783830850953, 0.02488083729804868] and RPY: [-3.0800021024885065, 0.11818838663218356, -1.5945270186832077]\n",
      "[INFO] [1738445908.599236, 1061.342000]: Path constraints cleared.\n",
      "[INFO] [1738445908.900398, 1061.612000]: Sending grasp goal: width: 0.05\n",
      "epsilon: \n",
      "  inner: 0.02\n",
      "  outer: 0.02\n",
      "speed: 0.1\n",
      "force: 50.0\n",
      "[INFO] [1738445909.482916, 1062.195000]: Grasp successful.\n",
      "[INFO] [1738445909.784638, 1062.477000]: Planning Cartesian path...\n",
      "[INFO] [1738445909.792478, 1062.517000]: Path planning completed successfully!\n",
      "[INFO] [1738445909.793685, 1062.519000]: Executing Cartesian path...\n",
      "[INFO] [1738445911.704818, 1064.406000]: Grasp approach executed successfully.\n",
      "[INFO] [1738445911.906999, 1064.604000]: Constraints added: z > 0.01\n",
      "[INFO] [1738445916.879692, 1069.445000]: Move successful to position: [0.3, -0.08775, 0.32999999999999996] and RPY: [3.141592653589793, 0.0, -1.5707963267948966]\n",
      "[INFO] [1738445916.880817, 1069.447000]: Path constraints cleared.\n",
      "[INFO] [1738445917.382177, 1069.909000]: Planning Cartesian path...\n",
      "[INFO] [1738445917.389485, 1069.909000]: Path planning completed successfully!\n",
      "[INFO] [1738445917.391504, 1069.947000]: Executing Cartesian path...\n",
      "[INFO] [1738445919.420379, 1071.939000]: Grasp approach executed successfully.\n",
      "[INFO] [1738445919.925616, 1072.426000]: Sending open goal: width: 0.07\n",
      "speed: 0.1\n",
      "[INFO] [1738445920.275260, 1072.790000]: Gripper opened successfully.\n",
      "[INFO] [1738445920.778605, 1073.284000]: Planning Cartesian path...\n",
      "[INFO] [1738445920.785498, 1073.291000]: Path planning completed successfully!\n",
      "[INFO] [1738445920.786701, 1073.291000]: Executing Cartesian path...\n",
      "[INFO] [1738445923.037778, 1075.501000]: Grasp approach executed successfully.\n"
     ]
    }
   ],
   "source": [
    "transform_matrix_x_180 = np.array([\n",
    "    [1, 0, 0, 0],\n",
    "    [0, -1, 0, 0],\n",
    "    [0, 0, -1, 0],\n",
    "    [0, 0, 0, 1]\n",
    "])\n",
    "transform_matrix_z_90 = np.array([\n",
    "    [0, -1, 0, 0],\n",
    "    [1, 0, 0, 0],\n",
    "    [0, 0, 1, 0],\n",
    "    [0, 0, 0, 1]\n",
    "])\n",
    "\n",
    "pick_rpy, pick_pos = matrix_to_rpy_and_translation(Ts[0])\n",
    "pick_pos_ = [a + b for a, b in zip(pick_pos, [0.0, 0, 0.001])]\n",
    "pick_rpy = [a + b for a, b in zip(pick_rpy, [0, 0, 0])]\n",
    "    \n",
    "place_rpy, place_pos = matrix_to_rpy_and_translation(aim_transforms[0]@transform_matrix_x_180@transform_matrix_z_90)\n",
    "place_pos_ = [a + b for a, b in zip(place_pos, [0.0, 0, 0.03])]\n",
    "\n",
    "pick_place.pick_and_place(\n",
    "    pick_pos=pick_pos_,\n",
    "    pick_rpy=pick_rpy,\n",
    "    place_pos=place_pos_,\n",
    "    place_rpy=place_rpy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a662392-36bb-46d1-a2b3-ac8562db28ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [1738445929.144609, 1081.510000]: Sending open goal: width: 0.08\n",
      "speed: 0.1\n",
      "[INFO] [1738445929.315264, 1081.699000]: Gripper opened successfully.\n",
      "[INFO] [1738445930.317991, 1082.684000]: Constraints added: z > 0.01\n",
      "[INFO] [1738445937.411010, 1089.630000]: Move successful to position: [0.6623058224445575, -0.06282686359785475, 0.323875682769187] and RPY: [-3.076379084125696, -0.061269282088262766, -0.08556868613912767]\n",
      "[INFO] [1738445937.413916, 1089.644000]: Path constraints cleared.\n",
      "[INFO] [1738445937.614905, 1089.844000]: Constraints added: z > 0.01\n",
      "[INFO] [1738445941.675301, 1093.798000]: Move successful to position: [0.6623058224445575, -0.06282686359785475, 0.023875682769186984] and RPY: [-3.076379084125696, -0.061269282088262766, -0.08556868613912767]\n",
      "[INFO] [1738445941.676888, 1093.799000]: Path constraints cleared.\n",
      "[INFO] [1738445941.978435, 1094.087000]: Sending grasp goal: width: 0.05\n",
      "epsilon: \n",
      "  inner: 0.02\n",
      "  outer: 0.02\n",
      "speed: 0.1\n",
      "force: 50.0\n",
      "[INFO] [1738445942.509512, 1094.622000]: Grasp successful.\n",
      "[INFO] [1738445942.811132, 1094.889000]: Planning Cartesian path...\n",
      "[INFO] [1738445942.817079, 1094.889000]: Path planning completed successfully!\n",
      "[INFO] [1738445942.818707, 1094.926000]: Executing Cartesian path...\n",
      "[INFO] [1738445944.152564, 1096.228000]: Grasp approach executed successfully.\n",
      "[INFO] [1738445944.355448, 1096.440000]: Constraints added: z > 0.01\n",
      "[INFO] [1738445952.134141, 1104.072000]: Move successful to position: [0.3, -0.029249999999999998, 0.32999999999999996] and RPY: [3.141592653589793, 0.0, -1.5707963267948966]\n",
      "[INFO] [1738445952.135616, 1104.075000]: Path constraints cleared.\n",
      "[INFO] [1738445952.637291, 1104.570000]: Planning Cartesian path...\n",
      "[INFO] [1738445952.643172, 1104.575000]: Path planning completed successfully!\n",
      "[INFO] [1738445952.644163, 1104.577000]: Executing Cartesian path...\n",
      "[INFO] [1738445954.429619, 1106.339000]: Grasp approach executed successfully.\n",
      "[INFO] [1738445954.931605, 1106.822000]: Sending open goal: width: 0.07\n",
      "speed: 0.1\n",
      "[INFO] [1738445955.294634, 1107.191000]: Gripper opened successfully.\n",
      "[INFO] [1738445955.797026, 1107.689000]: Planning Cartesian path...\n",
      "[INFO] [1738445955.804647, 1107.690000]: Path planning completed successfully!\n",
      "[INFO] [1738445955.805753, 1107.690000]: Executing Cartesian path...\n",
      "[INFO] [1738445957.857713, 1109.707000]: Grasp approach executed successfully.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 15\u001b[0m\n\u001b[1;32m      2\u001b[0m ptransform_matrix_x_180 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\n\u001b[1;32m      3\u001b[0m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m      4\u001b[0m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m      5\u001b[0m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m      6\u001b[0m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      7\u001b[0m ])\n\u001b[1;32m      8\u001b[0m transform_matrix_z_90 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\n\u001b[1;32m      9\u001b[0m     [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     10\u001b[0m     [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     11\u001b[0m     [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     12\u001b[0m     [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     13\u001b[0m ])\n\u001b[0;32m---> 15\u001b[0m pick_rpy, pick_pos \u001b[38;5;241m=\u001b[39m \u001b[43mmatrix_to_rpy_and_translation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m pick_pos_ \u001b[38;5;241m=\u001b[39m [a \u001b[38;5;241m+\u001b[39m b \u001b[38;5;28;01mfor\u001b[39;00m a, b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(pick_pos, [\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m])]\n\u001b[1;32m     17\u001b[0m pick_rpy \u001b[38;5;241m=\u001b[39m [a \u001b[38;5;241m+\u001b[39m b \u001b[38;5;28;01mfor\u001b[39;00m a, b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(pick_rpy, [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m])]\n",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m, in \u001b[0;36mmatrix_to_rpy_and_translation\u001b[0;34m(matrix)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmatrix_to_rpy_and_translation\u001b[39m(matrix):\n\u001b[1;32m      5\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m    从4x4变换矩阵中提取RPY（Roll, Pitch, Yaw）和位移信息，并返回一个列表形式。\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m        result: 一个包含 [roll, pitch, yaw, x, y, z] 的列表\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mmatrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m4\u001b[39m):\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m输入必须是一个 4x4 矩阵\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# 提取旋转矩阵和位移\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    ptransform_matrix_x_180 = np.array([\n",
    "    [1, 0, 0, 0],\n",
    "    [0, -1, 0, 0],\n",
    "    [0, 0, -1, 0],\n",
    "    [0, 0, 0, 1]\n",
    "    ])\n",
    "    transform_matrix_z_90 = np.array([\n",
    "        [0, -1, 0, 0],\n",
    "        [1, 0, 0, 0],\n",
    "        [0, 0, 1, 0],\n",
    "        [0, 0, 0, 1]\n",
    "    ])\n",
    "\n",
    "    pick_rpy, pick_pos = matrix_to_rpy_and_translation(Ts[i])\n",
    "    pick_pos_ = [a + b for a, b in zip(pick_pos, [0.0, 0, 0.0])]\n",
    "    pick_rpy = [a + b for a, b in zip(pick_rpy, [0, 0, 0])]\n",
    "\n",
    "    place_rpy, place_pos = matrix_to_rpy_and_translation(aim_transforms[i]@transform_matrix_x_180@transform_matrix_z_90)\n",
    "    place_pos_ = [a + b for a, b in zip(place_pos, [0.0, 0, 0.03])]\n",
    "\n",
    "    pick_place.pick_and_place(\n",
    "        pick_pos=pick_pos_,\n",
    "        pick_rpy=pick_rpy,\n",
    "        place_pos=place_pos_,\n",
    "        place_rpy=place_rpy\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae12895-f189-48d9-98a8-7f5b4ce8f8dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28a61a9-5a2d-46d9-85f8-6e0d2d2e66e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb28b7de-2a7b-447b-b92c-f9487c4a8977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344eea87-4f39-40cd-adcb-2d3490950865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb0f4e0-2497-4dfc-b1a0-816609f38564",
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_place.pick_and_place(\n",
    "    pick_pos=pick_pos_,\n",
    "    pick_rpy=pick_rpy,\n",
    "    place_pos=place_pos,\n",
    "    place_rpy=place_rpy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b49a45-b76a-4109-a1b9-92473eb0cc5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90752b1-45fd-40c6-95e6-5c641111580b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e628f0-7d4c-4612-8453-cc769bb96ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0b93ec-fc14-4c5b-a51b-ddd187495ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cf24a9-2107-4c18-8b75-410152602d54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97c4cfa-2497-47fb-abcc-b4d8102d5a27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91fbf85f-e79f-4861-b31c-77b8ff6b48d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layer 0 (Z range: 0.0050 to 0.0470)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6568554396423248\n",
      "move  1  cube\n",
      "[[-0.82532072 -0.5291985   0.19696358  0.56893383]\n",
      " [ 0.54097936 -0.84100484  0.00722457 -0.03136308]\n",
      " [ 0.16182409  0.11251582  0.98038419  0.02395822]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "move_to [0.5689338307802249, -0.03136307750997802, 0.12395821807537309] [-3.027325521527317, -0.16253882482928028, 2.5613762806369786]\n",
      "0.8390461997019374\n",
      "move  2  cube\n",
      "[[ 0.06259848 -0.99209167 -0.10879135  0.45976295]\n",
      " [ 0.99646799  0.06824087 -0.04893604  0.0824304 ]\n",
      " [ 0.05597305 -0.10534377  0.99285936  0.02386023]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "move_to [0.45976294713341037, 0.08243039788916531, 0.12386022799508747] [3.0358867255183286, -0.056002320953226326, 1.5080584053879056]\n",
      "0.7081159960258321\n",
      "move  3  cube\n",
      "[[-0.48858119  0.07856064  0.86897448  0.31169561]\n",
      " [ 0.87121089 -0.01057833  0.49079495 -0.14818237]\n",
      " [ 0.04774947  0.99685321 -0.06327451  0.02577682]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "move_to [0.31169561373288673, -0.14818236614166583, 0.12577681878391994] [-1.5074071192414733, -0.04776762920723199, 2.0818987972479417]\n",
      "0.0\n",
      "0.851356799503799\n",
      "move  4  cube\n",
      "[[ 0.07212782  0.02087549 -0.99717691  0.5951346 ]\n",
      " [ 0.03152921  0.99923356  0.02319912 -0.27131852]\n",
      " [ 0.99689693 -0.0331135   0.07141435  0.02486218]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "move_to [0.5951346028937979, -0.2713185230286453, 0.12486217724260637] [2.7074197422617856, -1.4919968623840272, 0.4120995668221619]\n",
      "0.7045743526128082\n",
      "move  5  cube\n",
      "[[ 0.87096352 -0.49088136  0.02140196  0.45178266]\n",
      " [-0.49122069 -0.87090227  0.01521406 -0.16509991]\n",
      " [ 0.01117072 -0.02376398 -0.99965518  0.0418175 ]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "move_to [0.4517826578276561, -0.16509990668845834, 0.14181750008816782] [0.023767700164496818, -0.011170952259720757, -0.5135258121540024]\n",
      "0.8276321910373702\n",
      "move  6  cube\n",
      "[[ 0.04307026  0.59629008 -0.80161281  0.47368501]\n",
      " [-0.05196555  0.80260834  0.59423853 -0.25292227]\n",
      " [ 0.99771967  0.01606224  0.06555509  0.02592202]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "move_to [0.4736850136331662, -0.2529222700231813, 0.1259220175580822] [-2.901307467096101, -1.5032507839156157, -0.8787255998111483]\n",
      "0.6904016126531245\n",
      "move  7  cube\n",
      "[[-0.03447521 -0.99887297  0.03262273  0.48596515]\n",
      " [-0.99893002  0.03544729  0.02970375 -0.10916899]\n",
      " [-0.03082666 -0.03156379 -0.99902625  0.04227949]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "move_to [0.48596514868644547, -0.10916898606659527, 0.14227948552437925] [0.03158404431845031, 0.03083154601246796, -1.6052947676687943]\n",
      "0.7089781361451388\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 143\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone!\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# T, remaining_pointcloud, deleted_pointcloud = pointcloud_splite_by_layers(filtered_point_cloud, max_layer)\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# cube_top_image, image_recognizer_result = pointcloud_splite_by_layers(filtered_point_cloud, max_layer)\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# cube_point_cloud_transormed = pointcloud_splite_by_layers(filtered_point_cloud, max_layer)\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m \u001b[43mpointcloud_splite_by_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered_point_cloud\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_layer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 59\u001b[0m, in \u001b[0;36mpointcloud_splite_by_layers\u001b[0;34m(point_cloud, max_layer, layer_thickness, slice_tolerance)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# if check_transform_z_axis_alignment(transform) and fitness>0.60 and  np.array_equal(transform, align_transform_z_axis(transform)):\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fitness\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0.60\u001b[39m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[43mo3d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisualization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_geometries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcoordinate_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining_pointcloud\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mremaining_pointcloud\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmove \u001b[39m\u001b[38;5;124m\"\u001b[39m, movecount\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m cube\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# 1. 矫正翻转的z轴\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# 2. 识别识别出的cube的top面是什么\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "# 设置日志级别为 WARNING，这样 INFO 级别的日志就不会显示\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "try:\n",
    "    broadcaster\n",
    "except NameError:\n",
    "    broadcaster = TransformBroadcaster()           \n",
    "    \n",
    "\n",
    "def pointcloud_splite_by_layers(point_cloud, max_layer, layer_thickness=0.042, slice_tolerance=0.005):\n",
    "    \"\"\"\n",
    "    将点云切割成多层，每层0.04个高度，然后依次取每个方块放到固定位置并显示。\n",
    "    \"\"\"\n",
    "    # 获取点和颜色信息直接使用 open3d 的方法\n",
    "    points = point_cloud.points\n",
    "    colors = point_cloud.colors if point_cloud.has_colors() else o3d.utility.Vector3dVector([[1, 1, 1]] * len(points))\n",
    "    movecount = 0\n",
    "    cube_point_cloud = cube_mesh.sample_points_uniformly(number_of_points=50000) \n",
    "    cube_point_cloud = filter_point_cloud_by_depth(cube_point_cloud, depth_threshold=-0.01)\n",
    "    \n",
    "    for layer in range(max_layer-1, -1, -1):\n",
    "        z_base = layer * layer_thickness\n",
    "        z_min = z_base + slice_tolerance\n",
    "        z_max = z_base + layer_thickness + slice_tolerance\n",
    "\n",
    "        # 筛选属于该层的点\n",
    "        mask = [z_min <= pt[2] <= z_max for pt in points]\n",
    "        layer_points = [points[i] for i in range(len(points)) if mask[i]]\n",
    "        layer_colors = [colors[i] for i in range(len(colors)) if mask[i]]\n",
    "\n",
    "        if len(layer_points) > 0:\n",
    "            print(f\"Processing layer {layer} (Z range: {z_min:.4f} to {z_max:.4f})\")\n",
    "            \n",
    "            # 创建一个新的点云对象用于显示16\n",
    "            layer_point_cloud = o3d.geometry.PointCloud()\n",
    "            \n",
    "            layer_point_cloud.points = o3d.utility.Vector3dVector(layer_points)\n",
    "            layer_point_cloud.colors = o3d.utility.Vector3dVector(layer_colors)\n",
    "            o3d.visualization.draw_geometries([coordinate_frame, layer_point_cloud], window_name=\"layer_point_cloud\")\n",
    "            \n",
    "            remaining_pointcloud_count = 10000\n",
    "            countdown = 100\n",
    "            # 使用 open3d 可视化点云\n",
    "            # o3d.visualization.draw_geometries([layer_point_cloud], window_name=f\"Layer {layer} (Z range: {z_min:.4f} to {z_max:.4f})\")\n",
    "            while remaining_pointcloud_count > 500 and countdown>0:\n",
    "                transform, remaining_pointcloud, deleted_pointcloud, fitness = register_and_filter(layer_point_cloud, cube_point_cloud)\n",
    "                remaining_pointcloud_count = len(remaining_pointcloud.points)\n",
    "                # return transform, remaining_pointcloud, deleted_pointcloud\n",
    "                if fitness > 0.1:\n",
    "                    countdown = countdown - 1\n",
    "                print(fitness)\n",
    "                # if check_transform_z_axis_alignment(transform) and fitness>0.60 and  np.array_equal(transform, align_transform_z_axis(transform)):\n",
    "                if fitness>0.60:\n",
    "                    o3d.visualization.draw_geometries([coordinate_frame, remaining_pointcloud], window_name=\"remaining_pointcloud\")\n",
    "                    print(\"move \", movecount+1, \" cube\")\n",
    "                    # 1. 矫正翻转的z轴\n",
    "                    \n",
    "                    # 2. 识别识别出的cube的top面是什么\n",
    "                    cube_point_cloud_transormed = copy.deepcopy(deleted_pointcloud)\n",
    "                    cube_point_cloud_transormed = cube_point_cloud_transormed.transform(np.linalg.inv(transform))\n",
    "                    print(transform)\n",
    "                    broadcaster.update(transform)\n",
    "                    cube_coordinate_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "                        size=0.1,  # 坐标轴大小，可以根据需要调整\n",
    "                        origin=[0, 0, 0]  # 坐标轴的原点\n",
    "                    )\n",
    "                    theta = np.radians(45)  # 将角度转换为弧度\n",
    "                    transform_matrix_x_180 = np.array([\n",
    "                        [1, 0, 0, 0],\n",
    "                        [0, -1, 0, 0],\n",
    "                        [0, 0, -1, 0],\n",
    "                        [0, 0, 0, 1]\n",
    "                    ])\n",
    "                    graps_transform = transform@transform_matrix_x_180\n",
    "                    cube_point_cloud_transormed_cubes = enlarge_points_as_cubes(cube_point_cloud_transormed)\n",
    "                    \n",
    "\n",
    "                    cube_top_image = triangle_mesh_to_image(cube_point_cloud_transormed_cubes, image_size=(100, 100))\n",
    "                    cube_top_image = (cube_top_image / cube_top_image.max() * 255).astype(np.uint8)\n",
    "                    grasp_coordinate_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "                        size=0.1,  # 坐标轴大小，可以根据需要调整\n",
    "                        origin=[0, 0, 0]  # 坐标轴的原点\n",
    "                    )\n",
    "\n",
    "                    # 应用变换矩阵到坐标系\n",
    "                    grasp_coordinate_frame.transform(graps_transform)\n",
    "                    # o3d.visualization.draw_geometries([grasp_coordinate_frame, deleted_pointcloud, coordinate_frame], window_name=\"Filtered Point Cloud\")\n",
    "                    \n",
    "                    # cube_top_image = point_cloud_to_image(cube_point_cloud_transormed)\n",
    "                    plt.imsave(f\"test_{movecount}.png\", cube_top_image)\n",
    "                    plt.show()\n",
    "                    # o3d.visualization.draw_geometries([coordinate_frame, cube_coordinate_frame, deleted_pointcloud], window_name=\"Transformed Coordinate Frame\")\n",
    "                    \n",
    "                    # print(gpt4o_analysis(f\"test_{movecount}.png\"))\n",
    "                    # return\n",
    "                    # image_recognizer_result = image_recognizer.recognize_image(cube_top_image)\n",
    "                    # image_recognizer.display_results(cube_top_image, image_recognizer_result)\n",
    "                    # return cube_top_image, image_recognizer_result\n",
    "                    # image_recognizer_best_result = image_recognizer.selected_best_based_on_CNN(image_recognizer_result, cube_top_image)\n",
    "                    # img, angle = image_recognizer.get_image_from_result(image_recognizer_best_result) # angle用于在place时候将其转正\n",
    "                    # plt.imshow(img)\n",
    "                    # plt.axis(\"off\")\n",
    "                    # plt.show()\n",
    "                    angle = 0\n",
    "                    \n",
    "                    layer_point_cloud = remaining_pointcloud\n",
    "                    \n",
    "                    # continue\n",
    "                    \n",
    "                    # 3. move \n",
    "#                     # 如果匹配度高，则移动将其移动到指定位置\n",
    "                    # 创建绕x轴旋转180度的4x4变换矩阵\n",
    "                    \n",
    "                    pick_rpy, pick_pos = matrix_to_rpy_and_translation(graps_transform)\n",
    "                    pick_pos_ = [a + b for a, b in zip(pick_pos, [0, 0, 0.10])]\n",
    "                    pick_rpy = [a + b for a, b in zip(pick_rpy, [0, 0, 0])]\n",
    "                    # pick_place.move(pick_pos_, pick_rpy)\n",
    "                    print(\"move_to\", pick_pos_, pick_rpy)\n",
    "            \n",
    "                    pick_pos_ = [a + b for a, b in zip(pick_pos, [0.014, 0.020, 0.12])] # 安全距离\n",
    "                    place_pos = [0.5-0.1*(movecount%4), 0.4-0.1*(movecount//4), 0.15]\n",
    "                    place_rpy = [0, np.pi, -np.pi/4+angle]\n",
    "\n",
    "                    \n",
    "                    # 保持一个安全距离，或者做collision avoidance\n",
    "                    # pick_place.move(pick_pos_, pick_rpy)\n",
    "                    movecount = movecount+1\n",
    "                else:\n",
    "                    cube_point_cloud = cube_mesh.sample_points_uniformly(number_of_points=50000) \n",
    "                    cube_point_cloud = filter_point_cloud_by_depth(cube_point_cloud, depth_threshold=-0.01)\n",
    "                \n",
    "            # 这里debug用，直接return\n",
    "            # return transform, remaining_pointcloud, deleted_pointcloud\n",
    "    print(\"done!\") \n",
    "# T, remaining_pointcloud, deleted_pointcloud = pointcloud_splite_by_layers(filtered_point_cloud, max_layer)\n",
    "# cube_top_image, image_recognizer_result = pointcloud_splite_by_layers(filtered_point_cloud, max_layer)\n",
    "# cube_point_cloud_transormed = pointcloud_splite_by_layers(filtered_point_cloud, max_layer)\n",
    "pointcloud_splite_by_layers(filtered_point_cloud, max_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97a75a1-7a1b-4df9-87e5-f22fc098e059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916923c9-2c36-417b-bb2a-7a07e665e320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1aa9b1-890b-4a21-a656-5c54a75d5c01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8e1942-89b9-460e-8013-c3406e5ec660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f97b18-cf6e-4683-b2b0-b18f61f0c335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84bdaf3-eb89-4acf-aa35-34d10d9ff810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72f5be6-10ab-4a45-9860-f3cdf9737da3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc74575-a184-436e-b10f-6e5cbd701094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
