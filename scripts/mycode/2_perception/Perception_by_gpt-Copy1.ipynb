{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb0fd4c1-97e3-4984-a270-edddc5a05230",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Python Path:\n",
      "\n",
      "/opt/ros_ws/devel/lib/python3/dist-packages\n",
      "/opt/ros/noetic/lib/python3/dist-packages\n",
      "/usr/lib/python38.zip\n",
      "/usr/lib/python3.8\n",
      "/usr/lib/python3.8/lib-dynload\n",
      "/usr/local/lib/python3.8/dist-packages\n",
      "/usr/lib/python3/dist-packages\n",
      "/opt/ros_ws/src/franka_zed_gazebo/scripts/mycode/3_move\n",
      "/opt/ros_ws/src/franka_zed_gazebo/scripts/mycode/1_getPointCloud\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 获取当前工作目录（用于替代 __file__）\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "target_path1 = os.path.abspath(os.path.join(current_dir, '../3_move'))\n",
    "target_path2 = os.path.abspath(os.path.join(current_dir, '../1_getPointCloud'))\n",
    "\n",
    "# 将路径添加到 sys.path\n",
    "if target_path1 not in sys.path:\n",
    "    sys.path.append(target_path1)\n",
    "    \n",
    "if target_path2 not in sys.path:\n",
    "    sys.path.append(target_path2)\n",
    "    \n",
    "# 检查路径是否添加成功\n",
    "print(\"Current Python Path:\")\n",
    "print(\"\\n\".join(sys.path))\n",
    "\n",
    "from ImageRecognizer import ImageRecognizer\n",
    "image_recognizer = ImageRecognizer(top_dir=\"/opt/ros_ws/src/franka_zed_gazebo/scripts/mycode/2_perception/cubes/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed72673e-cc5b-4fc5-8942-e6652c917234",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "def matrix_to_rpy_and_translation(matrix):\n",
    "    \"\"\"\n",
    "    从4x4变换矩阵中提取RPY（Roll, Pitch, Yaw）和位移信息，并返回一个列表形式。\n",
    "    \n",
    "    参数:\n",
    "        matrix: 4x4变换矩阵 (numpy.ndarray)\n",
    "        \n",
    "    返回:\n",
    "        result: 一个包含 [roll, pitch, yaw, x, y, z] 的列表\n",
    "    \"\"\"\n",
    "    if matrix.shape != (4, 4):\n",
    "        raise ValueError(\"输入必须是一个 4x4 矩阵\")\n",
    "    \n",
    "    # 提取旋转矩阵和位移\n",
    "    rotation_matrix = matrix[:3, :3]\n",
    "    translation = matrix[:3, 3]\n",
    "    \n",
    "    # 创建旋转矩阵的副本，避免只读内存问题\n",
    "    rotation_matrix = np.array(rotation_matrix)\n",
    "    \n",
    "    # 使用scipy转换为RPY角\n",
    "    r = R.from_matrix(rotation_matrix)\n",
    "    roll, pitch, yaw = r.as_euler('xyz', degrees=False)\n",
    "    \n",
    "    # 返回结果\n",
    "    return [roll, pitch, yaw], translation.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c575264-32a4-4fc0-9469-5ce80c9a98fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2025-01-31 07:12:13,807 - topics - topicmanager initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[%t] [%l] %m\n",
      "[%t] [%l] %m\n",
      "[%t] [%l] %m\n",
      "[%t] [%l] %m\n",
      "[%t] [%l] %m\n",
      "[%t] [%l] %m\n",
      "[%t] [%l] %m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[%t] [%l] %m\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[%t] [%l] %m\n",
      "[%t] [%l] %m\n",
      "[%t] [%l] %m\n"
     ]
    }
   ],
   "source": [
    "from save_point_cloud import PointCloudSaver\n",
    "import open3d as o3d\n",
    "import rospy\n",
    "point_cloud_saver = PointCloudSaver()\n",
    "\n",
    "# 等待数据准备\n",
    "rospy.loginfo(\"Waiting for data...\")\n",
    "rospy.sleep(1)  # 等待话题数据发布\n",
    "\n",
    "# 保存点云\n",
    "world_file = \"/opt/ros_ws/src/franka_zed_gazebo/scripts/mycode/2_perception/mesh/zed_point_cloud_world3.ply\"\n",
    "point_cloud_saver.save_point_clouds(world_file)\n",
    "\n",
    "\n",
    "from PickAndPlace import PickAndPlace\n",
    "pick_place = PickAndPlace(approach_distance=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ebdb0eb-9e99-4745-88a8-52bfcc7225d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "def filter_point_cloud_by_depth_and_range(point_cloud, depth_threshold=0.005, range=[0.001, -0.8, 1, 1.6]):\n",
    "    \"\"\"\n",
    "    读取点云文件并过滤掉深度低于指定阈值和超出检测范围的点。\n",
    "\n",
    "    Args:\n",
    "        point_cloud (o3d.geometry.PointCloud): 点云对象。\n",
    "        depth_threshold (float): 深度阈值，低于该值的点将被过滤。\n",
    "        range (list): 过滤范围，包含 [x, y, w, h]。\n",
    "        \n",
    "    Returns:\n",
    "        o3d.geometry.PointCloud: 过滤后的点云对象。\n",
    "    \"\"\"\n",
    "\n",
    "    # 获取点云的点坐标\n",
    "    points = np.asarray(point_cloud.points)\n",
    "\n",
    "    # 过滤深度小于阈值的点\n",
    "    filtered_points = points[points[:, 2] >= depth_threshold]\n",
    "\n",
    "    # 根据范围过滤点 (x, y, w, h) -> 左上角和宽高\n",
    "    x, y, w, h = range\n",
    "    filtered_points = filtered_points[\n",
    "        (filtered_points[:, 0] >= x) & (filtered_points[:, 0] <= x + w) &\n",
    "        (filtered_points[:, 1] >= y) & (filtered_points[:, 1] <= y + h)\n",
    "    ]\n",
    "\n",
    "    # 创建新的点云对象\n",
    "    filtered_point_cloud = o3d.geometry.PointCloud()\n",
    "    filtered_point_cloud.points = o3d.utility.Vector3dVector(filtered_points)\n",
    "\n",
    "    # 保留颜色信息（如果存在）\n",
    "    if point_cloud.has_colors():\n",
    "        colors = np.asarray(point_cloud.colors)\n",
    "        filtered_colors = colors[points[:, 2] >= depth_threshold]\n",
    "        filtered_point_cloud.colors = o3d.utility.Vector3dVector(filtered_colors)\n",
    "\n",
    "    return filtered_point_cloud\n",
    "\n",
    "def filter_point_cloud_by_depth(point_cloud, depth_threshold=0.005):\n",
    "    \"\"\"\n",
    "    读取点云文件并过滤掉深度低于指定阈值的点。\n",
    "\n",
    "    Args:\n",
    "        ply_path (str): 点云文件的路径。\n",
    "        depth_threshold (float): 深度阈值，低于该值的点将被过滤。\n",
    "\n",
    "    Returns:\n",
    "        o3d.geometry.PointCloud: 过滤后的点云对象。\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # 获取点云的点坐标\n",
    "    points = np.asarray(point_cloud.points)\n",
    "\n",
    "    # 过滤深度小于阈值的点\n",
    "    filtered_points = points[points[:, 2] >= depth_threshold]\n",
    "\n",
    "    # 创建新的点云对象\n",
    "    filtered_point_cloud = o3d.geometry.PointCloud()\n",
    "    filtered_point_cloud.points = o3d.utility.Vector3dVector(filtered_points)\n",
    "\n",
    "    # 保留颜色信息（如果存在）\n",
    "    if point_cloud.has_colors():\n",
    "        colors = np.asarray(point_cloud.colors)\n",
    "        filtered_colors = colors[points[:, 2] >= depth_threshold]\n",
    "        filtered_point_cloud.colors = o3d.utility.Vector3dVector(filtered_colors)\n",
    "\n",
    "    return filtered_point_cloud\n",
    "\n",
    "zed_ply_path = \"mesh/zed_point_cloud_world3.ply\"\n",
    "\n",
    "coordinate_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "    size=0.1,  # 坐标轴大小，可以根据需要调整\n",
    "    origin=[0, 0, 0]  # 坐标轴的原点\n",
    ")\n",
    "\n",
    "# 读取点云文件\n",
    "point_cloud = o3d.io.read_point_cloud(zed_ply_path)\n",
    "if not point_cloud.has_points():\n",
    "    raise ValueError(f\"Failed to read point cloud from {zed_ply_path}\")\n",
    "filtered_point_cloud = filter_point_cloud_by_depth_and_range(point_cloud, depth_threshold=0.005, range=[0.001, -0.8, 1, 1.6])\n",
    "o3d.visualization.draw_geometries([filtered_point_cloud, coordinate_frame], window_name=\"Filtered Point Cloud\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9883e9d-4bce-412e-ad0a-224f0121b514",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxLayer: 1\n"
     ]
    }
   ],
   "source": [
    "def calculate_max_layer(filtered_point_cloud, layer_height=0.04):\n",
    "    \"\"\"\n",
    "    计算点云的最高层数 (MaxLayer)，基于 z 轴最大值，使用四舍五入计算。\n",
    "\n",
    "    Args:\n",
    "        filtered_point_cloud (o3d.geometry.PointCloud): 已过滤的点云对象。\n",
    "        layer_height (float): 每一层的高度，默认值为 0.04。\n",
    "\n",
    "    Returns:\n",
    "        int: 最高层数 (MaxLayer)。\n",
    "    \"\"\"\n",
    "    # 提取点云的 z 轴最大值\n",
    "    points = np.asarray(filtered_point_cloud.points)\n",
    "    z_max = np.max(points[:, 2])\n",
    "\n",
    "    # 计算最高层数，严格四舍五入\n",
    "    max_layer = int(np.floor(z_max / layer_height + 0.5))\n",
    "\n",
    "    return max_layer\n",
    "\n",
    "# 示例调用\n",
    "max_layer = calculate_max_layer(filtered_point_cloud, layer_height=0.04)\n",
    "print(f\"MaxLayer: {max_layer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88fe104e-b675-4313-93a1-417cdc00c8cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "def register_and_filter(pointcloud, mesh, voxel_size=0.01):\n",
    "    # 转换mesh为点云\n",
    "    if isinstance(mesh, o3d.geometry.TriangleMesh):\n",
    "        mesh_pointcloud = mesh.sample_points_uniformly(number_of_points=1000)\n",
    "    elif isinstance(mesh, o3d.geometry.PointCloud):\n",
    "        mesh_pointcloud = copy.deepcopy(mesh)\n",
    "    \n",
    "    # 下采样点云并计算特征\n",
    "    def preprocess_point_cloud(pcd, voxel_size):\n",
    "        pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "        pcd_down.estimate_normals(\n",
    "            search_param=o3d.geometry.KDTreeSearchParamHybrid(\n",
    "                radius=voxel_size*2, \n",
    "                max_nn=30\n",
    "            )\n",
    "        )\n",
    "        pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "            pcd_down,\n",
    "            search_param=o3d.geometry.KDTreeSearchParamHybrid(\n",
    "                radius=voxel_size*5, \n",
    "                max_nn=100\n",
    "            )\n",
    "        )\n",
    "        return pcd_down, pcd_fpfh\n",
    "\n",
    "    # 粗配准\n",
    "    def execute_global_registration(source_down, target_down, source_fpfh, target_fpfh, voxel_size):\n",
    "        distance_threshold = voxel_size * 1.5\n",
    "        result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "            source_down, target_down, source_fpfh, target_fpfh, True,\n",
    "            distance_threshold,\n",
    "            o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "            4,\n",
    "            [\n",
    "                o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "                o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "            ],\n",
    "            o3d.pipelines.registration.RANSACConvergenceCriteria(4000000, 500)\n",
    "        )\n",
    "        return result\n",
    "\n",
    "    # 精配准\n",
    "    def refine_registration(source, target, initial_transformation, voxel_size):\n",
    "        distance_threshold = voxel_size * 1  # 减小阈值提高精度\n",
    "        result = o3d.pipelines.registration.registration_icp(\n",
    "            source, target, distance_threshold, initial_transformation,\n",
    "            o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "            o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=1000000)\n",
    "        )\n",
    "        return result\n",
    "\n",
    "    # 执行点云预处理\n",
    "    source_down, source_fpfh = preprocess_point_cloud(mesh_pointcloud, voxel_size)\n",
    "    target_down, target_fpfh = preprocess_point_cloud(pointcloud, voxel_size)\n",
    "\n",
    "    # 执行配准\n",
    "    coarse_result = execute_global_registration(source_down, target_down, source_fpfh, target_fpfh, voxel_size)\n",
    "    refined_result = refine_registration(mesh_pointcloud, pointcloud, coarse_result.transformation, voxel_size)\n",
    "\n",
    "    # 变换网格点云\n",
    "    transform = refined_result.transformation\n",
    "    transformed_mesh_pointcloud = mesh_pointcloud.transform(transform)\n",
    "\n",
    "    # 创建包围盒\n",
    "    oriented_bounding_box = transformed_mesh_pointcloud.get_oriented_bounding_box()\n",
    "    center = oriented_bounding_box.center\n",
    "    extent = oriented_bounding_box.extent\n",
    "    rotation_matrix = oriented_bounding_box.R\n",
    "\n",
    "    # 扩展包围盒\n",
    "    margin = voxel_size\n",
    "    expanded_extent = extent + 1.0 * margin\n",
    "    expanded_bounding_box = o3d.geometry.OrientedBoundingBox(\n",
    "        center=center,\n",
    "        extent=expanded_extent,\n",
    "        R=rotation_matrix\n",
    "    )\n",
    "\n",
    "    # 过滤点云\n",
    "    indices_inside_box = expanded_bounding_box.get_point_indices_within_bounding_box(pointcloud.points)\n",
    "    indices_outside_box = list(set(range(len(pointcloud.points))) - set(indices_inside_box))\n",
    "\n",
    "    # 分离点云\n",
    "    remaining_pointcloud = pointcloud.select_by_index(indices_outside_box)\n",
    "    deleted_pointcloud = pointcloud.select_by_index(indices_inside_box)\n",
    "\n",
    "    return transform, remaining_pointcloud, deleted_pointcloud, refined_result.fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97050aea-fb60-4b73-b5ee-14d1b5891787",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 读取cube\n",
    "# 定义文件路径\n",
    "cube_obj_path = \"mesh/cube_0.obj\"\n",
    "zed_ply_path = \"mesh/zed_point_cloud_world3.ply\"\n",
    "\n",
    "# 读取 cube_0.obj 点云\n",
    "cube_mesh = o3d.io.read_triangle_mesh(cube_obj_path)\n",
    "cube_mesh.compute_vertex_normals()  # 计算法线以便更好显示\n",
    "# cube_point_cloud = cube_mesh.sample_points_uniformly(number_of_points=50000)  # 转为点云\n",
    "# cube_point_cloud = cube_mesh.sample_points_poisson_disk(number_of_points=1000)\n",
    "\n",
    "# 去掉cube下半部分，防止z轴翻转\n",
    "# cube_point_cloud = filter_point_cloud_by_depth(cube_point_cloud, depth_threshold=-0.015)\n",
    "# o3d.visualization.draw_geometries([cube_point_cloud])\n",
    "\n",
    "\n",
    "coordinate_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "    size=0.1,  # 坐标轴大小，可以根据需要调整\n",
    "    origin=[0, 0, 0]  # 坐标轴的原点\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54f3fe34-f397-4e76-8452-b24a6cf4e9f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_transform_z_axis_alignment(transform, tolerance=0.1):\n",
    "    \"\"\"\n",
    "    检查 transform 的 Z 轴是否与世界坐标系的 Z 轴平行。\n",
    "    允许一定的容差范围内，判断是否平行或反向平行。\n",
    "    参数:\n",
    "    - transform: 4x4 转换矩阵\n",
    "    - tolerance: 判断的容差范围，默认 0.1\n",
    "    返回:\n",
    "    - True: 如果 Z 轴平行或反向平行\n",
    "    - False: 如果 Z 轴不平行\n",
    "    - 修正后的\n",
    "    \"\"\"\n",
    "    z_axis = np.array([0, 0, 1])  # 世界坐标系的 Z 轴\n",
    "    transform_z_axis = transform[:3, 2]  # 获取 transform 的 Z 轴（即旋转矩阵的第三列）\n",
    "\n",
    "    # 计算 transform Z 轴与世界坐标系 Z 轴的夹角\n",
    "    dot_product = np.dot(transform_z_axis, z_axis)\n",
    "    # 计算夹角的余弦值，如果接近 1 或 -1，表示平行或反向平行\n",
    "    if np.abs(dot_product) > (1 - tolerance):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def align_transform_z_axis(transform):\n",
    "    \"\"\"\n",
    "    如果 transform 的 Z 轴与世界坐标系 Z 轴反向平行，\n",
    "    则通过绕 X 轴旋转 180 度（np.pi）来翻转 Z 轴方向。\n",
    "    \n",
    "    参数:\n",
    "    - transform: 4x4 转换矩阵\n",
    "    \n",
    "    返回:\n",
    "    - 修正后的 transform 矩阵\n",
    "    \"\"\"\n",
    "    z_axis_world = np.array([0, 0, 1])  # 世界坐标系的 Z 轴\n",
    "    transform_z_axis = transform[:3, 2]  # 获取 transform 的 Z 轴（旋转矩阵的第三列）\n",
    "\n",
    "    # 判断 Z 轴是否与世界坐标系 Z 轴反向平行\n",
    "    if np.dot(transform_z_axis, z_axis_world) < 0:  # Z 轴反向\n",
    "        print(\"修正z轴\")\n",
    "        # 创建绕 X 轴旋转 180 度的旋转矩阵\n",
    "        rotation_matrix = np.eye(4)\n",
    "        rotation_matrix[1, 1] = -1  # 旋转矩阵绕 X 轴旋转 180 度\n",
    "        rotation_matrix[2, 2] = -1  # 旋转矩阵绕 X 轴旋转 180 度\n",
    "        \n",
    "        # 进行矩阵乘法，旋转矩阵应用到原始 transform 上\n",
    "        transform = np.dot(rotation_matrix, transform)\n",
    "\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcefc557-cb74-405f-bc65-51be58aebe8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "def max_downsample_image(image, pool_size=(2, 2)):\n",
    "    \"\"\"\n",
    "    使用最大值池化对图像进行降采样。\n",
    "\n",
    "    Args:\n",
    "        image (numpy.ndarray): 输入彩色图像 (height, width, 3)\n",
    "        pool_size (tuple): 池化窗口大小 (height, width)\n",
    "\n",
    "    Returns:\n",
    "        downsampled_image (numpy.ndarray): 降采样后的图像\n",
    "    \"\"\"\n",
    "    h, w, c = image.shape\n",
    "    ph, pw = pool_size\n",
    "\n",
    "    # 确保图像尺寸是池化窗口的整数倍\n",
    "    h_new = h // ph * ph\n",
    "    w_new = w // pw * pw\n",
    "    image_cropped = image[:h_new, :w_new, :]\n",
    "\n",
    "    # 使用最大池化降采样\n",
    "    downsampled_image = image_cropped.reshape(h_new // ph, ph, w_new // pw, pw, c).max(axis=(1, 3))\n",
    "\n",
    "    return downsampled_image\n",
    "\n",
    "def pointcloud_to_top_view_image_color(pointcloud, voxel_size=0.01, output_image_size=(512, 512)):\n",
    "    \"\"\"\n",
    "    从点云生成正上方的彩色 2D 图像。\n",
    "    \n",
    "    Args:\n",
    "        pointcloud (o3d.geometry.PointCloud): 输入点云\n",
    "        voxel_size (float): 分辨率，用于划分网格\n",
    "        output_image_size (tuple): 输出图像大小 (width, height)\n",
    "    \n",
    "    Returns:\n",
    "        top_view_image (numpy.ndarray): 生成的 2D 彩色图像\n",
    "    \"\"\"\n",
    "    # 获取点云的点坐标和颜色\n",
    "    points = np.asarray(pointcloud.points)\n",
    "    colors = np.asarray(pointcloud.colors) if pointcloud.has_colors() else np.zeros_like(points)\n",
    "\n",
    "    # 提取 x-y 范围\n",
    "    x_min, y_min = np.min(points[:, :2], axis=0)\n",
    "    x_max, y_max = np.max(points[:, :2], axis=0)\n",
    "    print(x_max, y_max)\n",
    "\n",
    "    # 定义网格分辨率\n",
    "    width, height = output_image_size\n",
    "    grid_x = np.linspace(x_min, x_max, width)\n",
    "    grid_y = np.linspace(y_min, y_max, height)\n",
    "\n",
    "    # 初始化 2D 彩色图像\n",
    "    top_view_image = np.zeros((height, width, 3))  # RGB 图像\n",
    "\n",
    "    # 初始化计数矩阵以累积颜色\n",
    "    count_matrix = np.zeros((height, width))\n",
    "\n",
    "    # 遍历点云，将每个点投影到网格上\n",
    "    for point, color in zip(points, colors):\n",
    "        x, y, z = point\n",
    "        # 找到对应的网格索引\n",
    "        x_idx = int((x - x_min) / (x_max - x_min) * (width - 1))\n",
    "        y_idx = int((y - y_min) / (y_max - y_min) * (height - 1))\n",
    "        \n",
    "        # 更新彩色图像和计数矩阵\n",
    "        top_view_image[height - 1 - y_idx, x_idx] += color  # 累加颜色\n",
    "        count_matrix[height - 1 - y_idx, x_idx] += 1\n",
    "\n",
    "    # 平均化颜色值\n",
    "    nonzero_mask = count_matrix > 0\n",
    "    top_view_image[nonzero_mask] /= count_matrix[nonzero_mask, None]\n",
    "\n",
    "    # 将结果归一化到 0-1 范围内\n",
    "    top_view_image = np.clip(top_view_image, 0, 1)\n",
    "\n",
    "    return top_view_image\n",
    "\n",
    "\n",
    "import scipy.ndimage\n",
    "\n",
    "def interpolate_sparse_image(image, dilation_size=(7, 7)):\n",
    "    \"\"\"\n",
    "    对稀疏的彩色图像进行插值填充。\n",
    "    \n",
    "    Args:\n",
    "        image (numpy.ndarray): 输入彩色图像 (height, width, 3)\n",
    "        dilation_size (tuple): 膨胀操作的邻域大小 (height, width)\n",
    "    \n",
    "    Returns:\n",
    "        interpolated_image (numpy.ndarray): 插值后的彩色图像\n",
    "    \"\"\"\n",
    "    interpolated_image = image.copy()\n",
    "    for i in range(3):  # 分别处理 RGB 三个通道\n",
    "        interpolated_image[:, :, i] = scipy.ndimage.morphology.grey_dilation(\n",
    "            image[:, :, i], size=dilation_size\n",
    "        )\n",
    "    return interpolated_image\n",
    "\n",
    "\n",
    "def pointcloud_to_colored_image_with_filling(pointcloud, output_size=(512, 512), voxel_size=0.01):\n",
    "    \"\"\"\n",
    "    从点云生成正上方的彩色 2D 图像，使用高斯滤波填充空白区域。\n",
    "    \n",
    "    Args:\n",
    "        pointcloud (o3d.geometry.PointCloud): 输入点云。\n",
    "        output_size (tuple): 输出图像大小 (width, height)。\n",
    "        voxel_size (float): 网格分辨率，用于划分网格。\n",
    "    \n",
    "    Returns:\n",
    "        top_view_image (numpy.ndarray): 填充后的彩色图像。\n",
    "    \"\"\"\n",
    "    # 获取点云的点坐标和颜色\n",
    "    points = np.asarray(pointcloud.points)\n",
    "    colors = np.asarray(pointcloud.colors) if pointcloud.has_colors() else np.zeros_like(points)\n",
    "\n",
    "    # 提取 x-y 范围\n",
    "    x_min, y_min = np.min(points[:, :2], axis=0)\n",
    "    x_max, y_max = np.max(points[:, :2], axis=0)\n",
    "\n",
    "    # 定义网格分辨率\n",
    "    width, height = output_size\n",
    "    grid_x = np.linspace(x_min, x_max, width)\n",
    "    grid_y = np.linspace(y_min, y_max, height)\n",
    "\n",
    "    # 初始化 2D 彩色图像和计数矩阵\n",
    "    top_view_image = np.zeros((height, width, 3), dtype=np.float32)  # RGB 图像\n",
    "    count_matrix = np.zeros((height, width), dtype=np.float32)\n",
    "\n",
    "    # 遍历点云，将每个点投影到网格上\n",
    "    for point, color in zip(points, colors):\n",
    "        x, y, z = point\n",
    "        # 找到对应的网格索引\n",
    "        x_idx = int((x - x_min) / (x_max - x_min) * (width - 1))\n",
    "        y_idx = int((y - y_min) / (y_max - y_min) * (height - 1))\n",
    "        \n",
    "        # 累积颜色值\n",
    "        top_view_image[height - 1 - y_idx, x_idx] += color  # 累加颜色\n",
    "        count_matrix[height - 1 - y_idx, x_idx] += 1\n",
    "\n",
    "    # 归一化颜色值\n",
    "    nonzero_mask = count_matrix > 0\n",
    "    top_view_image[nonzero_mask] /= count_matrix[nonzero_mask, None]\n",
    "\n",
    "    # 使用高斯滤波填充空白区域\n",
    "    for channel in range(3):  # 对 R/G/B 通道分别处理\n",
    "        top_view_image[:, :, channel] = gaussian_filter(top_view_image[:, :, channel], sigma=2)\n",
    "\n",
    "    # 将图像裁剪到 [0, 1] 范围\n",
    "    top_view_image = np.clip(top_view_image, 0, 1)\n",
    "\n",
    "    return top_view_image\n",
    "\n",
    "def triangle_mesh_to_image(mesh, image_size=(100, 100), fill_radius=1):\n",
    "    \"\"\"\n",
    "    将 TriangleMesh 的顶点投影到 2D 图像上，并通过最大池化生成较小的图像。\n",
    "    确保每个像素点有值。\n",
    "    \n",
    "    Args:\n",
    "        mesh (o3d.geometry.TriangleMesh): 输入三角网格。\n",
    "        image_size (tuple): 输出图像大小 (width, height)。\n",
    "        pool_size (tuple): 池化窗口大小 (height, width)。\n",
    "        fill_radius (int): 每个点影响的邻域半径（像素）。\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: 投影后的 2D 图像（池化后大小）。\n",
    "    \"\"\"\n",
    "    # 获取顶点和颜色\n",
    "    vertices = np.asarray(mesh.vertices)\n",
    "    colors = np.asarray(mesh.vertex_colors) if mesh.has_vertex_colors() else np.ones((len(vertices), 3))\n",
    "\n",
    "    # 提取 x-y 范围\n",
    "    x_min, y_min = vertices[:, 0].min(), vertices[:, 1].min()\n",
    "    x_max, y_max = vertices[:, 0].max(), vertices[:, 1].max()\n",
    "\n",
    "    # 初始化 2D 图像\n",
    "    width, height = image_size\n",
    "    image = np.zeros((height, width, 3), dtype=np.float32)\n",
    "    count_matrix = np.zeros((height, width), dtype=np.int32)  # 用于统计像素值累计次数\n",
    "\n",
    "    # 映射顶点到图像坐标并填充周围像素\n",
    "    for vertex, color in zip(vertices, colors):\n",
    "        x, y = vertex[0], vertex[1]\n",
    "        u = int((x - x_min) / (x_max - x_min) * (width - 1))\n",
    "        v = int((y - y_min) / (y_max - y_min) * (height - 1))\n",
    "\n",
    "        # 填充当前点和周围像素\n",
    "        for du in range(-fill_radius, fill_radius + 1):\n",
    "            for dv in range(-fill_radius, fill_radius + 1):\n",
    "                uu = min(max(u + du, 0), width - 1)\n",
    "                vv = min(max(v + dv, 0), height - 1)\n",
    "                image[vv, uu] += color\n",
    "                count_matrix[vv, uu] += 1\n",
    "\n",
    "    # 平均化每个像素的颜色值\n",
    "    mask = count_matrix > 0\n",
    "    image[mask] /= count_matrix[mask, None]\n",
    "\n",
    "    # 将图像转换为 0-255 的范围\n",
    "    image = (np.clip(image, 0, 1) * 255).astype(np.uint8)\n",
    "\n",
    "    return image\n",
    "\n",
    "def enlarge_points_as_cubes(point_cloud, cube_size=0.0001):\n",
    "    \"\"\"\n",
    "    将点云的每个点替换为一个立方体以增大显示大小。\n",
    "    \n",
    "    Args:\n",
    "        point_cloud (o3d.geometry.PointCloud): 输入点云。\n",
    "        cube_size (float): 立方体的边长。\n",
    "    \n",
    "    Returns:\n",
    "        o3d.geometry.TriangleMesh: 包含所有点的立方体的组合几何体。\n",
    "    \"\"\"\n",
    "    points = np.asarray(point_cloud.points)\n",
    "    colors = np.asarray(point_cloud.colors) if point_cloud.has_colors() else [[1, 0, 0]] * len(points)\n",
    "    mesh = o3d.geometry.TriangleMesh()\n",
    "\n",
    "    for point, color in zip(points, colors):\n",
    "        # 创建一个小立方体并移动到点的位置\n",
    "        cube = o3d.geometry.TriangleMesh.create_box(width=cube_size, height=cube_size, depth=cube_size)\n",
    "        cube.translate(point - np.array([cube_size / 2, cube_size / 2, cube_size / 2]))\n",
    "        cube.paint_uniform_color(color)\n",
    "        mesh += cube  # 将立方体添加到组合网格中\n",
    "\n",
    "    return mesh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9fcf074-462c-450a-921d-b9589f4b627f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import base64\n",
    "import json\n",
    "SYSTEM_PROMPT = \"\"\"Please act as an image recognition agent. \n",
    "You will be given a square face of a block, \n",
    "which is projected from a point cloud. \n",
    "Your task is to recognize the following:\n",
    "\n",
    "Determine if this is a block face.\n",
    "Each face contains only one letter, \n",
    "one pattern (just detect whether it's a pattern, no need to identify the exact pattern), \n",
    "or is blank (only wood texture). \n",
    "Please detect whether it is a letter, \n",
    "a pattern, or blank. \n",
    "Each of these may be rotated. \n",
    "Please analyze all possible rotations in a clockwise direction: 0°, 90°, 180°, and 270°.\n",
    "There might be a circular border around the face. \n",
    "Please detect if this border exists. \n",
    "It's confirmed that the color of the border matches the color of the letter or pattern.\n",
    "The expected output is a JSON in the following format:\n",
    "{\n",
    "    \"check\": true/false, \n",
    "    \"c\": char/\"pattern\"/\"blank\", \n",
    "    \"color\": \"green\"/\"yellow\"/\"red\"/\"blue\"/\"None\", \n",
    "    \"rotation\": 0/90/180/270, \n",
    "    \"circle\": true/false\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "api_key=\"\"\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "def encode_image(image, quality=100):\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')  # Convert to RGB\n",
    "    buffered = BytesIO()\n",
    "    image.save(buffered, format=\"JPEG\", quality=quality) \n",
    "    return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "def gpt4o_analysis(image_path, quality=50):\n",
    "    with Image.open(image_path) as img:\n",
    "        img_b64_str = encode_image(img, quality=quality)\n",
    "    img_type = \"image/jpeg\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": SYSTEM_PROMPT},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:{img_type};base64,{img_b64_str}\"},\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76d4d048-43c7-4a8a-ba1b-9c8e9fadcfa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import rospy\n",
    "import tf\n",
    "import numpy as np\n",
    "from geometry_msgs.msg import TransformStamped\n",
    "\n",
    "class TransformBroadcaster:\n",
    "    def __init__(self):\n",
    "        # 尝试初始化ROS节点，避免多次初始化\n",
    "        try:\n",
    "            rospy.init_node('tf_broadcaster_node')\n",
    "        except rospy.exceptions.ROSException:\n",
    "            pass  # 如果节点已初始化，就不做任何操作\n",
    "\n",
    "        # 创建一个TransformBroadcaster实例\n",
    "        self.br = tf.TransformBroadcaster()\n",
    "\n",
    "        # 假设T是给定的4x4变换矩阵\n",
    "        self.T = np.ones((4, 4))  # 修改为4x4矩阵\n",
    "\n",
    "        # 设置定时器，每100毫秒调用一次broadcast_transform函数\n",
    "        self.timer = rospy.Timer(rospy.Duration(0.1), self.broadcast_transform)\n",
    "\n",
    "    def broadcast_transform(self, event):\n",
    "        # 从4x4矩阵中提取旋转部分和位移部分\n",
    "        translation = self.T[0:3, 3]  # 位移部分 (x, y, z)\n",
    "        rotation_matrix = self.T[0:3, 0:3]  # 旋转矩阵部分\n",
    "\n",
    "        # 创建一个完整的4x4矩阵，包括旋转矩阵和齐次坐标\n",
    "        full_matrix = np.eye(4)\n",
    "        full_matrix[0:3, 0:3] = rotation_matrix\n",
    "        full_matrix[0:3, 3] = translation\n",
    "\n",
    "        # 创建一个Quaternion（四元数）来表示旋转\n",
    "        quaternion = tf.transformations.quaternion_from_matrix(full_matrix)\n",
    "\n",
    "        # 发布变换\n",
    "        self.br.sendTransform(\n",
    "            (translation[0], translation[1], translation[2]),  # 位移部分\n",
    "            (quaternion[0], quaternion[1], quaternion[2], quaternion[3]),  # 旋转部分（四元数）\n",
    "            rospy.Time.now(),  # 时间戳\n",
    "            \"cube\",  # 子坐标系名称\n",
    "            \"world\"   # 父坐标系名称\n",
    "        )\n",
    "\n",
    "    def update(self, T):\n",
    "        self.T = T\n",
    "        \n",
    "    def stop(self):\n",
    "        # 停止定时器\n",
    "        self.timer.shutdown()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "155cbbb8-ad8b-4146-a453-4cdaf9afbad5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import *  # 假设你的create_grasp_mesh函数在utils.py中\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "def generate_gripper_from_transform(T: np.ndarray):\n",
    "    \"\"\"\n",
    "    Generates a robotic gripper mesh from a given 4x4 transformation matrix,\n",
    "    with additional rotations around x and y axes.\n",
    "\n",
    "    Args:\n",
    "        T: 4x4 transformation matrix (numpy array).\n",
    "        \n",
    "    Returns:\n",
    "        gripper_meshes: List of meshes representing the gripper.\n",
    "    \"\"\"\n",
    "    # 提取旋转矩阵（3x3）\n",
    "    rotation_matrix = T[:3, :3]\n",
    "\n",
    "    # 提取平移向量\n",
    "    translation = T[:3, 3]\n",
    "\n",
    "    # 设置抓手的中心点位置，通常为平移向量\n",
    "    center_point = translation\n",
    "\n",
    "    # 创建绕x轴旋转 -90 度的旋转矩阵\n",
    "    R_x = np.array([\n",
    "        [1, 0, 0],\n",
    "        [0, np.cos(-np.pi/2), -np.sin(-np.pi/2)],\n",
    "        [0, np.sin(-np.pi/2), np.cos(-np.pi/2)]\n",
    "    ])\n",
    "\n",
    "    # 创建绕y轴旋转 90 度的旋转矩阵\n",
    "    R_y = np.array([\n",
    "        [np.cos(np.pi/2), 0, np.sin(np.pi/2)],\n",
    "        [0, 1, 0],\n",
    "        [-np.sin(np.pi/2), 0, np.cos(np.pi/2)]\n",
    "    ])\n",
    "    \n",
    "    R_z = np.array([\n",
    "        [0, -1, 0],\n",
    "        [1, 0, 0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    # 组合旋转矩阵，先绕 x 轴旋转，再绕 y 轴旋转\n",
    "    combined_rotation = R_z @ rotation_matrix @ R_x \n",
    "\n",
    "    # 调用 create_grasp_mesh 函数生成抓手\n",
    "    gripper_meshes = create_grasp_mesh(\n",
    "        center_point=center_point, \n",
    "        rotation_matrix=combined_rotation,\n",
    "        width=0.3\n",
    "    )\n",
    "\n",
    "    return gripper_meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47315293-9f5e-4dd0-a1aa-9efab7885c1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 测试代码：传入一个4x4变换矩阵\n",
    "# T = np.array([\n",
    "#     [1, 0, 0, 0.1],  # 旋转矩阵和位移\n",
    "#     [0, 1, 0, 0.2],\n",
    "#     [0, 0, 1, 0.3],\n",
    "#     [0, 0, 0, 1]\n",
    "# ])\n",
    "\n",
    "# # 调用生成抓手的函数\n",
    "# gripper_meshes = generate_gripper_from_transform(T)\n",
    "\n",
    "# # 可视化生成的抓手\n",
    "# o3d.visualization.draw_geometries(gripper_meshes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348b83d4-ff09-4bbd-a7f0-b5a606c423ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "try:\n",
    "    broadcaster\n",
    "except NameError:\n",
    "    broadcaster = TransformBroadcaster()           \n",
    "    \n",
    "    \n",
    "def pointcloud_process(point_cloud, slice_tolerance=0.005):\n",
    "    '''\n",
    "        识别点云中的cubes\n",
    "        returns:\n",
    "            [\n",
    "                json,\n",
    "                T\n",
    "            ]\n",
    "    '''\n",
    "    T = []\n",
    "    remaining_pointcloud_count = 10000\n",
    "    countdown = 80\n",
    "    # 使用 open3d 可视化点云\n",
    "    # o3d.visualization.draw_geometries([layer_point_cloud], window_name=f\"Layer {layer} (Z range: {z_min:.4f} to {z_max:.4f})\")\n",
    "    movecount = 0\n",
    "    while remaining_pointcloud_count > 50 and countdown > 0:\n",
    "        cube_point_cloud = cube_mesh.sample_points_uniformly(number_of_points=50000) \n",
    "        cube_point_cloud = filter_point_cloud_by_depth(cube_point_cloud, depth_threshold=-0.01)\n",
    "        transform, remaining_pointcloud, deleted_pointcloud, fitness = register_and_filter(point_cloud,cube_point_cloud)\n",
    "        remaining_pointcloud_count = len(remaining_pointcloud.points)\n",
    "        # return transform, remaining_pointcloud, deleted_pointcloud\n",
    "        if fitness > 0.01:\n",
    "            countdown = countdown - 1\n",
    "        # print(fitness)\n",
    "        if check_transform_z_axis_alignment(transform) and fitness>0.70 and np.array_equal(transform, align_transform_z_axis(transform)):\n",
    "        # if fitness > 0.70:\n",
    "            movecount += 1\n",
    "            print(movecount)\n",
    "            \n",
    "\n",
    "            broadcaster.update(transform)\n",
    "            cube_coordinate_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "                size=0.1,  # 坐标轴大小，可以根据需要调整\n",
    "                origin=[0, 0, 0]  # 坐标轴的原点\n",
    "            )\n",
    "            theta = np.radians(45)  # 将角度转换为弧度\n",
    "            transform_matrix_x_180 = np.array([\n",
    "                [1, 0, 0, 0],\n",
    "                [0, -1, 0, 0],\n",
    "                [0, 0, -1, 0],\n",
    "                [0, 0, 0, 1]\n",
    "            ])\n",
    "            graps_transform = transform @ transform_matrix_x_180\n",
    "                        # o3d.visualization.draw_geometries([coordinate_frame, remaining_pointcloud], window_name=\"remaining_pointcloud\")\n",
    "            cube_point_cloud_transormed = copy.deepcopy(deleted_pointcloud)\n",
    "            cube_point_cloud_transormed = cube_point_cloud_transormed.transform(np.linalg.inv(graps_transform))\n",
    "            cube_point_cloud_transormed_cubes = enlarge_points_as_cubes(cube_point_cloud_transormed)\n",
    "\n",
    "            cube_top_image = triangle_mesh_to_image(cube_point_cloud_transormed_cubes, image_size=(100, 100))\n",
    "            cube_top_image = (cube_top_image / cube_top_image.max() * 255).astype(np.uint8)\n",
    "            grasp_coordinate_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "                size=0.1,  # 坐标轴大小，可以根据需要调整\n",
    "                origin=[0, 0, 0]  # 坐标轴的原点\n",
    "            )\n",
    "            grasp_mesh = generate_gripper_from_transform(graps_transform)\n",
    "            # 应用变换矩阵到坐标系\n",
    "            grasp_coordinate_frame.transform(graps_transform)\n",
    "            o3d.visualization.draw_geometries(grasp_mesh+[grasp_coordinate_frame, deleted_pointcloud, coordinate_frame], window_name=\"deleted_pointcloud\")\n",
    "            # o3d.visualization.draw_geometries([grasp_coordinate_frame, remaining_pointcloud, coordinate_frame], window_name=\"remaining_pointcloud\")\n",
    "            pick_rpy, pick_pos = matrix_to_rpy_and_translation(graps_transform)\n",
    "            pick_pos_ = [a + b for a, b in zip(pick_pos, [0, 0, 0.10])]\n",
    "            pick_rpy = [a + b for a, b in zip(pick_rpy, [0, 0, 0])]\n",
    "            pick_place.move(pick_pos_, pick_rpy)\n",
    "            # cube_top_image = point_cloud_to_image(cube_point_cloud_transormed)\n",
    "            plt.imsave(f\"test_{movecount}.png\", cube_top_image)\n",
    "            plt.show()\n",
    "            point_cloud = remaining_pointcloud\n",
    "            # TODO: 识别第一个面\n",
    "            \n",
    "            T.append(graps_transform)\n",
    "        else:\n",
    "            cube_point_cloud = cube_mesh.sample_points_uniformly(number_of_points=50000)\n",
    "            cube_point_cloud = filter_point_cloud_by_depth(cube_point_cloud, depth_threshold=-0.01)\n",
    "    print(T)\n",
    "            \n",
    "Ts = pointcloud_process(filtered_point_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d90518-6b07-4d34-9b10-13a9a97c7c26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7bf932-3c72-44a4-90b3-559ba899174c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf7d104-3c62-454c-8cdc-25427abc1061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1ff911-c41c-4330-be82-95130ec626fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb0f4e0-2497-4dfc-b1a0-816609f38564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b49a45-b76a-4109-a1b9-92473eb0cc5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90752b1-45fd-40c6-95e6-5c641111580b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e628f0-7d4c-4612-8453-cc769bb96ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0b93ec-fc14-4c5b-a51b-ddd187495ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cf24a9-2107-4c18-8b75-410152602d54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97c4cfa-2497-47fb-abcc-b4d8102d5a27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91fbf85f-e79f-4861-b31c-77b8ff6b48d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layer 0 (Z range: 0.0050 to 0.0470)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6568554396423248\n",
      "move  1  cube\n",
      "[[-0.82532072 -0.5291985   0.19696358  0.56893383]\n",
      " [ 0.54097936 -0.84100484  0.00722457 -0.03136308]\n",
      " [ 0.16182409  0.11251582  0.98038419  0.02395822]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "move_to [0.5689338307802249, -0.03136307750997802, 0.12395821807537309] [-3.027325521527317, -0.16253882482928028, 2.5613762806369786]\n",
      "0.8390461997019374\n",
      "move  2  cube\n",
      "[[ 0.06259848 -0.99209167 -0.10879135  0.45976295]\n",
      " [ 0.99646799  0.06824087 -0.04893604  0.0824304 ]\n",
      " [ 0.05597305 -0.10534377  0.99285936  0.02386023]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "move_to [0.45976294713341037, 0.08243039788916531, 0.12386022799508747] [3.0358867255183286, -0.056002320953226326, 1.5080584053879056]\n",
      "0.7081159960258321\n",
      "move  3  cube\n",
      "[[-0.48858119  0.07856064  0.86897448  0.31169561]\n",
      " [ 0.87121089 -0.01057833  0.49079495 -0.14818237]\n",
      " [ 0.04774947  0.99685321 -0.06327451  0.02577682]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "move_to [0.31169561373288673, -0.14818236614166583, 0.12577681878391994] [-1.5074071192414733, -0.04776762920723199, 2.0818987972479417]\n",
      "0.0\n",
      "0.851356799503799\n",
      "move  4  cube\n",
      "[[ 0.07212782  0.02087549 -0.99717691  0.5951346 ]\n",
      " [ 0.03152921  0.99923356  0.02319912 -0.27131852]\n",
      " [ 0.99689693 -0.0331135   0.07141435  0.02486218]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "move_to [0.5951346028937979, -0.2713185230286453, 0.12486217724260637] [2.7074197422617856, -1.4919968623840272, 0.4120995668221619]\n",
      "0.7045743526128082\n",
      "move  5  cube\n",
      "[[ 0.87096352 -0.49088136  0.02140196  0.45178266]\n",
      " [-0.49122069 -0.87090227  0.01521406 -0.16509991]\n",
      " [ 0.01117072 -0.02376398 -0.99965518  0.0418175 ]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "move_to [0.4517826578276561, -0.16509990668845834, 0.14181750008816782] [0.023767700164496818, -0.011170952259720757, -0.5135258121540024]\n",
      "0.8276321910373702\n",
      "move  6  cube\n",
      "[[ 0.04307026  0.59629008 -0.80161281  0.47368501]\n",
      " [-0.05196555  0.80260834  0.59423853 -0.25292227]\n",
      " [ 0.99771967  0.01606224  0.06555509  0.02592202]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "move_to [0.4736850136331662, -0.2529222700231813, 0.1259220175580822] [-2.901307467096101, -1.5032507839156157, -0.8787255998111483]\n",
      "0.6904016126531245\n",
      "move  7  cube\n",
      "[[-0.03447521 -0.99887297  0.03262273  0.48596515]\n",
      " [-0.99893002  0.03544729  0.02970375 -0.10916899]\n",
      " [-0.03082666 -0.03156379 -0.99902625  0.04227949]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "move_to [0.48596514868644547, -0.10916898606659527, 0.14227948552437925] [0.03158404431845031, 0.03083154601246796, -1.6052947676687943]\n",
      "0.7089781361451388\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 143\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone!\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# T, remaining_pointcloud, deleted_pointcloud = pointcloud_splite_by_layers(filtered_point_cloud, max_layer)\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# cube_top_image, image_recognizer_result = pointcloud_splite_by_layers(filtered_point_cloud, max_layer)\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# cube_point_cloud_transormed = pointcloud_splite_by_layers(filtered_point_cloud, max_layer)\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m \u001b[43mpointcloud_splite_by_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered_point_cloud\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_layer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 59\u001b[0m, in \u001b[0;36mpointcloud_splite_by_layers\u001b[0;34m(point_cloud, max_layer, layer_thickness, slice_tolerance)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# if check_transform_z_axis_alignment(transform) and fitness>0.60 and  np.array_equal(transform, align_transform_z_axis(transform)):\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fitness\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0.60\u001b[39m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[43mo3d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisualization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_geometries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcoordinate_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining_pointcloud\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mremaining_pointcloud\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmove \u001b[39m\u001b[38;5;124m\"\u001b[39m, movecount\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m cube\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# 1. 矫正翻转的z轴\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# 2. 识别识别出的cube的top面是什么\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n",
      "\u001b[33m[%t] [%l] %m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "# 设置日志级别为 WARNING，这样 INFO 级别的日志就不会显示\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "try:\n",
    "    broadcaster\n",
    "except NameError:\n",
    "    broadcaster = TransformBroadcaster()           \n",
    "    \n",
    "\n",
    "def pointcloud_splite_by_layers(point_cloud, max_layer, layer_thickness=0.042, slice_tolerance=0.005):\n",
    "    \"\"\"\n",
    "    将点云切割成多层，每层0.04个高度，然后依次取每个方块放到固定位置并显示。\n",
    "    \"\"\"\n",
    "    # 获取点和颜色信息直接使用 open3d 的方法\n",
    "    points = point_cloud.points\n",
    "    colors = point_cloud.colors if point_cloud.has_colors() else o3d.utility.Vector3dVector([[1, 1, 1]] * len(points))\n",
    "    movecount = 0\n",
    "    cube_point_cloud = cube_mesh.sample_points_uniformly(number_of_points=50000) \n",
    "    cube_point_cloud = filter_point_cloud_by_depth(cube_point_cloud, depth_threshold=-0.01)\n",
    "    \n",
    "    for layer in range(max_layer-1, -1, -1):\n",
    "        z_base = layer * layer_thickness\n",
    "        z_min = z_base + slice_tolerance\n",
    "        z_max = z_base + layer_thickness + slice_tolerance\n",
    "\n",
    "        # 筛选属于该层的点\n",
    "        mask = [z_min <= pt[2] <= z_max for pt in points]\n",
    "        layer_points = [points[i] for i in range(len(points)) if mask[i]]\n",
    "        layer_colors = [colors[i] for i in range(len(colors)) if mask[i]]\n",
    "\n",
    "        if len(layer_points) > 0:\n",
    "            print(f\"Processing layer {layer} (Z range: {z_min:.4f} to {z_max:.4f})\")\n",
    "            \n",
    "            # 创建一个新的点云对象用于显示16\n",
    "            layer_point_cloud = o3d.geometry.PointCloud()\n",
    "            \n",
    "            layer_point_cloud.points = o3d.utility.Vector3dVector(layer_points)\n",
    "            layer_point_cloud.colors = o3d.utility.Vector3dVector(layer_colors)\n",
    "            o3d.visualization.draw_geometries([coordinate_frame, layer_point_cloud], window_name=\"layer_point_cloud\")\n",
    "            \n",
    "            remaining_pointcloud_count = 10000\n",
    "            countdown = 100\n",
    "            # 使用 open3d 可视化点云\n",
    "            # o3d.visualization.draw_geometries([layer_point_cloud], window_name=f\"Layer {layer} (Z range: {z_min:.4f} to {z_max:.4f})\")\n",
    "            while remaining_pointcloud_count > 500 and countdown>0:\n",
    "                transform, remaining_pointcloud, deleted_pointcloud, fitness = register_and_filter(layer_point_cloud, cube_point_cloud)\n",
    "                remaining_pointcloud_count = len(remaining_pointcloud.points)\n",
    "                # return transform, remaining_pointcloud, deleted_pointcloud\n",
    "                if fitness > 0.1:\n",
    "                    countdown = countdown - 1\n",
    "                print(fitness)\n",
    "                # if check_transform_z_axis_alignment(transform) and fitness>0.60 and  np.array_equal(transform, align_transform_z_axis(transform)):\n",
    "                if fitness>0.60:\n",
    "                    o3d.visualization.draw_geometries([coordinate_frame, remaining_pointcloud], window_name=\"remaining_pointcloud\")\n",
    "                    print(\"move \", movecount+1, \" cube\")\n",
    "                    # 1. 矫正翻转的z轴\n",
    "                    \n",
    "                    # 2. 识别识别出的cube的top面是什么\n",
    "                    cube_point_cloud_transormed = copy.deepcopy(deleted_pointcloud)\n",
    "                    cube_point_cloud_transormed = cube_point_cloud_transormed.transform(np.linalg.inv(transform))\n",
    "                    print(transform)\n",
    "                    broadcaster.update(transform)\n",
    "                    cube_coordinate_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "                        size=0.1,  # 坐标轴大小，可以根据需要调整\n",
    "                        origin=[0, 0, 0]  # 坐标轴的原点\n",
    "                    )\n",
    "                    theta = np.radians(45)  # 将角度转换为弧度\n",
    "                    transform_matrix_x_180 = np.array([\n",
    "                        [1, 0, 0, 0],\n",
    "                        [0, -1, 0, 0],\n",
    "                        [0, 0, -1, 0],\n",
    "                        [0, 0, 0, 1]\n",
    "                    ])\n",
    "                    graps_transform = transform@transform_matrix_x_180\n",
    "                    cube_point_cloud_transormed_cubes = enlarge_points_as_cubes(cube_point_cloud_transormed)\n",
    "                    \n",
    "\n",
    "                    cube_top_image = triangle_mesh_to_image(cube_point_cloud_transormed_cubes, image_size=(100, 100))\n",
    "                    cube_top_image = (cube_top_image / cube_top_image.max() * 255).astype(np.uint8)\n",
    "                    grasp_coordinate_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "                        size=0.1,  # 坐标轴大小，可以根据需要调整\n",
    "                        origin=[0, 0, 0]  # 坐标轴的原点\n",
    "                    )\n",
    "\n",
    "                    # 应用变换矩阵到坐标系\n",
    "                    grasp_coordinate_frame.transform(graps_transform)\n",
    "                    # o3d.visualization.draw_geometries([grasp_coordinate_frame, deleted_pointcloud, coordinate_frame], window_name=\"Filtered Point Cloud\")\n",
    "                    \n",
    "                    # cube_top_image = point_cloud_to_image(cube_point_cloud_transormed)\n",
    "                    plt.imsave(f\"test_{movecount}.png\", cube_top_image)\n",
    "                    plt.show()\n",
    "                    # o3d.visualization.draw_geometries([coordinate_frame, cube_coordinate_frame, deleted_pointcloud], window_name=\"Transformed Coordinate Frame\")\n",
    "                    \n",
    "                    # print(gpt4o_analysis(f\"test_{movecount}.png\"))\n",
    "                    # return\n",
    "                    # image_recognizer_result = image_recognizer.recognize_image(cube_top_image)\n",
    "                    # image_recognizer.display_results(cube_top_image, image_recognizer_result)\n",
    "                    # return cube_top_image, image_recognizer_result\n",
    "                    # image_recognizer_best_result = image_recognizer.selected_best_based_on_CNN(image_recognizer_result, cube_top_image)\n",
    "                    # img, angle = image_recognizer.get_image_from_result(image_recognizer_best_result) # angle用于在place时候将其转正\n",
    "                    # plt.imshow(img)\n",
    "                    # plt.axis(\"off\")\n",
    "                    # plt.show()\n",
    "                    angle = 0\n",
    "                    \n",
    "                    layer_point_cloud = remaining_pointcloud\n",
    "                    \n",
    "                    # continue\n",
    "                    \n",
    "                    # 3. move \n",
    "#                     # 如果匹配度高，则移动将其移动到指定位置\n",
    "                    # 创建绕x轴旋转180度的4x4变换矩阵\n",
    "                    \n",
    "                    pick_rpy, pick_pos = matrix_to_rpy_and_translation(graps_transform)\n",
    "                    pick_pos_ = [a + b for a, b in zip(pick_pos, [0, 0, 0.10])]\n",
    "                    pick_rpy = [a + b for a, b in zip(pick_rpy, [0, 0, 0])]\n",
    "                    # pick_place.move(pick_pos_, pick_rpy)\n",
    "                    print(\"move_to\", pick_pos_, pick_rpy)\n",
    "            \n",
    "                    pick_pos_ = [a + b for a, b in zip(pick_pos, [0.014, 0.020, 0.12])] # 安全距离\n",
    "                    place_pos = [0.5-0.1*(movecount%4), 0.4-0.1*(movecount//4), 0.15]\n",
    "                    place_rpy = [0, np.pi, -np.pi/4+angle]\n",
    "\n",
    "                    \n",
    "                    # 保持一个安全距离，或者做collision avoidance\n",
    "                    # pick_place.move(pick_pos_, pick_rpy)\n",
    "                    movecount = movecount+1\n",
    "                else:\n",
    "                    cube_point_cloud = cube_mesh.sample_points_uniformly(number_of_points=50000) \n",
    "                    cube_point_cloud = filter_point_cloud_by_depth(cube_point_cloud, depth_threshold=-0.01)\n",
    "                \n",
    "            # 这里debug用，直接return\n",
    "            # return transform, remaining_pointcloud, deleted_pointcloud\n",
    "    print(\"done!\") \n",
    "# T, remaining_pointcloud, deleted_pointcloud = pointcloud_splite_by_layers(filtered_point_cloud, max_layer)\n",
    "# cube_top_image, image_recognizer_result = pointcloud_splite_by_layers(filtered_point_cloud, max_layer)\n",
    "# cube_point_cloud_transormed = pointcloud_splite_by_layers(filtered_point_cloud, max_layer)\n",
    "pointcloud_splite_by_layers(filtered_point_cloud, max_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97a75a1-7a1b-4df9-87e5-f22fc098e059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916923c9-2c36-417b-bb2a-7a07e665e320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1aa9b1-890b-4a21-a656-5c54a75d5c01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8e1942-89b9-460e-8013-c3406e5ec660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f97b18-cf6e-4683-b2b0-b18f61f0c335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84bdaf3-eb89-4acf-aa35-34d10d9ff810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72f5be6-10ab-4a45-9860-f3cdf9737da3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc74575-a184-436e-b10f-6e5cbd701094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
