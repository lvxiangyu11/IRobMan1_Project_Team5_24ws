{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95482eee-ad8f-423f-a497-8990e8ac372a",
   "metadata": {},
   "source": [
    "# 1. record point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb0fd4c1-97e3-4984-a270-edddc5a05230",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Python Path:\n",
      "\n",
      "/opt/ros_ws/devel/lib/python3/dist-packages\n",
      "/opt/ros/noetic/lib/python3/dist-packages\n",
      "/usr/lib/python38.zip\n",
      "/usr/lib/python3.8\n",
      "/usr/lib/python3.8/lib-dynload\n",
      "/opt/ros_ws/irobmanenv/lib/python3.8/site-packages\n",
      "/opt/ros_ws/src/franka_zed_gazebo/scripts/mycode_clean/3_move\n",
      "/opt/ros_ws/src/franka_zed_gazebo/scripts/mycode_clean/1_getPointCloud\n",
      "/opt/ros_ws/irobmanenv/lib/python3.8/site-packages/setuptools/_vendor\n",
      "[INFO] [1742596897.347842, 669.222000]: Waiting for move_group action server...\n",
      "[INFO] [1742596897.605754, 669.226000]: Table added to the scene to prevent collision below z = 0.001\n",
      "\u001b[0m[ INFO] [1742596897.600263585, 669.458000000]: Ready to take commands for planning group panda_manipulator.\u001b[0m\n",
      "[INFO] [1742596897.615286, 669.466000]: Wall 'wall_right' added to the scene with rotation theta=-0.6283185307179586 radians at position: 0.0, 0.8, 0.0\n",
      "[INFO] [1742596897.624432, 669.477000]: Wall 'wall_left' added to the scene with rotation theta=0.6283185307179586 radians at position: 0.0, -0.8, 0.0\n",
      "[INFO] [1742596897.629117, 669.485000]: MoveRobot initialized successfully.\n",
      "[INFO] [1742596897.642997, 669.489000]: Current joint values: [-0.00013074875599183855, -0.7839494710298842, 4.049768720904012e-05, -2.358736779051908, 1.7905211326052495e-05, 1.5713223090023947, 0.7853858548175268]\n",
      "[INFO] [1742596897.648969, 669.506000]: Waiting for gripper action servers...\n",
      "[INFO] [1742596897.650224, 669.507000]: Gripper action servers ready.\n",
      "[INFO] [1742596897.651099, 669.508000]: Restoring to initial joint values...\n",
      "[INFO] [1742596897.900892, 669.740000]: Successfully restored to the initial joint configuration.\n",
      "[INFO] [1742596898.025003, 669.745000]: MoveRobot shut down.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the current working directory (used to replace __file__)\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "target_path1 = os.path.abspath(os.path.join(current_dir, '../3_move'))\n",
    "target_path2 = os.path.abspath(os.path.join(current_dir, '../1_getPointCloud'))\n",
    "\n",
    "# Add the paths to sys.path\n",
    "if target_path1 not in sys.path:\n",
    "    sys.path.append(target_path1)\n",
    "    \n",
    "if target_path2 not in sys.path:\n",
    "    sys.path.append(target_path2)\n",
    "    \n",
    "# Check if the paths were added successfully\n",
    "print(\"Current Python Path:\")\n",
    "print(\"\\n\".join(sys.path))\n",
    "\n",
    "from ImageRecognizer import ImageRecognizer\n",
    "image_recognizer = ImageRecognizer(top_dir=\"/opt/ros_ws/src/franka_zed_gazebo/scripts/mycode_clean/2_perception/cubes/\")\n",
    "\n",
    "from utils import matrix_to_rpy_and_translation\n",
    "\n",
    "from PickAndPlace import PickAndPlace\n",
    "pick_place = PickAndPlace(approach_distance=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c575264-32a4-4fc0-9469-5ce80c9a98fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [1742596910.979215, 682.120000]: Waiting for data...\n",
      "[INFO] [1742596911.196814, 682.299000]: Received image message.\n",
      "[INFO] [1742596911.295750, 682.335000]: Received point cloud data.\n",
      "[INFO] [1742596915.892342, 686.479000]: Color range - Min: [0.10196078 0.10196078 0.10196078], Max: [0.75294118 0.63921569 0.60784314]\n",
      "[INFO] [1742596915.911566, 686.497000]: Requesting transform from world to left_camera_link_optical...\n",
      "[INFO] [1742596915.918164, 686.497000]: Transform found: header: \n",
      "  seq: 0\n",
      "  stamp: \n",
      "    secs: 686\n",
      "    nsecs: 467000000\n",
      "  frame_id: \"world\"\n",
      "child_frame_id: \"left_camera_link_optical\"\n",
      "transform: \n",
      "  translation: \n",
      "    x: 0.20991587728489502\n",
      "    y: -0.05995457173018651\n",
      "    z: 0.5609911284057665\n",
      "  rotation: \n",
      "    x: 0.6590531542888034\n",
      "    y: 0.6591330828003503\n",
      "    z: 0.25611571331347577\n",
      "    w: 0.2561196212202706\n",
      "[INFO] [1742596916.662878, 687.157000]: Transformed point cloud saved to /opt/ros_ws/src/franka_zed_gazebo/scripts/mycode_clean/2_perception/mesh/zed_point_cloud_world3.ply\n"
     ]
    }
   ],
   "source": [
    "from save_point_cloud import PointCloudSaver\n",
    "import open3d as o3d\n",
    "import rospy\n",
    "point_cloud_saver = PointCloudSaver()\n",
    "\n",
    "# Wait for data to be ready\n",
    "rospy.loginfo(\"Waiting for data...\")\n",
    "rospy.sleep(1)  # Wait for topic data to be published\n",
    "\n",
    "# Save the point cloud\n",
    "world_file = \"/opt/ros_ws/src/franka_zed_gazebo/scripts/mycode_clean/2_perception/mesh/zed_point_cloud_world3.ply\"\n",
    "point_cloud_saver.save_point_clouds(world_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ebdb0eb-9e99-4745-88a8-52bfcc7225d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error: XDG_RUNTIME_DIR not set in the environment.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from utils import filter_point_cloud_by_depth_and_range, filter_point_cloud_by_depth\n",
    "\n",
    "# zed_ply_path = \"mesh/zed_point_cloud_world3.ply\"\n",
    "zed_ply_path = \"/opt/ros_ws/src/franka_zed_gazebo/scripts/mycode_clean/2_perception/mesh/zed_point_cloud_world3.ply\"\n",
    "\n",
    "coordinate_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "    size=0.1,  # Size of the coordinate axes, can be adjusted as needed\n",
    "    origin=[0, 0, 0]  # Origin of the coordinate axes\n",
    ")\n",
    "\n",
    "# Read the point cloud file\n",
    "point_cloud = o3d.io.read_point_cloud(zed_ply_path)\n",
    "if not point_cloud.has_points():\n",
    "    raise ValueError(f\"Failed to read point cloud from {zed_ply_path}\")\n",
    "filtered_point_cloud = filter_point_cloud_by_depth_and_range(point_cloud, depth_threshold=0.02, range=[0.001, -0.8, 1, 1.6])\n",
    "o3d.visualization.draw_geometries([filtered_point_cloud, coordinate_frame], window_name=\"Filtered Point Cloud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9883e9d-4bce-412e-ad0a-224f0121b514",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from utils import calculate_max_layer\n",
    "\n",
    "# # Example usage\n",
    "# max_layer = calculate_max_layer(filtered_point_cloud, layer_height=0.04)\n",
    "# print(f\"MaxLayer: {max_layer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d5b48e-3edb-4683-a774-6ef27ecad23b",
   "metadata": {},
   "source": [
    "# 2. Perception"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f7d2ab-d25d-4387-ac97-81de3ec741dd",
   "metadata": {},
   "source": [
    "## 2.1 Coarse and Fine registration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88fe104e-b675-4313-93a1-417cdc00c8cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "def register_and_filter(pointcloud, mesh, voxel_size=0.01):\n",
    "    # Convert mesh to point cloud\n",
    "    if isinstance(mesh, o3d.geometry.TriangleMesh):\n",
    "        mesh_pointcloud = mesh.sample_points_uniformly(number_of_points=1000)\n",
    "    elif isinstance(mesh, o3d.geometry.PointCloud):\n",
    "        mesh_pointcloud = copy.deepcopy(mesh)\n",
    "    \n",
    "    # Downsample the point cloud and compute features\n",
    "    def preprocess_point_cloud(pcd, voxel_size):\n",
    "        pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "        pcd_down.estimate_normals(\n",
    "            search_param=o3d.geometry.KDTreeSearchParamHybrid(\n",
    "                radius=voxel_size*2, \n",
    "                max_nn=30\n",
    "            )\n",
    "        )\n",
    "        pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "            pcd_down,\n",
    "            search_param=o3d.geometry.KDTreeSearchParamHybrid(\n",
    "                radius=voxel_size*5, \n",
    "                max_nn=100\n",
    "            )\n",
    "        )\n",
    "        return pcd_down, pcd_fpfh\n",
    "\n",
    "    # Coarse registration\n",
    "    def execute_global_registration(source_down, target_down, source_fpfh, target_fpfh, voxel_size):\n",
    "        distance_threshold = voxel_size * 1.5\n",
    "        result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "            source_down, target_down, source_fpfh, target_fpfh, True,\n",
    "            distance_threshold,\n",
    "            o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "            4,\n",
    "            [\n",
    "                o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "                o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "            ],\n",
    "            o3d.pipelines.registration.RANSACConvergenceCriteria(4000000, 500)\n",
    "        )\n",
    "        return result\n",
    "\n",
    "    # Fine registration\n",
    "    def refine_registration(source, target, initial_transformation, voxel_size):\n",
    "        distance_threshold = voxel_size * 1  # Reduce the threshold for higher accuracy\n",
    "        result = o3d.pipelines.registration.registration_icp(\n",
    "            source, target, distance_threshold, initial_transformation,\n",
    "            o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "            o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=1000000)\n",
    "        )\n",
    "        return result\n",
    "\n",
    "    # Execute point cloud preprocessing\n",
    "    source_down, source_fpfh = preprocess_point_cloud(mesh_pointcloud, voxel_size)\n",
    "    target_down, target_fpfh = preprocess_point_cloud(pointcloud, voxel_size)\n",
    "\n",
    "    # Execute registration\n",
    "    coarse_result = execute_global_registration(source_down, target_down, source_fpfh, target_fpfh, voxel_size)\n",
    "    refined_result = refine_registration(mesh_pointcloud, pointcloud, coarse_result.transformation, voxel_size)\n",
    "\n",
    "    # Transform the mesh point cloud\n",
    "    transform = refined_result.transformation\n",
    "    transformed_mesh_pointcloud = mesh_pointcloud.transform(transform)\n",
    "\n",
    "    # Create bounding box\n",
    "    oriented_bounding_box = transformed_mesh_pointcloud.get_oriented_bounding_box()\n",
    "    center = oriented_bounding_box.center\n",
    "    extent = oriented_bounding_box.extent\n",
    "    rotation_matrix = oriented_bounding_box.R\n",
    "\n",
    "    # Expand the bounding box\n",
    "    margin = voxel_size\n",
    "    expanded_extent = extent + 0.5 * margin\n",
    "    expanded_bounding_box = o3d.geometry.OrientedBoundingBox(\n",
    "        center=center,\n",
    "        extent=expanded_extent,\n",
    "        R=rotation_matrix\n",
    "    )\n",
    "\n",
    "    # Filter the point cloud\n",
    "    indices_inside_box = expanded_bounding_box.get_point_indices_within_bounding_box(pointcloud.points)\n",
    "    indices_outside_box = list(set(range(len(pointcloud.points))) - set(indices_inside_box))\n",
    "\n",
    "    # Separate the point cloud\n",
    "    remaining_pointcloud = pointcloud.select_by_index(indices_outside_box)\n",
    "    deleted_pointcloud = pointcloud.select_by_index(indices_inside_box)\n",
    "\n",
    "    return transform, remaining_pointcloud, deleted_pointcloud, refined_result.fitness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97050aea-fb60-4b73-b5ee-14d1b5891787",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the cube\n",
    "# Define file paths\n",
    "cube_obj_path = \"mesh/cube_0.obj\"\n",
    "zed_ply_path = \"mesh/zed_point_cloud_world3.ply\"\n",
    "\n",
    "# Read the cube_0.obj mesh\n",
    "cube_mesh = o3d.io.read_triangle_mesh(cube_obj_path)\n",
    "cube_mesh.compute_vertex_normals()  # Compute normals for better visualization\n",
    "# cube_point_cloud = cube_mesh.sample_points_uniformly(number_of_points=50000)  # Convert to point cloud\n",
    "# cube_point_cloud = cube_mesh.sample_points_poisson_disk(number_of_points=1000)\n",
    "\n",
    "# Remove the lower part of the cube to prevent flipping along the z-axis\n",
    "# cube_point_cloud = filter_point_cloud_by_depth(cube_point_cloud, depth_threshold=-0.015)\n",
    "# o3d.visualization.draw_geometries([cube_point_cloud])\n",
    "\n",
    "\n",
    "coordinate_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "    size=0.1,  # Size of the coordinate axes, can be adjusted as needed\n",
    "    origin=[0, 0, 0]  # Origin of the coordinate axes\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54f3fe34-f397-4e76-8452-b24a6cf4e9f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_transform_z_axis_alignment(transform, tolerance=0.1):\n",
    "    \"\"\"\n",
    "    Check if the Z-axis of the transform is parallel to the Z-axis of the world coordinate system.\n",
    "    Allows a certain tolerance range to check if it is parallel or anti-parallel.\n",
    "    \n",
    "    Args:\n",
    "    - transform: 4x4 transformation matrix\n",
    "    - tolerance: Tolerance range for checking, default is 0.1\n",
    "    \n",
    "    Returns:\n",
    "    - True: If the Z-axis is parallel or anti-parallel\n",
    "    - False: If the Z-axis is not parallel\n",
    "    - The corrected transform\n",
    "    \"\"\"\n",
    "    z_axis = np.array([0, 0, 1])  # Z-axis of the world coordinate system\n",
    "    transform_z_axis = transform[:3, 2]  # Get the Z-axis of the transform (i.e., the third column of the rotation matrix)\n",
    "\n",
    "    # Compute the angle between the transform's Z-axis and the world coordinate system's Z-axis\n",
    "    dot_product = np.dot(transform_z_axis, z_axis)\n",
    "    # Compute the cosine of the angle, if close to 1 or -1, it means parallel or anti-parallel\n",
    "    if np.abs(dot_product) > (1 - tolerance):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def align_transform_z_axis(transform):\n",
    "    \"\"\"\n",
    "    If the Z-axis of the transform is anti-parallel to the Z-axis of the world coordinate system,\n",
    "    rotate by 180 degrees around the X-axis (np.pi) to flip the direction of the Z-axis.\n",
    "    \n",
    "    Args:\n",
    "    - transform: 4x4 transformation matrix\n",
    "    \n",
    "    Returns:\n",
    "    - The corrected transform matrix\n",
    "    \"\"\"\n",
    "    z_axis_world = np.array([0, 0, 1])  # Z-axis of the world coordinate system\n",
    "    transform_z_axis = transform[:3, 2]  # Get the Z-axis of the transform (the third column of the rotation matrix)\n",
    "\n",
    "    # Check if the Z-axis is anti-parallel to the world coordinate system's Z-axis\n",
    "    if np.dot(transform_z_axis, z_axis_world) < 0:  # Z-axis is anti-parallel\n",
    "        print(\"Correcting Z axis\")\n",
    "        # Create a rotation matrix to rotate 180 degrees around the X-axis\n",
    "        rotation_matrix = np.eye(4)\n",
    "        rotation_matrix[1, 1] = -1  # Rotate the matrix by 180 degrees around the X-axis\n",
    "        rotation_matrix[2, 2] = -1  # Rotate the matrix by 180 degrees around the X-axis\n",
    "        \n",
    "        # Perform matrix multiplication, applying the rotation matrix to the original transform\n",
    "        transform = np.dot(rotation_matrix, transform)\n",
    "\n",
    "    return transform\n",
    "\n",
    "def align_transform_z_axis_any_orientation(transform):\n",
    "    \"\"\"\n",
    "    Aligns the Z-axis of the transform with the negative Z-axis of the world coordinate system,\n",
    "    no matter what the original orientation is.\n",
    "    \n",
    "    Args:\n",
    "    - transform: 4x4 transformation matrix\n",
    "    \n",
    "    Returns:\n",
    "    - The corrected transform matrix with Z-axis pointing downward\n",
    "    \"\"\"\n",
    "    # Extract the original rotation matrix and translation vector\n",
    "    rotation = transform[:3, :3]\n",
    "    translation = transform[:3, 3]\n",
    "    \n",
    "    # Extract the current z-axis direction (third column of rotation matrix)\n",
    "    current_z = rotation[:, 2]\n",
    "    \n",
    "    # Target z-axis direction (downward in world coordinates)\n",
    "    target_z = np.array([0, 0, -1])\n",
    "    \n",
    "    # Check if already aligned within a small tolerance\n",
    "    if np.allclose(current_z, target_z, atol=1e-6):\n",
    "        return transform\n",
    "    \n",
    "    # For completely anti-aligned case (pointing directly up), simple 180° rotation works\n",
    "    if np.allclose(current_z, -target_z, atol=1e-6):\n",
    "        # Rotate 180 degrees around x-axis\n",
    "        r = np.eye(3)\n",
    "        r[1, 1] = -1\n",
    "        r[2, 2] = -1\n",
    "        new_rotation = rotation @ r\n",
    "    else:\n",
    "        # For any other orientation, we need to find the rotation that aligns vectors\n",
    "        # Compute the rotation axis (cross product of current and target z-axes)\n",
    "        rotation_axis = np.cross(current_z, target_z)\n",
    "        \n",
    "        # If current_z and target_z are parallel or anti-parallel, rotation_axis might be zero\n",
    "        # In that case, choose any perpendicular axis\n",
    "        if np.allclose(rotation_axis, 0, atol=1e-10):\n",
    "            # Find a non-zero component in current_z\n",
    "            if abs(current_z[0]) > 1e-10:\n",
    "                rotation_axis = np.array([current_z[1], -current_z[0], 0])\n",
    "            else:\n",
    "                rotation_axis = np.array([0, current_z[2], -current_z[1]])\n",
    "        \n",
    "        # Normalize the rotation axis\n",
    "        rotation_axis = rotation_axis / np.linalg.norm(rotation_axis)\n",
    "        \n",
    "        # Compute the rotation angle (dot product gives cosine of angle)\n",
    "        # We want the shorter arc between the vectors\n",
    "        cos_angle = np.dot(current_z, target_z)\n",
    "        angle = np.arccos(np.clip(cos_angle, -1.0, 1.0))\n",
    "        \n",
    "        # Rodrigues' rotation formula to get rotation matrix\n",
    "        K = np.array([\n",
    "            [0, -rotation_axis[2], rotation_axis[1]],\n",
    "            [rotation_axis[2], 0, -rotation_axis[0]],\n",
    "            [-rotation_axis[1], rotation_axis[0], 0]\n",
    "        ])\n",
    "        R = np.eye(3) + np.sin(angle) * K + (1 - np.cos(angle)) * (K @ K)\n",
    "        \n",
    "        # Apply the rotation to the original rotation matrix\n",
    "        new_rotation = rotation @ R\n",
    "    \n",
    "    # Create the new transformation matrix\n",
    "    new_transform = np.eye(4)\n",
    "    new_transform[:3, :3] = new_rotation\n",
    "    new_transform[:3, 3] = translation\n",
    "    \n",
    "    # Validate the result\n",
    "    result_z = new_transform[:3, :3][:, 2]\n",
    "    alignment_quality = np.dot(result_z, target_z)\n",
    "    print(f\"Z-axis alignment quality: {alignment_quality:.6f} (closer to 1 is better)\")\n",
    "    \n",
    "    return new_transform\n",
    "\n",
    "def align_transform_z_axis_preserving_xy(transform):\n",
    "    \"\"\"\n",
    "    Align the Z-axis of the transformation matrix to point downward (world -Z axis),\n",
    "    while preserving the original XY plane orientation as much as possible.\n",
    "\n",
    "    This function ensures:\n",
    "    1. The Z-axis points downward (aligned with the world -Z axis)\n",
    "    2. The XY plane is preserved as much as possible to minimize disruption to the original grasp direction\n",
    "\n",
    "    Args:\n",
    "        transform: A 4x4 transformation matrix\n",
    "\n",
    "    Returns:\n",
    "        A corrected transformation matrix with the Z-axis pointing downward and XY directions as close as possible to the original\n",
    "    \"\"\"\n",
    "    # Extract the original rotation matrix and translation vector\n",
    "    rotation = transform[:3, :3]\n",
    "    translation = transform[:3, 3]\n",
    "\n",
    "    # Extract current axes directions from the rotation matrix\n",
    "    x_axis = rotation[:, 0]  # X-axis is the first column\n",
    "    y_axis = rotation[:, 1]  # Y-axis is the second column\n",
    "    z_axis = rotation[:, 2]  # Z-axis is the third column\n",
    "\n",
    "    # Target direction for Z-axis (world -Z direction)\n",
    "    target_z = np.array([0, 0, -1])\n",
    "\n",
    "    # Check if the current Z-axis is already aligned with the target\n",
    "    aligned = np.isclose(np.abs(np.dot(z_axis, target_z)), 1.0, atol=1e-6)\n",
    "    if aligned and np.dot(z_axis, target_z) > 0:\n",
    "        # Already aligned, no changes needed\n",
    "        return transform\n",
    "\n",
    "    # Set new Z-axis to point down\n",
    "    new_z = target_z\n",
    "\n",
    "    # Compute a new X-axis that is orthogonal to the new Z-axis\n",
    "    # Do this by projecting the original X-axis onto the plane perpendicular to new Z\n",
    "\n",
    "    new_x = x_axis - np.dot(x_axis, new_z) * new_z\n",
    "\n",
    "    # If the projection is too small (i.e., X was almost aligned with Z), try using original Y\n",
    "    if np.linalg.norm(new_x) < 1e-6:\n",
    "        new_x = y_axis - np.dot(y_axis, new_z) * new_z\n",
    "\n",
    "    # If still too small, pick an arbitrary vector that's not parallel to Z\n",
    "    if np.linalg.norm(new_x) < 1e-6:\n",
    "        temp = np.array([1, 0, 0]) if abs(new_z[0]) < 0.9 else np.array([0, 1, 0])\n",
    "        new_x = temp - np.dot(temp, new_z) * new_z\n",
    "\n",
    "    # Normalize the new X-axis\n",
    "    new_x = new_x / np.linalg.norm(new_x)\n",
    "\n",
    "    # Calculate the new Y-axis using the cross product (ensures orthogonality)\n",
    "    new_y = np.cross(new_z, new_x)\n",
    "\n",
    "    # Construct the new rotation matrix from the orthonormal axes\n",
    "    new_rotation = np.column_stack((new_x, new_y, new_z))\n",
    "\n",
    "    # Assemble the final transformation matrix\n",
    "    new_transform = np.eye(4)\n",
    "    new_transform[:3, :3] = new_rotation\n",
    "    new_transform[:3, 3] = translation\n",
    "\n",
    "    # Evaluate alignment quality of the new Z-axis\n",
    "    result_z = new_transform[:3, :3][:, 2]\n",
    "    alignment_quality = np.dot(result_z, target_z)\n",
    "    print(f\"Z-axis alignment quality: {alignment_quality:.6f} (closer to 1 is better)\")\n",
    "\n",
    "    # Evaluate how well the XY plane orientation is preserved\n",
    "    original_xy_normal = np.cross(x_axis, y_axis)\n",
    "    original_xy_normal = original_xy_normal / np.linalg.norm(original_xy_normal)\n",
    "\n",
    "    new_xy_normal = np.cross(new_x, new_y)\n",
    "    new_xy_normal = new_xy_normal / np.linalg.norm(new_xy_normal)\n",
    "\n",
    "    xy_preservation = np.abs(np.dot(original_xy_normal, new_xy_normal))\n",
    "    print(f\"XY plane preservation quality: {xy_preservation:.6f} (closer to 1 is better)\")\n",
    "\n",
    "    return new_transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76d4d048-43c7-4a8a-ba1b-9c8e9fadcfa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import rospy\n",
    "import tf\n",
    "import numpy as np\n",
    "from geometry_msgs.msg import TransformStamped\n",
    "\n",
    "class TransformBroadcaster:\n",
    "    def __init__(self):\n",
    "        # Try to initialize the ROS node, avoid initializing multiple times\n",
    "        try:\n",
    "            rospy.init_node('tf_broadcaster_node')\n",
    "        except rospy.exceptions.ROSException:\n",
    "            pass  # If the node is already initialized, do nothing\n",
    "\n",
    "        # Create a TransformBroadcaster instance\n",
    "        self.br = tf.TransformBroadcaster()\n",
    "\n",
    "        # Assume T is the given 4x4 transformation matrix\n",
    "        self.T = np.ones((4, 4))  # Set to a 4x4 matrix\n",
    "\n",
    "        # Set a timer to call the broadcast_transform function every 100 milliseconds\n",
    "        self.timer = rospy.Timer(rospy.Duration(0.1), self.broadcast_transform)\n",
    "\n",
    "        # Store the timestamp of the last sent transformation\n",
    "        self.last_sent_time = None\n",
    "\n",
    "    def broadcast_transform(self, event):\n",
    "        try:\n",
    "            # Extract the translation and rotation parts from the 4x4 matrix\n",
    "            translation = self.T[0:3, 3]  # Translation part (x, y, z)\n",
    "            rotation_matrix = self.T[0:3, 0:3]  # Rotation matrix part\n",
    "\n",
    "            # Create a complete 4x4 matrix, including rotation and homogeneous coordinates\n",
    "            full_matrix = np.eye(4)\n",
    "            full_matrix[0:3, 0:3] = rotation_matrix\n",
    "            full_matrix[0:3, 3] = translation\n",
    "\n",
    "            # Create a quaternion to represent the rotation\n",
    "            quaternion = tf.transformations.quaternion_from_matrix(full_matrix)\n",
    "\n",
    "            # Get the current timestamp\n",
    "            current_time = rospy.Time.now()\n",
    "\n",
    "            # Check if the last sent timestamp and the current timestamp are the same\n",
    "            if self.last_sent_time is None or current_time != self.last_sent_time:\n",
    "                # Publish the transformation\n",
    "                self.br.sendTransform(\n",
    "                    (translation[0], translation[1], translation[2]),  # Translation part\n",
    "                    (quaternion[0], quaternion[1], quaternion[2], quaternion[3]),  # Rotation part (quaternion)\n",
    "                    current_time,  # Use the current timestamp\n",
    "                    \"cube\",  # Child frame name\n",
    "                    \"world\"   # Parent frame name\n",
    "                )\n",
    "                # Update the last sent timestamp\n",
    "                self.last_sent_time = current_time\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def update(self, T):\n",
    "        self.T = T\n",
    "        \n",
    "    def stop(self):\n",
    "        # Stop the timer\n",
    "        self.timer.shutdown()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4cef69-b1d4-40d5-92e0-ad3c6f59fc93",
   "metadata": {},
   "source": [
    "## 2.2 Grasp Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "155cbbb8-ad8b-4146-a453-4cdaf9afbad5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import *  # Assuming the create_grasp_mesh function is in utils.py\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "def generate_gripper_from_transform(T: np.ndarray):\n",
    "    \"\"\"\n",
    "    Generates a robotic gripper mesh from a given 4x4 transformation matrix,\n",
    "    with additional rotations around x and y axes.\n",
    "\n",
    "    Args:\n",
    "        T: 4x4 transformation matrix (numpy array).\n",
    "        \n",
    "    Returns:\n",
    "        gripper_meshes: List of meshes representing the gripper.\n",
    "    \"\"\"\n",
    "    # Extract the rotation matrix (3x3)\n",
    "    rotation_matrix = T[:3, :3]\n",
    "\n",
    "    # Extract the translation vector\n",
    "    translation = T[:3, 3]\n",
    "\n",
    "    # Set the gripper's center point position, usually the translation vector\n",
    "    center_point = translation\n",
    "\n",
    "    # Create a rotation matrix for -90 degrees around the x-axis\n",
    "    R_x = np.array([\n",
    "        [1, 0, 0],\n",
    "        [0, np.cos(-np.pi/2), -np.sin(-np.pi/2)],\n",
    "        [0, np.sin(-np.pi/2), np.cos(-np.pi/2)]\n",
    "    ])\n",
    "\n",
    "    # Create a rotation matrix for 90 degrees around the y-axis\n",
    "    R_y = np.array([\n",
    "        [np.cos(np.pi/2), 0, np.sin(np.pi/2)],\n",
    "        [0, 1, 0],\n",
    "        [-np.sin(np.pi/2), 0, np.cos(np.pi/2)]\n",
    "    ])\n",
    "    \n",
    "    R_z = np.array([\n",
    "        [0, -1, 0],\n",
    "        [1, 0, 0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    # Combine rotation matrices, first rotate around the x-axis, then around the y-axis\n",
    "    combined_rotation = R_z @ rotation_matrix @ R_x \n",
    "\n",
    "    # Call create_grasp_mesh function to generate the gripper\n",
    "    gripper_meshes = create_grasp_mesh(\n",
    "        center_point=center_point, \n",
    "        rotation_matrix=combined_rotation,\n",
    "        width=0.25\n",
    "    )\n",
    "    # Call create_grasp_mesh function to generate the gripper with a different rotation\n",
    "    gripper_meshes_rotate = create_grasp_mesh(\n",
    "        center_point=center_point, \n",
    "        rotation_matrix=rotation_matrix @ R_x,\n",
    "        width=0.25\n",
    "    )\n",
    "\n",
    "    return gripper_meshes, gripper_meshes_rotate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47315293-9f5e-4dd0-a1aa-9efab7885c1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error: XDG_RUNTIME_DIR not set in the environment.\n"
     ]
    }
   ],
   "source": [
    "# Test code: Pass in a 4x4 transformation matrix\n",
    "T = np.array([\n",
    "    [1, 0, 0, 0.1],  # Rotation matrix and translation\n",
    "    [0, 1, 0, 0.2],\n",
    "    [0, 0, 1, 0.3],\n",
    "    [0, 0, 0, 1]\n",
    "])\n",
    "\n",
    "# Call the function to generate the gripper\n",
    "gripper_meshes, _ = generate_gripper_from_transform(T)\n",
    "\n",
    "# Visualize the generated gripper\n",
    "o3d.visualization.draw_geometries(gripper_meshes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8067b9a2-8d15-4f9e-9842-e1d6815c3d34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_grasp_collision(\n",
    "    grasp_meshes: Sequence[o3d.geometry.TriangleMesh],\n",
    "    object_pcd: o3d.geometry.TriangleMesh,\n",
    "    num_colisions: int = 10,\n",
    "    tolerance: float = 0.00001\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Checks for collisions between a gripper grasp pose and target object\n",
    "    using point cloud sampling.\n",
    "\n",
    "    Args:\n",
    "        grasp_meshes: List of mesh geometries representing the gripper components\n",
    "        object_mesh: Triangle mesh of the target object\n",
    "        num_collisions: Threshold on how many points to check\n",
    "        tolerance: Distance threshold for considering a collision (in meters)\n",
    "\n",
    "    Returns:\n",
    "        bool: True if collision detected between gripper and object, False otherwise\n",
    "    \"\"\"\n",
    "    # Combine gripper meshes\n",
    "    combined_gripper = o3d.geometry.TriangleMesh()\n",
    "    for mesh in grasp_meshes:\n",
    "        combined_gripper += mesh  # Combine multiple gripper meshes\n",
    "\n",
    "    # Sample points from both meshes\n",
    "    num_points = 5000  # Sample 5000 points from both gripper and target object\n",
    "    #######################TODO#######################\n",
    "    # Uniformly sample point clouds from both the gripper and object meshes\n",
    "    gripper_pcd = combined_gripper.sample_points_uniformly(number_of_points=num_points)\n",
    "    gripper_points = np.asarray(gripper_pcd.points)  # Point coordinates of the gripper point cloud\n",
    "    object_points = np.asarray(object_pcd.points)  # Point coordinates of the target object point cloud\n",
    "    ##################################################\n",
    "    \n",
    "    # Build KDTree for object points\n",
    "    is_collision = False\n",
    "    #######################TODO#######################\n",
    "    collision_count = 0\n",
    "    # Build a KDTree for the target object point cloud\n",
    "    object_kdtree = o3d.geometry.KDTreeFlann(object_pcd)\n",
    "    for gripper_point in gripper_points:\n",
    "        # For each gripper point, find the nearest point in the target object point cloud\n",
    "        _, _, distances = object_kdtree.search_knn_vector_3d(gripper_point, 1)  # Find the nearest neighbor\n",
    "        \n",
    "        # If the distance to the nearest neighbor is less than the tolerance, consider it a collision\n",
    "        if distances[0] <= tolerance:\n",
    "            collision_count += 1\n",
    "            \n",
    "            # Exit early if enough collisions are detected\n",
    "            if collision_count >= num_colisions:\n",
    "                is_collision = True\n",
    "                break\n",
    "    #######################TODO#######################\n",
    "\n",
    "    return is_collision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed7a038-40aa-4a06-a50d-9abae0aba06f",
   "metadata": {},
   "source": [
    "## 2.3 identify image of cubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9fcf074-462c-450a-921d-b9589f4b627f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "# from io import BytesIO\n",
    "# from PIL import Image\n",
    "# import base64\n",
    "# import json\n",
    "# SYSTEM_PROMPT = \"\"\"Please act as an image recognition agent. \n",
    "# You will be given a square face of a block, \n",
    "# which is projected from a point cloud. \n",
    "# Your task is to recognize the following:\n",
    "\n",
    "# Determine if this is a block face.\n",
    "# Each face contains only one letter, \n",
    "# one pattern (just detect whether it's a pattern, no need to identify the exact pattern), \n",
    "# or is blank (only wood texture). \n",
    "# Please detect whether it is a letter, \n",
    "# a pattern, or blank. \n",
    "# Each of these may be rotated. \n",
    "# Please analyze all possible rotations in a clockwise direction: 0°, 90°, 180°, and 270°.\n",
    "# There might be a circular border around the face. \n",
    "# Please detect if this border exists. \n",
    "# It's confirmed that the color of the border matches the color of the letter or pattern.\n",
    "# The expected output is a JSON in the following format:\n",
    "# {\n",
    "#     \"check\": true/false, \n",
    "#     \"c\": char/\"pattern\"/\"blank\", \n",
    "#     \"color\": \"green\"/\"yellow\"/\"red\"/\"blue\"/\"None\", \n",
    "#     \"rotation\": 0/90/180/270, \n",
    "#     \"circle\": true/false\n",
    "# }\n",
    "# \"\"\"\n",
    "\n",
    "# api_key=\"\"\n",
    "# client = OpenAI(api_key=api_key)\n",
    "\n",
    "# def encode_image(image, quality=100):\n",
    "#     if image.mode != 'RGB':\n",
    "#         image = image.convert('RGB')  # Convert to RGB\n",
    "#     buffered = BytesIO()\n",
    "#     image.save(buffered, format=\"JPEG\", quality=quality) \n",
    "#     return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "# def gpt4o_analysis(image_path, quality=50):\n",
    "#     with Image.open(image_path) as img:\n",
    "#         img_b64_str = encode_image(img, quality=quality)\n",
    "#     img_type = \"image/jpeg\"\n",
    "#     response = client.chat.completions.create(\n",
    "#         model=\"gpt-4o-mini\",\n",
    "#         messages=[\n",
    "#             {\n",
    "#                 \"role\": \"user\",\n",
    "#                 \"content\": [\n",
    "#                     {\"type\": \"text\", \"text\": SYSTEM_PROMPT},\n",
    "#                     {\n",
    "#                         \"type\": \"image_url\",\n",
    "#                         \"image_url\": {\"url\": f\"data:{img_type};base64,{img_b64_str}\"},\n",
    "#                     },\n",
    "#                 ],\n",
    "#             }from openai import OpenAI\n",
    "# from io import BytesIO\n",
    "# from PIL import Image\n",
    "# import base64\n",
    "# import json\n",
    "# SYSTEM_PROMPT = \"\"\"Please act as an image recognition agent. \n",
    "# You will be given a square face of a block, \n",
    "# which is projected from a point cloud. \n",
    "# Your task is to recognize the following:\n",
    "\n",
    "# Determine if this is a block face.\n",
    "# Each face contains only one letter, \n",
    "# one pattern (just detect whether it's a pattern, no need to identify the exact pattern), \n",
    "# or is blank (only wood texture). \n",
    "# Please detect whether it is a letter, \n",
    "# a pattern, or blank. \n",
    "# Each of these may be rotated. \n",
    "# Please analyze all possible rotations in a clockwise direction: 0°, 90°, 180°, and 270°.\n",
    "# There might be a circular border around the face. \n",
    "# Please detect if this border exists. \n",
    "# It's confirmed that the color of the border matches the color of the letter or pattern.\n",
    "# The expected output is a JSON in the following format:\n",
    "# {\n",
    "#     \"check\": true/false, \n",
    "#     \"c\": char/\"pattern\"/\"blank\", \n",
    "#     \"color\": \"green\"/\"yellow\"/\"red\"/\"blue\"/\"None\", \n",
    "#     \"rotation\": 0/90/180/270, \n",
    "#     \"circle\": true/false\n",
    "# }\n",
    "# \"\"\"\n",
    "\n",
    "# api_key=\"\"\n",
    "# client = OpenAI(api_key=api_key)\n",
    "\n",
    "# def encode_image(image, quality=100):\n",
    "#     if image.mode != 'RGB':\n",
    "#         image = image.convert('RGB')  # Convert to RGB\n",
    "#     buffered = BytesIO()\n",
    "#     image.save(buffered, format=\"JPEG\", quality=quality) \n",
    "#     return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "# def gpt4o_analysis(image_path, quality=50):\n",
    "#     with Image.open(image_path) as img:\n",
    "#         img_b64_str = encode_image(img, quality=quality)\n",
    "#     img_type = \"image/jpeg\"\n",
    "#     response = client.chat.completions.create(\n",
    "#         model=\"gpt-4o-mini\",\n",
    "#         messages=[\n",
    "#             {\n",
    "#                 \"role\": \"user\",\n",
    "#                 \"content\": [\n",
    "#                     {\"type\": \"text\", \"text\": SYSTEM_PROMPT},\n",
    "#                     {\n",
    "#                         \"type\": \"image_url\",\n",
    "#                         \"image_url\": {\"url\": f\"data:{img_type};base64,{img_b64_str}\"},\n",
    "#                     },\n",
    "#                 ],\n",
    "#             }\n",
    "#         ],\n",
    "#     )\n",
    "#     return response.choices[0].message.content\n",
    "#         ],\n",
    "#     )\n",
    "#     return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348b83d4-ff09-4bbd-a7f0-b5a606c423ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代 1: 拟合度 = 0.8412, 剩余点数: 19106\n",
      "处理立方体 #1\n",
      "Z-axis alignment quality: 1.000000 (closer to 1 is better)\n",
      "XY plane preservation quality: 0.998749 (closer to 1 is better)\n",
      "使用标准抓取方向\n",
      "立方体 #1 抓取位置: [0.5289837279170989, -0.010098020185695014, 0.024541929567309734]\n",
      "接近位置: [0.5289837279170989, -0.010098020185695014, 0.12454192956730974]\n",
      "RPY方向: [0.0, 0.0, 0.33864135392116157]\n",
      "抓取变换矩阵:\n",
      "[[ 0.94320689 -0.33220591  0.          0.52898373]\n",
      " [ 0.33220591  0.94320689  0.         -0.01009802]\n",
      " [ 0.          0.          1.          0.02454193]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "迭代 1: 拟合度 = 0.8199, 剩余点数: 16676\n",
      "处理立方体 #2\n",
      "Z-axis alignment quality: 1.000000 (closer to 1 is better)\n",
      "XY plane preservation quality: 0.998788 (closer to 1 is better)\n",
      "使用标准抓取方向\n",
      "立方体 #2 抓取位置: [0.4970921171222455, 0.30115411737378356, 0.02445701548324259]\n",
      "接近位置: [0.4970921171222455, 0.30115411737378356, 0.12445701548324259]\n",
      "RPY方向: [0.0, 0.0, 0.5710685147446949]\n",
      "抓取变换矩阵:\n",
      "[[ 0.84132389 -0.54053132  0.          0.49709212]\n",
      " [ 0.54053132  0.84132389  0.          0.30115412]\n",
      " [ 0.          0.          1.          0.02445702]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "迭代 1: 拟合度 = 0.8086, 剩余点数: 13817\n",
      "处理立方体 #3\n",
      "Z-axis alignment quality: 1.000000 (closer to 1 is better)\n",
      "XY plane preservation quality: 0.999285 (closer to 1 is better)\n",
      "使用标准抓取方向\n",
      "立方体 #3 抓取位置: [0.3936141102195277, 0.1118674722427118, 0.024750046723177994]\n",
      "接近位置: [0.3936141102195277, 0.1118674722427118, 0.12475004672317799]\n",
      "RPY方向: [0.0, 0.0, 0.6429928816452974]\n",
      "抓取变换矩阵:\n",
      "[[ 0.80030483 -0.59959334  0.          0.39361411]\n",
      " [ 0.59959334  0.80030483  0.          0.11186747]\n",
      " [ 0.          0.          1.          0.02475005]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "迭代 1: 拟合度 = 0.7068, 剩余点数: 12153\n",
      "处理立方体 #4\n",
      "Z-axis alignment quality: 1.000000 (closer to 1 is better)\n",
      "XY plane preservation quality: 0.999583 (closer to 1 is better)\n",
      "两种抓取方向都有碰撞，跳过此立方体\n",
      "迭代 2: 拟合度 = 0.8314, 剩余点数: 10165\n",
      "处理立方体 #4\n",
      "Z-axis alignment quality: 1.000000 (closer to 1 is better)\n",
      "XY plane preservation quality: 0.998894 (closer to 1 is better)\n",
      "使用标准抓取方向\n",
      "立方体 #4 抓取位置: [0.5297413973621702, -0.1113384582518187, 0.024657398194206277]\n",
      "接近位置: [0.5297413973621702, -0.1113384582518187, 0.12465739819420628]\n",
      "RPY方向: [0.0, 0.0, 0.48024438614592585]\n",
      "抓取变换矩阵:\n",
      "[[ 0.88688204 -0.46199593  0.          0.5297414 ]\n",
      " [ 0.46199593  0.88688204  0.         -0.11133846]\n",
      " [ 0.          0.          1.          0.0246574 ]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "迭代 1: 拟合度 = 0.8224, 剩余点数: 7386\n",
      "处理立方体 #5\n",
      "Z-axis alignment quality: 1.000000 (closer to 1 is better)\n",
      "XY plane preservation quality: 0.998731 (closer to 1 is better)\n",
      "使用标准抓取方向\n",
      "立方体 #5 抓取位置: [0.4414129217163664, 0.24818554136715776, 0.02446270518071292]\n",
      "接近位置: [0.4414129217163664, 0.24818554136715776, 0.12446270518071292]\n",
      "RPY方向: [0.0, 0.0, -0.3036735721124885]\n",
      "抓取变换矩阵:\n",
      "[[ 0.95424443  0.2990277   0.          0.44141292]\n",
      " [-0.2990277   0.95424443  0.          0.24818554]\n",
      " [ 0.          0.          1.          0.02446271]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (8) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "迭代 1: 拟合度 = 0.7114, 剩余点数: 5461\n",
      "处理立方体 #6\n",
      "Z-axis alignment quality: 1.000000 (closer to 1 is better)\n",
      "XY plane preservation quality: 0.998882 (closer to 1 is better)\n",
      "使用标准抓取方向\n",
      "立方体 #6 抓取位置: [0.582562865246966, 0.24740725082548695, 0.042583826926776466]\n",
      "接近位置: [0.582562865246966, 0.24740725082548695, 0.14258382692677646]\n",
      "RPY方向: [0.0, 0.0, -2.3186944946043067]\n",
      "抓取变换矩阵:\n",
      "[[-0.68009937  0.73311994  0.          0.58256287]\n",
      " [-0.73311994 -0.68009937  0.          0.24740725]\n",
      " [ 0.          0.          1.          0.04258383]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "迭代 1: 拟合度 = 0.8166, 剩余点数: 4178\n",
      "处理立方体 #7\n",
      "Z-axis alignment quality: 1.000000 (closer to 1 is better)\n",
      "XY plane preservation quality: 0.999285 (closer to 1 is better)\n",
      "使用标准抓取方向\n",
      "立方体 #7 抓取位置: [0.7132432671647235, -0.12897758431427192, 0.024532147149979054]\n",
      "接近位置: [0.7132432671647235, -0.12897758431427192, 0.12453214714997907]\n",
      "RPY方向: [0.0, 0.0, -0.3851767417558013]\n",
      "抓取变换矩阵:\n",
      "[[ 0.92673204  0.37572293  0.          0.71324327]\n",
      " [-0.37572293  0.92673204  0.         -0.12897758]\n",
      " [ 0.          0.          1.          0.02453215]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "迭代 1: 拟合度 = 0.6462, 剩余点数: 2943\n",
      "处理立方体 #8\n",
      "Z-axis alignment quality: 1.000000 (closer to 1 is better)\n",
      "XY plane preservation quality: 0.997977 (closer to 1 is better)\n",
      "两种抓取方向都有碰撞，跳过此立方体\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (2) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "迭代 2: 拟合度 = 0.7821, 剩余点数: 181\n",
      "处理立方体 #8\n",
      "Z-axis alignment quality: 1.000000 (closer to 1 is better)\n",
      "XY plane preservation quality: 0.999843 (closer to 1 is better)\n",
      "使用标准抓取方向\n",
      "立方体 #8 抓取位置: [0.3857049813509023, -0.1180243248029218, 0.024767729416670915]\n",
      "接近位置: [0.3857049813509023, -0.1180243248029218, 0.12476772941667091]\n",
      "RPY方向: [0.0, 0.0, -0.4246896206614637]\n",
      "抓取变换矩阵:\n",
      "[[ 0.91116666  0.41203799  0.          0.38570498]\n",
      " [-0.41203799  0.91116666  0.         -0.11802432]\n",
      " [ 0.          0.          1.          0.02476773]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (1) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "迭代 1: 拟合度 = 0.0288, 剩余点数: 179\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (1) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "迭代 2: 拟合度 = 0.2559, 剩余点数: 20\n",
      "从 2 次迭代中找到 8 个立方体\n",
      "立方体 #1 变换:\n",
      "[[ 0.94320689 -0.33220591  0.          0.52898373]\n",
      " [ 0.33220591  0.94320689  0.         -0.01009802]\n",
      " [ 0.          0.          1.          0.02454193]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "立方体 #2 变换:\n",
      "[[ 0.84132389 -0.54053132  0.          0.49709212]\n",
      " [ 0.54053132  0.84132389  0.          0.30115412]\n",
      " [ 0.          0.          1.          0.02445702]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "立方体 #3 变换:\n",
      "[[ 0.80030483 -0.59959334  0.          0.39361411]\n",
      " [ 0.59959334  0.80030483  0.          0.11186747]\n",
      " [ 0.          0.          1.          0.02475005]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "立方体 #4 变换:\n",
      "[[ 0.88688204 -0.46199593  0.          0.5297414 ]\n",
      " [ 0.46199593  0.88688204  0.         -0.11133846]\n",
      " [ 0.          0.          1.          0.0246574 ]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "立方体 #5 变换:\n",
      "[[ 0.95424443  0.2990277   0.          0.44141292]\n",
      " [-0.2990277   0.95424443  0.          0.24818554]\n",
      " [ 0.          0.          1.          0.02446271]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "立方体 #6 变换:\n",
      "[[-0.68009937  0.73311994  0.          0.58256287]\n",
      " [-0.73311994 -0.68009937  0.          0.24740725]\n",
      " [ 0.          0.          1.          0.04258383]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "立方体 #7 变换:\n",
      "[[ 0.92673204  0.37572293  0.          0.71324327]\n",
      " [-0.37572293  0.92673204  0.         -0.12897758]\n",
      " [ 0.          0.          1.          0.02453215]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "立方体 #8 变换:\n",
      "[[ 0.91116666  0.41203799  0.          0.38570498]\n",
      " [-0.41203799  0.91116666  0.         -0.11802432]\n",
      " [ 0.          0.          1.          0.02476773]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PointCloud2Image import enlarge_points_as_cubes, max_downsample_image, pointcloud_to_top_view_image_color, interpolate_sparse_image, pointcloud_to_colored_image_with_filling, triangle_mesh_to_image\n",
    "\n",
    "try:\n",
    "    broadcaster\n",
    "except NameError:\n",
    "    broadcaster = TransformBroadcaster()           \n",
    "    \n",
    "cube_num = 10\n",
    "# def pointcloud_process(point_cloud, slice_tolerance=0.005):\n",
    "#     '''\n",
    "#         Identify the cubes\n",
    "#         Returns:\n",
    "#             [\n",
    "#                 json,\n",
    "#                 T\n",
    "#             ]\n",
    "#     '''\n",
    "#     orignal_point_cloud = copy.deepcopy(point_cloud)\n",
    "#     T = []\n",
    "#     remaining_pointcloud_count = 10000\n",
    "#     countdown = 50\n",
    "#     # Use open3d to visualize the point cloud\n",
    "#     # o3d.visualization.draw_geometries([layer_point_cloud], window_name=f\"Layer {layer} (Z range: {z_min:.4f} to {z_max:.4f})\")\n",
    "#     movecount = 0\n",
    "#     while remaining_pointcloud_count > 50 and countdown > 0:\n",
    "#         cube_point_cloud = cube_mesh.sample_points_uniformly(number_of_points=50000) \n",
    "#         cube_point_cloud = filter_point_cloud_by_depth(cube_point_cloud, depth_threshold=-0.01)\n",
    "#         transform, remaining_pointcloud, deleted_pointcloud, fitness = register_and_filter(point_cloud, cube_point_cloud)\n",
    "#         remaining_pointcloud_count = len(remaining_pointcloud.points)\n",
    "#         # return transform, remaining_pointcloud, deleted_pointcloud\n",
    "#         if fitness > 0.01:\n",
    "#             countdown = countdown - 1\n",
    "#         print(fitness)\n",
    "#         if check_transform_z_axis_alignment(transform) and fitness > 0.50 and np.array_equal(transform, align_transform_z_axis(transform)):\n",
    "#         # if fitness > 0.70:\n",
    "#             if movecount >= cube_num-1:\n",
    "#                 break\n",
    "#             print(movecount)\n",
    "            \n",
    "\n",
    "#             broadcaster.update(transform)\n",
    "#             cube_coordinate_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "#                 size=0.1,  # Coordinate axis size, can be adjusted as needed\n",
    "#                 origin=[0, 0, 0]  # Origin of the coordinate axis\n",
    "#             )\n",
    "#             theta = np.radians(45)  # Convert angle to radians\n",
    "#             transform_matrix_x_180 = np.array([\n",
    "#                 [1, 0, 0, 0],\n",
    "#                 [0, -1, 0, 0],\n",
    "#                 [0, 0, -1, 0],\n",
    "#                 [0, 0, 0, 1]\n",
    "#             ])\n",
    "#             transform_matrix_z_90 = np.array([\n",
    "#                 [0, -1, 0, 0],\n",
    "#                 [1, 0, 0, 0],\n",
    "#                 [0, 0, 1, 0],\n",
    "#                 [0, 0, 0, 1]\n",
    "#             ])\n",
    "#             graps_transform = transform @ transform_matrix_x_180\n",
    "#             graps_transform_rotate = transform @ transform_matrix_x_180 @ transform_matrix_z_90\n",
    "#                         # o3d.visualization.draw_geometries([coordinate_frame, remaining_pointcloud], window_name=\"remaining_pointcloud\")\n",
    "#             cube_point_cloud_transormed = copy.deepcopy(deleted_pointcloud)\n",
    "#             cube_point_cloud_transormed = cube_point_cloud_transormed.transform(np.linalg.inv(graps_transform))\n",
    "#             cube_point_cloud_transormed_cubes = enlarge_points_as_cubes(cube_point_cloud_transormed)\n",
    "\n",
    "#             cube_top_image = triangle_mesh_to_image(cube_point_cloud_transormed_cubes, image_size=(100, 100))\n",
    "#             cube_top_image = (cube_top_image / cube_top_image.max() * 255).astype(np.uint8)\n",
    "#             grasp_coordinate_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "#                 size=0.1,  # Coordinate axis size, can be adjusted as needed\n",
    "#                 origin=[0, 0, 0]  # Origin of the coordinate axis\n",
    "#             )\n",
    "#             grasp_mesh, gripper_meshes_rotate = generate_gripper_from_transform(graps_transform)\n",
    "#             # Apply transformation matrix to the coordinate frame\n",
    "#             grasp_coordinate_frame.transform(graps_transform)\n",
    "#             grasp_final_matrix = None\n",
    "#             # o3d.visualization.draw_geometries(grasp_mesh+gripper_meshes_rotate+[orignal_point_cloud, coordinate_frame], window_name=\"remaining_pointcloud\")\n",
    "#             if check_grasp_collision(grasp_mesh, orignal_point_cloud):\n",
    "#             # if check_grasp_collision(grasp_mesh, deleted_pointcloud):\n",
    "#                 # If collision\n",
    "#                 grasp_mesh = []\n",
    "#             else:\n",
    "#                 grasp_final_matrix = graps_transform\n",
    "#             if check_grasp_collision(gripper_meshes_rotate, orignal_point_cloud):\n",
    "#             # if check_grasp_collision(gripper_meshes_rotate, deleted_pointcloud):\n",
    "#                 gripper_meshes_rotate = []\n",
    "#             else:\n",
    "#                 grasp_final_matrix = graps_transform_rotate\n",
    "#             # o3d.visualization.draw_geometries(grasp_mesh+gripper_meshes_rotate+[grasp_coordinate_frame, deleted_pointcloud, coordinate_frame], window_name=\"deleted_pointcloud\")\n",
    "#             # o3d.visualization.draw_geometries(grasp_mesh+gripper_meshes_rotate+[grasp_coordinate_frame, remaining_pointcloud, coordinate_frame], window_name=\"deleted_pointcloud\")\n",
    "#             if grasp_final_matrix is not None: # Can move\n",
    "#                 countdown = 50\n",
    "#                 print(grasp_final_matrix)\n",
    "#                 movecount += 1\n",
    "#                 pick_rpy, pick_pos = matrix_to_rpy_and_translation(grasp_final_matrix)\n",
    "#                 pick_pos_ = [a + b for a, b in zip(pick_pos, [0, 0, 0.10])]\n",
    "#                 pick_rpy = [a + b for a, b in zip(pick_rpy, [0, 0, 0])]\n",
    "#                 # pick_place.move(pick_pos_, pick_rpy)\n",
    "#                 print(pick_pos_, pick_rpy)\n",
    "#                 # cube_top_image = point_cloud_to_image(cube_point_cloud_transormed)\n",
    "#                 plt.imsave(f\"test_{movecount}.png\", cube_top_image)\n",
    "#                 plt.show()\n",
    "#                 point_cloud = remaining_pointcloud\n",
    "#                 # TODO: Identify the first face\n",
    "            \n",
    "#                 T.append(grasp_final_matrix)\n",
    "#         else:\n",
    "#             cube_point_cloud = cube_mesh.sample_points_uniformly(number_of_points=50000)\n",
    "#             cube_point_cloud = filter_point_cloud_by_depth(cube_point_cloud, depth_threshold=-0.01)\n",
    "#     print(T)\n",
    "#     return T\n",
    "\n",
    "# def pointcloud_process(point_cloud, slice_tolerance=0.005, cube_num=cube_num):\n",
    "#     '''\n",
    "#     Identify the cubes in a point cloud and determine their transformation matrices for grasping.\n",
    "#     Handles alignment of Z-axis in any orientation for proper grasping.\n",
    "    \n",
    "#     Args:\n",
    "#         point_cloud: The input point cloud containing cubes to be identified\n",
    "#         slice_tolerance: Tolerance for slicing the point cloud\n",
    "#         cube_num: Maximum number of cubes to detect\n",
    "        \n",
    "#     Returns:\n",
    "#         A list of transformation matrices for grasping the identified cubes\n",
    "#     '''\n",
    "#     original_point_cloud = copy.deepcopy(point_cloud)\n",
    "#     T = []\n",
    "#     remaining_pointcloud = point_cloud\n",
    "#     remaining_pointcloud_count = len(point_cloud.points)\n",
    "#     countdown = 50\n",
    "#     movecount = 0\n",
    "    \n",
    "#     # Define standard transformation matrices for grasping\n",
    "#     transform_matrix_x_180 = np.array([\n",
    "#         [1, 0, 0, 0],\n",
    "#         [0, -1, 0, 0],\n",
    "#         [0, 0, -1, 0],\n",
    "#         [0, 0, 0, 1]\n",
    "#     ])\n",
    "    \n",
    "#     transform_matrix_z_90 = np.array([\n",
    "#         [0, -1, 0, 0],\n",
    "#         [1, 0, 0, 0],\n",
    "#         [0, 0, 1, 0],\n",
    "#         [0, 0, 0, 1]\n",
    "#     ])\n",
    "    \n",
    "#     # Function to check if a cube's z-axis points approximately downward\n",
    "#     def is_z_axis_pointing_down(transform):\n",
    "#         z_axis = transform[:3, 2]  # Extract z-axis vector\n",
    "#         return np.dot(z_axis, np.array([0, 0, -1])) > 0.8  # Check if close to pointing down\n",
    "    \n",
    "#     while remaining_pointcloud_count > 50 and countdown > 0 and movecount < cube_num:\n",
    "#         # Sample points from the cube mesh model\n",
    "#         cube_point_cloud = cube_mesh.sample_points_uniformly(number_of_points=50000) \n",
    "#         cube_point_cloud = filter_point_cloud_by_depth(cube_point_cloud, depth_threshold=-0.01)\n",
    "        \n",
    "#         # Register the cube in the point cloud\n",
    "#         transform, remaining_pointcloud, deleted_pointcloud, fitness = register_and_filter(\n",
    "#             remaining_pointcloud, cube_point_cloud\n",
    "#         )\n",
    "        \n",
    "#         remaining_pointcloud_count = len(remaining_pointcloud.points)\n",
    "        \n",
    "#         # Decrement countdown if the fitness is above a minimum threshold\n",
    "#         if fitness > 0.01:\n",
    "#             countdown -= 1\n",
    "            \n",
    "#         print(f\"Iteration {50-countdown}: Fitness = {fitness:.4f}, Remaining points: {remaining_pointcloud_count}\")\n",
    "        \n",
    "#         # Check if the fitness is above the acceptable threshold\n",
    "#         if fitness > 0.40:  # Lowered threshold slightly for more detections\n",
    "#             print(f\"Processing cube #{movecount+1}\")\n",
    "            \n",
    "#             # Align the Z-axis to point downward regardless of original orientation\n",
    "#             aligned_transform = align_transform_z_axis_any_orientation(transform)\n",
    "            \n",
    "#             # Update the transform broadcaster for visualization\n",
    "#             if 'broadcaster' in globals():\n",
    "#                 broadcaster.update(aligned_transform)\n",
    "            \n",
    "#             # Create grasp transforms\n",
    "#             grasp_transform = aligned_transform @ transform_matrix_x_180\n",
    "#             grasp_transform_rotate = aligned_transform @ transform_matrix_x_180 @ transform_matrix_z_90\n",
    "            \n",
    "#             # Transform the detected cube point cloud for visualization\n",
    "#             cube_point_cloud_transformed = copy.deepcopy(deleted_pointcloud)\n",
    "#             cube_point_cloud_transformed = cube_point_cloud_transformed.transform(np.linalg.inv(grasp_transform))\n",
    "            \n",
    "#             # For generating a visual representation as a top-down view\n",
    "#             try:\n",
    "#                 cube_point_cloud_transformed_cubes = enlarge_points_as_cubes(cube_point_cloud_transformed)\n",
    "#                 cube_top_image = triangle_mesh_to_image(cube_point_cloud_transformed_cubes, image_size=(100, 100))\n",
    "#                 cube_top_image = (cube_top_image / cube_top_image.max() * 255).astype(np.uint8)\n",
    "#                 plt.imsave(f\"cube_{movecount+1}_top_view.png\", cube_top_image)\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Warning: Could not generate top view image: {e}\")\n",
    "            \n",
    "#             # Generate gripper meshes for collision checking\n",
    "#             grasp_mesh, gripper_meshes_rotate = generate_gripper_from_transform(grasp_transform)\n",
    "            \n",
    "#             # Find a valid grasp without collisions\n",
    "#             grasp_final_matrix = None\n",
    "            \n",
    "#             # Check first grasping orientation\n",
    "#             if not check_grasp_collision(grasp_mesh, original_point_cloud):\n",
    "#                 grasp_final_matrix = grasp_transform\n",
    "#                 print(\"Using standard grasp orientation\")\n",
    "#             # Check alternative grasping orientation (rotated by 90° around Z)\n",
    "#             elif not check_grasp_collision(gripper_meshes_rotate, original_point_cloud):\n",
    "#                 grasp_final_matrix = grasp_transform_rotate\n",
    "#                 print(\"Using 90° rotated grasp orientation\")\n",
    "#             else:\n",
    "#                 print(\"Both grasp orientations have collisions, skipping this cube\")\n",
    "                \n",
    "#             # If a valid grasp pose was found\n",
    "#             if grasp_final_matrix is not None:\n",
    "#                 # Reset countdown\n",
    "#                 countdown = 50\n",
    "                \n",
    "#                 # Calculate RPY and position for robot movement\n",
    "#                 pick_rpy, pick_pos = matrix_to_rpy_and_translation(grasp_final_matrix)\n",
    "#                 approach_offset = [0, 0, 0.10]  # 10cm above the cube for approach\n",
    "#                 pick_pos_approach = [a + b for a, b in zip(pick_pos, approach_offset)]\n",
    "                \n",
    "#                 print(f\"Cube #{movecount+1} grasp position: {pick_pos}\")\n",
    "#                 print(f\"Approach position: {pick_pos_approach}\")\n",
    "#                 print(f\"RPY orientation: {pick_rpy}\")\n",
    "                \n",
    "#                 # Add the transform to our results\n",
    "#                 T.append(grasp_final_matrix)\n",
    "#                 movecount += 1\n",
    "                \n",
    "#                 # Optional visualization of the detected cube\n",
    "#                 # o3d.visualization.draw_geometries([deleted_pointcloud], window_name=f\"Detected Cube #{movecount}\")\n",
    "                \n",
    "#                 # Optional visualization of the grasp\n",
    "#                 # vis_geometries = grasp_mesh + [create_coordinate_frame(0.1)]\n",
    "#                 # o3d.visualization.draw_geometries(vis_geometries, window_name=f\"Grasp Visualization #{movecount}\")\n",
    "#         else:\n",
    "#             # If fitness is too low, don't change the countdown\n",
    "#             pass\n",
    "    \n",
    "#     print(f\"Found {len(T)} cubes from {50-countdown} iterations\")\n",
    "    \n",
    "#     # Print the final transforms\n",
    "#     for i, transform in enumerate(T):\n",
    "#         print(f\"Cube #{i+1} Transform:\")\n",
    "#         print(transform)\n",
    "        \n",
    "#     return T\n",
    "def pointcloud_process(point_cloud, slice_tolerance=0.005, cube_num=4):\n",
    "    '''\n",
    "    Identify cubes within a point cloud and determine transformation matrices for grasping.\n",
    "    Uses improved Z-axis alignment method that preserves XY plane consistency to reduce alignment errors.\n",
    "    \n",
    "    Args:\n",
    "        point_cloud: The input point cloud containing cubes to be detected\n",
    "        slice_tolerance: Tolerance value for slicing the point cloud\n",
    "        cube_num: Maximum number of cubes to detect\n",
    "        \n",
    "    Returns:\n",
    "        A list of transformation matrices corresponding to the detected graspable cubes\n",
    "    '''\n",
    "    original_point_cloud = copy.deepcopy(point_cloud)\n",
    "    T = []\n",
    "    remaining_pointcloud = point_cloud\n",
    "    remaining_pointcloud_count = len(point_cloud.points)\n",
    "    countdown = 50\n",
    "    movecount = 0\n",
    "\n",
    "    # Define standard transformation matrices for grasping orientation\n",
    "    transform_matrix_x_180 = np.array([\n",
    "        [1, 0, 0, 0],\n",
    "        [0, -1, 0, 0],\n",
    "        [0, 0, -1, 0],\n",
    "        [0, 0, 0, 1]\n",
    "    ])\n",
    "\n",
    "    transform_matrix_z_90 = np.array([\n",
    "        [0, -1, 0, 0],\n",
    "        [1,  0, 0, 0],\n",
    "        [0,  0, 1, 0],\n",
    "        [0,  0, 0, 1]\n",
    "    ])\n",
    "\n",
    "    # Iterate to find and extract cubes\n",
    "    while remaining_pointcloud_count > 50 and countdown > 0 and movecount < cube_num:\n",
    "        # Sample points from the cube mesh model\n",
    "        cube_point_cloud = cube_mesh.sample_points_uniformly(number_of_points=50000) \n",
    "        cube_point_cloud = filter_point_cloud_by_depth(cube_point_cloud, depth_threshold=-0.01)\n",
    "\n",
    "        # Register cube with the current remaining scene point cloud\n",
    "        transform, remaining_pointcloud, deleted_pointcloud, fitness = register_and_filter(\n",
    "            remaining_pointcloud, cube_point_cloud\n",
    "        )\n",
    "\n",
    "        remaining_pointcloud_count = len(remaining_pointcloud.points)\n",
    "\n",
    "        # Reduce countdown if fitness exceeds minimum threshold\n",
    "        if fitness > 0.01:\n",
    "            countdown -= 1\n",
    "\n",
    "        print(f\"Iteration {50 - countdown}: Fitness = {fitness:.4f}, Remaining points: {remaining_pointcloud_count}\")\n",
    "\n",
    "        # Proceed only if the match is good enough\n",
    "        if fitness > 0.40:  # Slightly lowered threshold to detect more cubes\n",
    "            print(f\"Processing cube #{movecount+1}\")\n",
    "\n",
    "            # Align the Z-axis downward while preserving XY orientation\n",
    "            aligned_transform = align_transform_z_axis_preserving_xy(transform)\n",
    "\n",
    "            # Update transform broadcaster (for visualization in RViz, etc.)\n",
    "            if 'broadcaster' in globals():\n",
    "                broadcaster.update(aligned_transform)\n",
    "\n",
    "            # Create grasping transformations\n",
    "            grasp_transform = aligned_transform @ transform_matrix_x_180\n",
    "            grasp_transform_rotate = aligned_transform @ transform_matrix_x_180 @ transform_matrix_z_90\n",
    "\n",
    "            # Transform the detected cube point cloud (for visualization or checking)\n",
    "            cube_point_cloud_transformed = copy.deepcopy(deleted_pointcloud)\n",
    "            cube_point_cloud_transformed = cube_point_cloud_transformed.transform(np.linalg.inv(grasp_transform))\n",
    "\n",
    "            # Try generating a top-view image of the detected cube\n",
    "            try:\n",
    "                cube_point_cloud_transformed_cubes = enlarge_points_as_cubes(cube_point_cloud_transformed)\n",
    "                cube_top_image = triangle_mesh_to_image(cube_point_cloud_transformed_cubes, image_size=(100, 100))\n",
    "                cube_top_image = (cube_top_image / cube_top_image.max() * 255).astype(np.uint8)\n",
    "                plt.imsave(f\"cube_{movecount+1}_top_view.png\", cube_top_image)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not generate top view image: {e}\")\n",
    "\n",
    "            # Generate gripper meshes for collision checking\n",
    "            grasp_mesh, gripper_meshes_rotate = generate_gripper_from_transform(grasp_transform)\n",
    "\n",
    "            # Try both grasping orientations and choose one that doesn't collide\n",
    "            grasp_final_matrix = None\n",
    "\n",
    "            # Try standard grasp orientation\n",
    "            if not check_grasp_collision(grasp_mesh, original_point_cloud):\n",
    "                grasp_final_matrix = grasp_transform\n",
    "                print(\"Using standard grasp orientation\")\n",
    "            # Try alternative 90° rotated grasp\n",
    "            elif not check_grasp_collision(gripper_meshes_rotate, original_point_cloud):\n",
    "                grasp_final_matrix = grasp_transform_rotate\n",
    "                print(\"Using 90° rotated grasp orientation\")\n",
    "            else:\n",
    "                print(\"Both grasp orientations have collisions, skipping this cube\")\n",
    "\n",
    "            # If a valid grasp was found, store it\n",
    "            if grasp_final_matrix is not None:\n",
    "                countdown = 50  # Reset countdown\n",
    "\n",
    "                # Calculate RPY and position for motion planning\n",
    "                pick_rpy, pick_pos = matrix_to_rpy_and_translation(grasp_final_matrix)\n",
    "                approach_offset = [0, 0, 0.10]  # 10 cm above cube\n",
    "                pick_pos_approach = [a + b for a, b in zip(pick_pos, approach_offset)]\n",
    "\n",
    "                print(f\"Cube #{movecount+1} grasp position: {pick_pos}\")\n",
    "                print(f\"Approach position: {pick_pos_approach}\")\n",
    "                print(f\"RPY orientation: {pick_rpy}\")\n",
    "\n",
    "                # Append the transform to the result list\n",
    "                T.append(grasp_final_matrix)\n",
    "                movecount += 1\n",
    "\n",
    "                # Optional: show the grasp transform matrix\n",
    "                print(\"Grasp transform matrix:\")\n",
    "                print(grasp_final_matrix)\n",
    "\n",
    "                # Optional: visualize grasp\n",
    "                # vis_geometries = grasp_mesh + [create_coordinate_frame(0.1)]\n",
    "                # o3d.visualization.draw_geometries(vis_geometries, window_name=f\"Grasp Visualization #{movecount}\")\n",
    "\n",
    "    print(f\"Found {len(T)} cubes in {50 - countdown} iterations\")\n",
    "\n",
    "    # Print final grasp transforms\n",
    "    for i, transform in enumerate(T):\n",
    "        print(f\"Cube #{i+1} Transform:\")\n",
    "        print(transform)\n",
    "\n",
    "    return T\n",
    "\n",
    "            \n",
    "Ts = pointcloud_process(filtered_point_cloud)\n",
    "broadcaster.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a266f54-a76e-4263-8be7-958b208f8df2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ts.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7be0151b-983a-4f9f-b066-f8220e1f2f6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import copy\n",
    "\n",
    "def generate_pascal_triangle_transforms(t, T):\n",
    "    \"\"\"\n",
    "    Generate a list of transformation matrices for a Pascal triangle arrangement.\n",
    "    Each cube's center position is used as the translation part of the transform matrix.\n",
    "    \"\"\"\n",
    "    level = 1\n",
    "    total = 1\n",
    "    while total < t:\n",
    "        level += 1\n",
    "        total += level\n",
    "\n",
    "    transforms = []\n",
    "    cube_size = 0.045  # 4.5 cm\n",
    "    spacing_xy = cube_size * 1.25  # Increase spacing to 1.25 times the cube size\n",
    "    spacing_z = cube_size * 1.05   # Use the same spacing in the vertical direction\n",
    "\n",
    "    current_pos = 0\n",
    "    for row in range(level-1, -1, -1):\n",
    "        for col in range(row + 1):\n",
    "            if current_pos >= t:\n",
    "                break\n",
    "\n",
    "            center_x = 0\n",
    "            center_y = (col - row/2) * spacing_xy\n",
    "            center_z = (level - 1 - row) * spacing_z\n",
    "\n",
    "            # Create local transformation matrix\n",
    "            local_transform = np.eye(4)\n",
    "            local_transform[:3, 3] = [center_x, center_y, center_z]\n",
    "\n",
    "            # Combine local transformation with T transformation\n",
    "            transform = np.dot(T, local_transform)\n",
    "            transforms.append(transform)\n",
    "            current_pos += 1\n",
    "\n",
    "        if current_pos >= t:\n",
    "            break\n",
    "\n",
    "    return transforms\n",
    "\n",
    "def create_coordinate_frame(size=0.1, transform=None):\n",
    "    frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=size)\n",
    "    if transform is not None:\n",
    "        frame.transform(transform)\n",
    "    return frame\n",
    "\n",
    "def visualize_pascal_triangle(transforms, T):\n",
    "    # Create a cube centered at the origin\n",
    "    cube = o3d.geometry.TriangleMesh.create_box(\n",
    "        width=0.045,\n",
    "        height=0.045, \n",
    "        depth=0.045\n",
    "    )\n",
    "    # Move the cube to be centered at the origin\n",
    "    cube.translate([-0.045/2, -0.045/2, -0.045/2])\n",
    "    cube.compute_vertex_normals()\n",
    "\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.create_window()\n",
    "\n",
    "    # Add world coordinate frame\n",
    "    world_frame = create_coordinate_frame(size=0.2)\n",
    "    vis.add_geometry(world_frame)\n",
    "\n",
    "    # Add T coordinate frame\n",
    "    t_frame = create_coordinate_frame(size=0.2, transform=T)\n",
    "    vis.add_geometry(t_frame)\n",
    "\n",
    "    # Add all cubes and their local coordinate frames\n",
    "    for transform in transforms:\n",
    "        # Add cube\n",
    "        cube_copy = copy.deepcopy(cube)\n",
    "        cube_copy.transform(transform)\n",
    "        vis.add_geometry(cube_copy)\n",
    "        \n",
    "        # Add local coordinate frame\n",
    "        local_frame = create_coordinate_frame(size=0.05, transform=transform)\n",
    "        vis.add_geometry(local_frame)\n",
    "\n",
    "    opt = vis.get_render_option()\n",
    "    opt.background_color = np.asarray([0.5, 0.5, 0.5])\n",
    "\n",
    "    ctr = vis.get_view_control()\n",
    "    ctr.set_zoom(0.2)  # Adjust zoom to fit larger spacing\n",
    "    ctr.set_front([-0.8, -0.5, 0.5])\n",
    "    ctr.set_lookat([0, 0, 0])\n",
    "    ctr.set_up([0, 0, 1])\n",
    "\n",
    "    vis.run()\n",
    "    vis.destroy_window()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f396100-4bfb-4740-a839-6a5cef0fbb07",
   "metadata": {},
   "source": [
    "# 3. Motion Planning, movement, and grasp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0ff91c9-6108-48f9-8132-1d623b646c89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import generate_pascal_triangle_transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67d90518-6b07-4d34-9b10-13a9a97c7c26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# t = Ts.__len__()\n",
    "t = 2\n",
    "# 创建T矩阵（示例：绕Z轴旋转45度并平移）\n",
    "T = np.eye(4)\n",
    "theta = 0\n",
    "T[:3, :3] = np.array([\n",
    "    [np.cos(theta), -np.sin(theta), 0],\n",
    "    [np.sin(theta), np.cos(theta), 0],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "T[:3, 3] = [0.3, 0.00, 0]\n",
    "\n",
    "aim_transforms = generate_pascal_triangle_transforms(t, T)\n",
    "# visualize_pascal_triangle(aim_transforms, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed7bf932-3c72-44a4-90b3-559ba899174c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.      ,  0.      ,  0.      ,  0.3     ],\n",
       "        [ 0.      ,  1.      ,  0.      , -0.028125],\n",
       "        [ 0.      ,  0.      ,  1.      ,  0.      ],\n",
       "        [ 0.      ,  0.      ,  0.      ,  1.      ]]),\n",
       " array([[1.      , 0.      , 0.      , 0.3     ],\n",
       "        [0.      , 1.      , 0.      , 0.028125],\n",
       "        [0.      , 0.      , 1.      , 0.      ],\n",
       "        [0.      , 0.      , 0.      , 1.      ]])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aim_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bcf7d104-3c62-454c-8cdc-25427abc1061",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.94320689, -0.33220591,  0.        ,  0.52898373],\n",
       "        [ 0.33220591,  0.94320689,  0.        , -0.01009802],\n",
       "        [ 0.        ,  0.        ,  1.        ,  0.02454193],\n",
       "        [ 0.        ,  0.        ,  0.        ,  1.        ]]),\n",
       " array([[ 0.84132389, -0.54053132,  0.        ,  0.49709212],\n",
       "        [ 0.54053132,  0.84132389,  0.        ,  0.30115412],\n",
       "        [ 0.        ,  0.        ,  1.        ,  0.02445702],\n",
       "        [ 0.        ,  0.        ,  0.        ,  1.        ]]),\n",
       " array([[ 0.80030483, -0.59959334,  0.        ,  0.39361411],\n",
       "        [ 0.59959334,  0.80030483,  0.        ,  0.11186747],\n",
       "        [ 0.        ,  0.        ,  1.        ,  0.02475005],\n",
       "        [ 0.        ,  0.        ,  0.        ,  1.        ]]),\n",
       " array([[ 0.88688204, -0.46199593,  0.        ,  0.5297414 ],\n",
       "        [ 0.46199593,  0.88688204,  0.        , -0.11133846],\n",
       "        [ 0.        ,  0.        ,  1.        ,  0.0246574 ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  1.        ]]),\n",
       " array([[ 0.95424443,  0.2990277 ,  0.        ,  0.44141292],\n",
       "        [-0.2990277 ,  0.95424443,  0.        ,  0.24818554],\n",
       "        [ 0.        ,  0.        ,  1.        ,  0.02446271],\n",
       "        [ 0.        ,  0.        ,  0.        ,  1.        ]]),\n",
       " array([[-0.68009937,  0.73311994,  0.        ,  0.58256287],\n",
       "        [-0.73311994, -0.68009937,  0.        ,  0.24740725],\n",
       "        [ 0.        ,  0.        ,  1.        ,  0.04258383],\n",
       "        [ 0.        ,  0.        ,  0.        ,  1.        ]]),\n",
       " array([[ 0.92673204,  0.37572293,  0.        ,  0.71324327],\n",
       "        [-0.37572293,  0.92673204,  0.        , -0.12897758],\n",
       "        [ 0.        ,  0.        ,  1.        ,  0.02453215],\n",
       "        [ 0.        ,  0.        ,  0.        ,  1.        ]]),\n",
       " array([[ 0.91116666,  0.41203799,  0.        ,  0.38570498],\n",
       "        [-0.41203799,  0.91116666,  0.        , -0.11802432],\n",
       "        [ 0.        ,  0.        ,  1.        ,  0.02476773],\n",
       "        [ 0.        ,  0.        ,  0.        ,  1.        ]])]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c562e6c-a8e0-463e-8ccf-a661995771dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # debug:\n",
    "# import numpy as np\n",
    "\n",
    "# Ts = [np.array([[-0.30936624, -0.95090032,  0.00900657,  0.46123814],\n",
    "#         [-0.95038183,  0.30949514,  0.03141855, -0.07133785],\n",
    "#         [-0.0326634 ,  0.00116016, -0.99946574,  0.03173297],\n",
    "#         [ 0.        ,  0.        ,  0.        ,  1.        ]]),\n",
    "#  np.array([[ 0.9979552 , -0.0391174 , -0.05054952,  0.61442553],\n",
    "#         [-0.04106496, -0.99843052, -0.03808115,  0.10012986],\n",
    "#         [-0.04898055,  0.0400791 , -0.99799528,  0.01518867],\n",
    "#         [ 0.        ,  0.        ,  0.        ,  1.        ]]),\n",
    "#  # np.array([[ 0.97671909, -0.17776618,  0.12007919,  0.4728227 ],\n",
    "#  #        [-0.19286849, -0.97274425,  0.12872592,  0.08761278],\n",
    "#  #        [ 0.09392323, -0.14888855, -0.98438337,  0.02699751],\n",
    "#  #        [ 0.        ,  0.        ,  0.        ,  1.        ]])\n",
    "#      ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8276ec04-7fa0-42e1-ae1c-32d03f30fbd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 3.141592653589793, 0.33864135392116157]\n",
      "Successfully moved to approach position for cube #1\n",
      "[0.0, 3.141592653589793, 0.5710685147446949]\n",
      "Successfully moved to approach position for cube #2\n",
      "[0.0, 3.141592653589793, 0.6429928816452974]\n",
      "Successfully moved to approach position for cube #3\n",
      "[0.0, 3.141592653589793, 0.48024438614592585]\n",
      "Successfully moved to approach position for cube #4\n",
      "[0.0, 3.141592653589793, -0.3036735721124885]\n",
      "Successfully moved to approach position for cube #5\n",
      "[0.0, 3.141592653589793, -2.3186944946043067]\n",
      "Successfully moved to approach position for cube #6\n",
      "[0.0, 3.141592653589793, -0.3851767417558013]\n",
      "Successfully moved to approach position for cube #7\n",
      "[0.0, 3.141592653589793, -0.4246896206614637]\n",
      "Successfully moved to approach position for cube #8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] [1742599891.027330, 3369.298000]: Motion planning failed. No valid plan generated.\n",
      "[ERROR] [1742599891.032058, 3369.302000]: Motion planning failed. No valid plan generated.\n",
      "[ERROR] [1742599891.039970, 3369.303000]: Motion planning failed. No valid plan generated.\n",
      "[ERROR] [1742599891.047647, 3369.303000]: Motion planning failed. No valid plan generated.\n",
      "[ERROR] [1742599891.055904, 3369.303000]: Motion planning failed. No valid plan generated.\n",
      "[ERROR] [1742599891.087132, 3369.343000]: Motion planning failed. No valid plan generated.\n",
      "[ERROR] [1742599891.096378, 3369.352000]: Motion planning failed. No valid plan generated.\n",
      "[ERROR] [1742599891.102864, 3369.359000]: Motion planning failed. No valid plan generated.\n"
     ]
    }
   ],
   "source": [
    "# demostrate the movement to the head of identified cubes\n",
    "# for T in Ts:\n",
    "#     pick_rpy, pick_pos = matrix_to_rpy_and_translation(T)\n",
    "#     pick_pos_ = [a + b for a, b in zip(pick_pos, [0.04, 0.00, 0.10])]\n",
    "#     pick_rpy = [a + b for a, b in zip(pick_rpy, [0, 0, 0])]\n",
    "#     print(pick_rpy, pick_pos)\n",
    "#     pick_place.move(pick_pos_, pick_rpy)\n",
    "# Modified movement demonstration code\n",
    "def demonstrate_movement_to_cubes(Ts, pick_place, offset=[0.04, 0.00, 0.10]):\n",
    "    for i, T in enumerate(Ts):\n",
    "        try:\n",
    "            pick_rpy, pick_pos = matrix_to_rpy_and_translation(T)\n",
    "            pick_pos_approach = [a + b for a, b in zip(pick_pos, offset)]\n",
    "            \n",
    "            try:\n",
    "                pick_place.move(pick_pos_approach, pick_rpy)\n",
    "                print(f\"Successfully moved to approach position for cube #{i+1}\")\n",
    "            except ValueError as e:\n",
    "                if \"too many values to unpack\" in str(e):\n",
    "                    print(f\"Note: Handled unpacking error in move operation for cube #{i+1}\")\n",
    "                else:\n",
    "                    raise\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing cube #{i+1}: {e}\")\n",
    "\n",
    "# Use the modified function\n",
    "demonstrate_movement_to_cubes(Ts, pick_place)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1ff911-c41c-4330-be82-95130ec626fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] [1742598238.893879, 1898.446000]: Motion planning failed. No valid plan generated.\n",
      "[ERROR] [1742598238.903600, 1898.446000]: Motion planning failed. No valid plan generated.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([3.141592653589793, 0.0, -1.5707963267948966],\n",
       " [0.3, 0.028124999999999997, 0.0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# move the minipulator to the aim position\n",
    "for T in aim_transforms:\n",
    "    transform_matrix_x_180 = np.array([\n",
    "        [1, 0, 0, 0],\n",
    "        [0, -1, 0, 0],\n",
    "        [0, 0, -1, 0],\n",
    "        [0, 0, 0, 1]\n",
    "    ])\n",
    "    transform_matrix_z_90 = np.array([\n",
    "        [0, -1, 0, 0],\n",
    "        [1, 0, 0, 0],\n",
    "        [0, 0, 1, 0],\n",
    "        [0, 0, 0, 1]\n",
    "    ])\n",
    "    pick_rpy, pick_pos = matrix_to_rpy_and_translation(T@transform_matrix_x_180@transform_matrix_z_90)\n",
    "    pick_pos_ = [a + b for a, b in zip(pick_pos, [0.0, 0, 0.13])]\n",
    "    pick_rpy = [a + b for a, b in zip(pick_rpy, [0, 0, 0])]\n",
    "    pick_place.move(pick_pos_, pick_rpy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da6b4027-9a96-484e-b6b0-c423c42cd075",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [1742598142.215533, 1812.803000]: Sending open goal: width: 0.08\n",
      "speed: 0.1\n",
      "[INFO] [1742598142.395808, 1812.944000]: Gripper opened successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] [1742598143.403141, 1813.823000]: Motion planning failed. No valid plan generated.\n",
      "[ERROR] [1742598143.611586, 1814.044000]: Motion planning failed. No valid plan generated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [1742598143.919487, 1814.316000]: Sending grasp goal: width: 0.04\n",
      "epsilon: \n",
      "  inner: 0.02\n",
      "  outer: 0.02\n",
      "speed: 0.1\n",
      "force: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARN] [1742598145.036395, 1815.319000]: Grasp failed.\n",
      "[ERROR] [1742598145.345063, 1815.584000]: Motion planning failed. No valid plan generated.\n",
      "[ERROR] [1742598145.550580, 1815.748000]: Motion planning failed. No valid plan generated.\n",
      "[ERROR] [1742598146.056421, 1816.173000]: Motion planning failed. No valid plan generated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [1742598146.569202, 1816.620000]: Sending open goal: width: 0.07\n",
      "speed: 0.1\n",
      "[INFO] [1742598147.517664, 1817.455000]: Gripper opened successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] [1742598148.041935, 1817.949000]: Motion planning failed. No valid plan generated.\n"
     ]
    }
   ],
   "source": [
    "# pick and place the first cube \n",
    "transform_matrix_x_180 = np.array([\n",
    "    [1, 0, 0, 0],\n",
    "    [0, -1, 0, 0],\n",
    "    [0, 0, -1, 0],\n",
    "    [0, 0, 0, 1]\n",
    "])\n",
    "transform_matrix_z_90 = np.array([\n",
    "    [0, -1, 0, 0],\n",
    "    [1, 0, 0, 0],\n",
    "    [0, 0, 1, 0],\n",
    "    [0, 0, 0, 1]\n",
    "])\n",
    "\n",
    "pick_rpy, pick_pos = matrix_to_rpy_and_translation(Ts[0])\n",
    "pick_pos_ = [a + b for a, b in zip(pick_pos, [0.04, 0, 0.00])]\n",
    "pick_rpy = [a + b for a, b in zip(pick_rpy, [0, 0, 0])]\n",
    "    \n",
    "place_rpy, place_pos = matrix_to_rpy_and_translation(aim_transforms[0]@transform_matrix_x_180@transform_matrix_z_90)\n",
    "place_pos_ = [a + b for a, b in zip(place_pos, [0.0, 0, 0.03])]\n",
    "\n",
    "pick_place.pick_and_place(\n",
    "    pick_pos=pick_pos_,\n",
    "    pick_rpy=pick_rpy,\n",
    "    place_pos=place_pos_,\n",
    "    place_rpy=place_rpy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a662392-36bb-46d1-a2b3-ac8562db28ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [1742599801.925197, 3291.629000]: Sending open goal: width: 0.08\n",
      "speed: 0.1\n",
      "[INFO] [1742599801.974230, 3291.652000]: Gripper opened successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] [1742599802.983268, 3292.550000]: Motion planning failed. No valid plan generated.\n",
      "[ERROR] [1742599803.191008, 3292.719000]: Motion planning failed. No valid plan generated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [1742599803.494745, 3293.000000]: Sending grasp goal: width: 0.04\n",
      "epsilon: \n",
      "  inner: 0.02\n",
      "  outer: 0.02\n",
      "speed: 0.1\n",
      "force: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARN] [1742599804.662736, 3293.996000]: Grasp failed.\n",
      "[ERROR] [1742599804.965281, 3294.274000]: Motion planning failed. No valid plan generated.\n",
      "[ERROR] [1742599805.169579, 3294.412000]: Motion planning failed. No valid plan generated.\n",
      "[ERROR] [1742599805.690936, 3294.873000]: Motion planning failed. No valid plan generated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [1742599806.209010, 3295.339000]: Sending open goal: width: 0.07\n",
      "speed: 0.1\n",
      "[INFO] [1742599807.217041, 3296.211000]: Gripper opened successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] [1742599807.723500, 3296.678000]: Motion planning failed. No valid plan generated.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m pick_pos_ \u001b[38;5;241m=\u001b[39m [a \u001b[38;5;241m+\u001b[39m b \u001b[38;5;28;01mfor\u001b[39;00m a, b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(pick_pos, [\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0.008\u001b[39m])]\n\u001b[1;32m     18\u001b[0m pick_rpy \u001b[38;5;241m=\u001b[39m [a \u001b[38;5;241m+\u001b[39m b \u001b[38;5;28;01mfor\u001b[39;00m a, b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(pick_rpy, [\u001b[38;5;241m0\u001b[39m, np\u001b[38;5;241m.\u001b[39mpi, \u001b[38;5;241m0\u001b[39m])]\n\u001b[0;32m---> 20\u001b[0m place_rpy, place_pos \u001b[38;5;241m=\u001b[39m matrix_to_rpy_and_translation(\u001b[43maim_transforms\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;129m@transform_matrix_x_180\u001b[39m\u001b[38;5;129m@transform_matrix_z_90\u001b[39m)\n\u001b[1;32m     21\u001b[0m place_pos_ \u001b[38;5;241m=\u001b[39m [a \u001b[38;5;241m+\u001b[39m b \u001b[38;5;28;01mfor\u001b[39;00m a, b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(place_pos, [\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0.03\u001b[39m])]\n\u001b[1;32m     23\u001b[0m pick_place\u001b[38;5;241m.\u001b[39mpick_and_place(\n\u001b[1;32m     24\u001b[0m     pick_pos\u001b[38;5;241m=\u001b[39mpick_pos_,\n\u001b[1;32m     25\u001b[0m     pick_rpy\u001b[38;5;241m=\u001b[39mpick_rpy,\n\u001b[1;32m     26\u001b[0m     place_pos\u001b[38;5;241m=\u001b[39mplace_pos_,\n\u001b[1;32m     27\u001b[0m     place_rpy\u001b[38;5;241m=\u001b[39mplace_rpy\n\u001b[1;32m     28\u001b[0m )\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# pick and place following cubes \n",
    "for i in range(1, Ts.__len__()-1):\n",
    "    ptransform_matrix_x_180 = np.array([\n",
    "    [1, 0, 0, 0],\n",
    "    [0, -1, 0, 0],\n",
    "    [0, 0, -1, 0],\n",
    "    [0, 0, 0, 1]\n",
    "    ])\n",
    "    transform_matrix_z_90 = np.array([\n",
    "        [0, -1, 0, 0],\n",
    "        [1, 0, 0, 0],\n",
    "        [0, 0, 1, 0],\n",
    "        [0, 0, 0, 1]\n",
    "    ])\n",
    "\n",
    "    pick_rpy, pick_pos = matrix_to_rpy_and_translation(Ts[i])\n",
    "    pick_pos_ = [a + b for a, b in zip(pick_pos, [0.0, 0, 0.008])]\n",
    "    pick_rpy = [a + b for a, b in zip(pick_rpy, [0, 0, 0])]\n",
    "\n",
    "    place_rpy, place_pos = matrix_to_rpy_and_translation(aim_transforms[i]@transform_matrix_x_180@transform_matrix_z_90)\n",
    "    place_pos_ = [a + b for a, b in zip(place_pos, [0.0, 0, 0.03])]\n",
    "\n",
    "    pick_place.pick_and_place(\n",
    "        pick_pos=pick_pos_,\n",
    "        pick_rpy=pick_rpy,\n",
    "        place_pos=place_pos_,\n",
    "        place_rpy=place_rpy\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae12895-f189-48d9-98a8-7f5b4ce8f8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.94320689 -0.33220591  0.          0.52898373]\n",
      " [ 0.33220591  0.94320689  0.         -0.01009802]\n",
      " [ 0.          0.          1.          0.02454193]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "([0.0, 0.0, 0.33864135392116157], [0.5289837279170989, -0.010098020185695014, 0.024541929567309734])\n",
      "[[ 0.84132389 -0.54053132  0.          0.49709212]\n",
      " [ 0.54053132  0.84132389  0.          0.30115412]\n",
      " [ 0.          0.          1.          0.02445702]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "([0.0, 0.0, 0.5710685147446949], [0.4970921171222455, 0.30115411737378356, 0.02445701548324259])\n",
      "[[ 0.80030483 -0.59959334  0.          0.39361411]\n",
      " [ 0.59959334  0.80030483  0.          0.11186747]\n",
      " [ 0.          0.          1.          0.02475005]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "([0.0, 0.0, 0.6429928816452974], [0.3936141102195277, 0.1118674722427118, 0.024750046723177994])\n",
      "[[ 0.88688204 -0.46199593  0.          0.5297414 ]\n",
      " [ 0.46199593  0.88688204  0.         -0.11133846]\n",
      " [ 0.          0.          1.          0.0246574 ]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "([0.0, 0.0, 0.48024438614592585], [0.5297413973621702, -0.1113384582518187, 0.024657398194206277])\n",
      "[[ 0.95424443  0.2990277   0.          0.44141292]\n",
      " [-0.2990277   0.95424443  0.          0.24818554]\n",
      " [ 0.          0.          1.          0.02446271]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "([0.0, 0.0, -0.3036735721124885], [0.4414129217163664, 0.24818554136715776, 0.02446270518071292])\n",
      "[[-0.68009937  0.73311994  0.          0.58256287]\n",
      " [-0.73311994 -0.68009937  0.          0.24740725]\n",
      " [ 0.          0.          1.          0.04258383]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "([0.0, 0.0, -2.3186944946043067], [0.582562865246966, 0.24740725082548695, 0.042583826926776466])\n",
      "[[ 0.92673204  0.37572293  0.          0.71324327]\n",
      " [-0.37572293  0.92673204  0.         -0.12897758]\n",
      " [ 0.          0.          1.          0.02453215]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "([0.0, 0.0, -0.3851767417558013], [0.7132432671647235, -0.12897758431427192, 0.024532147149979054])\n",
      "[[ 0.91116666  0.41203799  0.          0.38570498]\n",
      " [-0.41203799  0.91116666  0.         -0.11802432]\n",
      " [ 0.          0.          1.          0.02476773]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "([0.0, 0.0, -0.4246896206614637], [0.3857049813509023, -0.1180243248029218, 0.024767729416670915])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28a61a9-5a2d-46d9-85f8-6e0d2d2e66e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.94320689, -0.33220591,  0.        ,  0.52898373],\n",
       "        [ 0.33220591,  0.94320689,  0.        , -0.01009802],\n",
       "        [ 0.        ,  0.        ,  1.        ,  0.02454193],\n",
       "        [ 0.        ,  0.        ,  0.        ,  1.        ]]),\n",
       " array([[ 0.84132389, -0.54053132,  0.        ,  0.49709212],\n",
       "        [ 0.54053132,  0.84132389,  0.        ,  0.30115412],\n",
       "        [ 0.        ,  0.        ,  1.        ,  0.02445702],\n",
       "        [ 0.        ,  0.        ,  0.        ,  1.        ]]),\n",
       " array([[ 0.80030483, -0.59959334,  0.        ,  0.39361411],\n",
       "        [ 0.59959334,  0.80030483,  0.        ,  0.11186747],\n",
       "        [ 0.        ,  0.        ,  1.        ,  0.02475005],\n",
       "        [ 0.        ,  0.        ,  0.        ,  1.        ]]),\n",
       " array([[ 0.88688204, -0.46199593,  0.        ,  0.5297414 ],\n",
       "        [ 0.46199593,  0.88688204,  0.        , -0.11133846],\n",
       "        [ 0.        ,  0.        ,  1.        ,  0.0246574 ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  1.        ]]),\n",
       " array([[ 0.95424443,  0.2990277 ,  0.        ,  0.44141292],\n",
       "        [-0.2990277 ,  0.95424443,  0.        ,  0.24818554],\n",
       "        [ 0.        ,  0.        ,  1.        ,  0.02446271],\n",
       "        [ 0.        ,  0.        ,  0.        ,  1.        ]]),\n",
       " array([[-0.68009937,  0.73311994,  0.        ,  0.58256287],\n",
       "        [-0.73311994, -0.68009937,  0.        ,  0.24740725],\n",
       "        [ 0.        ,  0.        ,  1.        ,  0.04258383],\n",
       "        [ 0.        ,  0.        ,  0.        ,  1.        ]]),\n",
       " array([[ 0.92673204,  0.37572293,  0.        ,  0.71324327],\n",
       "        [-0.37572293,  0.92673204,  0.        , -0.12897758],\n",
       "        [ 0.        ,  0.        ,  1.        ,  0.02453215],\n",
       "        [ 0.        ,  0.        ,  0.        ,  1.        ]]),\n",
       " array([[ 0.91116666,  0.41203799,  0.        ,  0.38570498],\n",
       "        [-0.41203799,  0.91116666,  0.        , -0.11802432],\n",
       "        [ 0.        ,  0.        ,  1.        ,  0.02476773],\n",
       "        [ 0.        ,  0.        ,  0.        ,  1.        ]])]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb28b7de-2a7b-447b-b92c-f9487c4a8977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344eea87-4f39-40cd-adcb-2d3490950865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b49a45-b76a-4109-a1b9-92473eb0cc5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90752b1-45fd-40c6-95e6-5c641111580b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e628f0-7d4c-4612-8453-cc769bb96ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0b93ec-fc14-4c5b-a51b-ddd187495ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cf24a9-2107-4c18-8b75-410152602d54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97c4cfa-2497-47fb-abcc-b4d8102d5a27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97a75a1-7a1b-4df9-87e5-f22fc098e059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916923c9-2c36-417b-bb2a-7a07e665e320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1aa9b1-890b-4a21-a656-5c54a75d5c01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8e1942-89b9-460e-8013-c3406e5ec660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f97b18-cf6e-4683-b2b0-b18f61f0c335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84bdaf3-eb89-4acf-aa35-34d10d9ff810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72f5be6-10ab-4a45-9860-f3cdf9737da3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc74575-a184-436e-b10f-6e5cbd701094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (irobmanenv)",
   "language": "python",
   "name": "irobmanenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
