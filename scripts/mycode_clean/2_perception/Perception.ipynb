{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95482eee-ad8f-423f-a497-8990e8ac372a",
   "metadata": {},
   "source": [
    "# 1. record point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb0fd4c1-97e3-4984-a270-edddc5a05230",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Python Path:\n",
      "\n",
      "/opt/ros_ws/devel/lib/python3/dist-packages\n",
      "/opt/ros/noetic/lib/python3/dist-packages\n",
      "/usr/lib/python38.zip\n",
      "/usr/lib/python3.8\n",
      "/usr/lib/python3.8/lib-dynload\n",
      "/usr/local/lib/python3.8/dist-packages\n",
      "/usr/lib/python3/dist-packages\n",
      "/opt/ros_ws/src/franka_zed_gazebo/scripts/mycode_clean/3_move\n",
      "/opt/ros_ws/src/franka_zed_gazebo/scripts/mycode_clean/1_getPointCloud\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2025-03-24 00:32:08,249 - topics - topicmanager initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "[INFO] [1742776328.469337, 0.000000]: Waiting for move_group action server...\n",
      "\u001b[0m[ INFO] [1742776328.471598255]: Loading robot model 'panda'...\u001b[0m\n",
      "\u001b[0m[ INFO] [1742776329.630174851, 677.928000000]: Ready to take commands for planning group panda_manipulator.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[ WARN] [1742776328.495741714]: Link zed2_holder has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [1742776329.633447, 0.000000]: Table added to the scene to prevent collision below z = 0.001\n",
      "[INFO] [1742776329.635815, 0.000000]: Wall 'wall_right' added to the scene with rotation theta=-0.7853981633974483 radians at position: 0.0, 0.8, 0.0\n",
      "[INFO] [1742776329.638132, 0.000000]: Wall 'wall_left' added to the scene with rotation theta=0.7853981633974483 radians at position: 0.0, -0.8, 0.0\n",
      "[INFO] [1742776329.639084, 677.937000]: MoveRobot initialized successfully.\n",
      "[INFO] [1742776329.869338, 678.153000]: Current joint values: [-2.7193123587074997, -0.2065849798509003, 2.123642072486204, -1.9446196233850204, 0.19669424918416034, 2.0408322569820037, -1.4616451166605682]\n",
      "[INFO] [1742776329.877676, 678.175000]: Waiting for gripper action servers...\n",
      "[INFO] [1742776330.201103, 678.497000]: Gripper action servers ready.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the current working directory (used to replace __file__)\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "target_path1 = os.path.abspath(os.path.join(current_dir, '../3_move'))\n",
    "target_path2 = os.path.abspath(os.path.join(current_dir, '../1_getPointCloud'))\n",
    "\n",
    "# Add the paths to sys.path\n",
    "if target_path1 not in sys.path:\n",
    "    sys.path.append(target_path1)\n",
    "    \n",
    "if target_path2 not in sys.path:\n",
    "    sys.path.append(target_path2)\n",
    "# Check if the paths were added successfully\n",
    "print(\"Current Python Path:\")\n",
    "print(\"\\n\".join(sys.path))\n",
    "\n",
    "from ImageRecognizer import ImageRecognizer\n",
    "image_recognizer = ImageRecognizer(top_dir=\"/opt/ros_ws/src/franka_zed_gazebo/scripts/mycode_clean/2_perception/cubes/\")\n",
    "\n",
    "from utils import matrix_to_rpy_and_translation\n",
    "\n",
    "from PickAndPlace import PickAndPlace\n",
    "\n",
    "pick_place = PickAndPlace(approach_distance=0.3, restart=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c575264-32a4-4fc0-9469-5ce80c9a98fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [1742776343.580195, 691.809000]: Waiting for data...\n",
      "[INFO] [1742776343.649154, 691.881000]: Received image message.\n",
      "[INFO] [1742776343.675687, 691.883000]: Received point cloud data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[ WARN] [1742776344.920727576, 693.131000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame target_frame (parent world) at time 693.105000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1742776344.931178869, 693.142000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame target_frame (parent world) at time 693.105000 according to authority /my_gripper_node_71928_1742776328347\u001b[0m\n",
      "\u001b[33m[ WARN] [1742776345.131737939, 693.331000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame target_frame (parent world) at time 693.317000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1742776345.137503668, 693.337000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame target_frame (parent world) at time 693.317000 according to authority /my_gripper_node_71928_1742776328347\u001b[0m\n",
      "\u001b[33m[ WARN] [1742776345.360995534, 693.539000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame target_frame (parent world) at time 693.526000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1742776345.366125186, 693.544000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame target_frame (parent world) at time 693.526000 according to authority /my_gripper_node_71928_1742776328347\u001b[0m\n",
      "\u001b[33m[ WARN] [1742776345.634426828, 693.811000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame target_frame (parent world) at time 693.780000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1742776345.645119850, 693.821000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame target_frame (parent world) at time 693.780000 according to authority /my_gripper_node_71928_1742776328347\u001b[0m\n",
      "\u001b[33m[ WARN] [1742776345.937921540, 694.101000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame target_frame (parent world) at time 694.089000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1742776345.938430537, 694.101000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame target_frame (parent world) at time 694.089000 according to authority /my_gripper_node_71928_1742776328347\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [1742776346.177940, 694.313000]: Color range - Min: [0.10196078 0.10196078 0.10196078], Max: [0.70196078 0.60784314 0.60784314]\n",
      "[INFO] [1742776346.180008, 694.319000]: Requesting transform from world to left_camera_link_optical...\n",
      "[INFO] [1742776346.181903, 694.321000]: Transform found: header: \n",
      "  seq: 0\n",
      "  stamp: \n",
      "    secs: 694\n",
      "    nsecs: 300000000\n",
      "  frame_id: \"world\"\n",
      "child_frame_id: \"left_camera_link_optical\"\n",
      "transform: \n",
      "  translation: \n",
      "    x: 0.21074797786961397\n",
      "    y: -0.059958558303076434\n",
      "    z: 0.5570633141644737\n",
      "  rotation: \n",
      "    x: 0.6601932466137219\n",
      "    y: 0.6605923269640532\n",
      "    z: 0.25267019392296003\n",
      "    w: 0.25282489550039294\n",
      "[INFO] [1742776346.459634, 694.598000]: Transformed point cloud saved to /opt/ros_ws/src/franka_zed_gazebo/scripts/mycode_clean/2_perception/mesh/zed_point_cloud_world3.ply\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[ WARN] [1742776346.415755984, 694.554000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame target_frame (parent world) at time 694.545000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1742776346.416452550, 694.555000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame target_frame (parent world) at time 694.545000 according to authority /my_gripper_node_71928_1742776328347\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from save_point_cloud import PointCloudSaver\n",
    "import open3d as o3d\n",
    "import rospy\n",
    "point_cloud_saver = PointCloudSaver()\n",
    "\n",
    "# Wait for data to be ready\n",
    "rospy.loginfo(\"Waiting for data...\")\n",
    "rospy.sleep(1)  # Wait for topic data to be published\n",
    "\n",
    "# Save the point cloud\n",
    "world_file = \"/opt/ros_ws/src/franka_zed_gazebo/scripts/mycode_clean/2_perception/mesh/zed_point_cloud_world3.ply\"\n",
    "point_cloud_saver.save_point_clouds(world_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ebdb0eb-9e99-4745-88a8-52bfcc7225d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[ WARN] [1742776348.411170414, 696.470000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame target_frame (parent world) at time 696.456000 according to authority unknown_publisher\u001b[0m\n",
      "\u001b[33m[ WARN] [1742776348.412216438, 696.471000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame target_frame (parent world) at time 696.456000 according to authority /my_gripper_node_71928_1742776328347\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from utils import filter_point_cloud_by_depth_and_range, filter_point_cloud_by_depth\n",
    "\n",
    "# zed_ply_path = \"mesh/zed_point_cloud_world3.ply\"\n",
    "zed_ply_path = \"/opt/ros_ws/src/franka_zed_gazebo/scripts/mycode_clean/2_perception/mesh/zed_point_cloud_world3.ply\"\n",
    "\n",
    "coordinate_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "    size=0.1,  # Size of the coordinate axes, can be adjusted as needed\n",
    "    origin=[0, 0, 0]  # Origin of the coordinate axes\n",
    ")\n",
    "\n",
    "# Read the point cloud file\n",
    "point_cloud = o3d.io.read_point_cloud(zed_ply_path)\n",
    "if not point_cloud.has_points():\n",
    "    raise ValueError(f\"Failed to read point cloud from {zed_ply_path}\")\n",
    "filtered_point_cloud = filter_point_cloud_by_depth_and_range(point_cloud, depth_threshold=0.02, range=[0.001, -0.8, 1, 1.6])\n",
    "o3d.visualization.draw_geometries([filtered_point_cloud, coordinate_frame], window_name=\"Filtered Point Cloud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9883e9d-4bce-412e-ad0a-224f0121b514",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from utils import calculate_max_layer\n",
    "\n",
    "# # Example usage\n",
    "# max_layer = calculate_max_layer(filtered_point_cloud, layer_height=0.04)\n",
    "# print(f\"MaxLayer: {max_layer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d5b48e-3edb-4683-a774-6ef27ecad23b",
   "metadata": {},
   "source": [
    "# 2. Perception"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f7d2ab-d25d-4387-ac97-81de3ec741dd",
   "metadata": {},
   "source": [
    "## 2.1 Coarse and Fine registration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88fe104e-b675-4313-93a1-417cdc00c8cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "def register_and_filter(pointcloud, mesh, voxel_size=0.01):\n",
    "    # Convert mesh to point cloud\n",
    "    if isinstance(mesh, o3d.geometry.TriangleMesh):\n",
    "        mesh_pointcloud = mesh.sample_points_uniformly(number_of_points=1000)\n",
    "    elif isinstance(mesh, o3d.geometry.PointCloud):\n",
    "        mesh_pointcloud = copy.deepcopy(mesh)\n",
    "    \n",
    "    # Downsample the point cloud and compute features\n",
    "    def preprocess_point_cloud(pcd, voxel_size):\n",
    "        pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "        pcd_down.estimate_normals(\n",
    "            search_param=o3d.geometry.KDTreeSearchParamHybrid(\n",
    "                radius=voxel_size*2, \n",
    "                max_nn=30\n",
    "            )\n",
    "        )\n",
    "        pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "            pcd_down,\n",
    "            search_param=o3d.geometry.KDTreeSearchParamHybrid(\n",
    "                radius=voxel_size*5, \n",
    "                max_nn=100\n",
    "            )\n",
    "        )\n",
    "        return pcd_down, pcd_fpfh\n",
    "\n",
    "    # Coarse registration\n",
    "    def execute_global_registration(source_down, target_down, source_fpfh, target_fpfh, voxel_size):\n",
    "        distance_threshold = voxel_size * 1.5\n",
    "        result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "            source_down, target_down, source_fpfh, target_fpfh, True,\n",
    "            distance_threshold,\n",
    "            o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "            4,\n",
    "            [\n",
    "                o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "                o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "            ],\n",
    "            o3d.pipelines.registration.RANSACConvergenceCriteria(4000000, 500)\n",
    "        )\n",
    "        return result\n",
    "\n",
    "    # Fine registration\n",
    "    def refine_registration(source, target, initial_transformation, voxel_size):\n",
    "        distance_threshold = voxel_size * 1  # Reduce the threshold for higher accuracy\n",
    "        result = o3d.pipelines.registration.registration_icp(\n",
    "            source, target, distance_threshold, initial_transformation,\n",
    "            o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "            o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=1000000)\n",
    "        )\n",
    "        return result\n",
    "\n",
    "    # Execute point cloud preprocessing\n",
    "    source_down, source_fpfh = preprocess_point_cloud(mesh_pointcloud, voxel_size)\n",
    "    target_down, target_fpfh = preprocess_point_cloud(pointcloud, voxel_size)\n",
    "\n",
    "    # Execute registration\n",
    "    coarse_result = execute_global_registration(source_down, target_down, source_fpfh, target_fpfh, voxel_size)\n",
    "    refined_result = refine_registration(mesh_pointcloud, pointcloud, coarse_result.transformation, voxel_size)\n",
    "\n",
    "    # Transform the mesh point cloud\n",
    "    transform = refined_result.transformation\n",
    "    transformed_mesh_pointcloud = mesh_pointcloud.transform(transform)\n",
    "\n",
    "    # Create bounding box\n",
    "    oriented_bounding_box = transformed_mesh_pointcloud.get_oriented_bounding_box()\n",
    "    center = oriented_bounding_box.center\n",
    "    extent = oriented_bounding_box.extent\n",
    "    rotation_matrix = oriented_bounding_box.R\n",
    "\n",
    "    # Expand the bounding box\n",
    "    margin = voxel_size\n",
    "    expanded_extent = extent + 0.5 * margin\n",
    "    expanded_bounding_box = o3d.geometry.OrientedBoundingBox(\n",
    "        center=center,\n",
    "        extent=expanded_extent,\n",
    "        R=rotation_matrix\n",
    "    )\n",
    "\n",
    "    # Filter the point cloud\n",
    "    indices_inside_box = expanded_bounding_box.get_point_indices_within_bounding_box(pointcloud.points)\n",
    "    indices_outside_box = list(set(range(len(pointcloud.points))) - set(indices_inside_box))\n",
    "\n",
    "    # Separate the point cloud\n",
    "    remaining_pointcloud = pointcloud.select_by_index(indices_outside_box)\n",
    "    deleted_pointcloud = pointcloud.select_by_index(indices_inside_box)\n",
    "\n",
    "    return transform, remaining_pointcloud, deleted_pointcloud, refined_result.fitness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97050aea-fb60-4b73-b5ee-14d1b5891787",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the cube\n",
    "# Define file paths\n",
    "cube_obj_path = \"mesh/cube_0.obj\"\n",
    "zed_ply_path = \"mesh/zed_point_cloud_world3.ply\"\n",
    "\n",
    "# Read the cube_0.obj mesh\n",
    "cube_mesh = o3d.io.read_triangle_mesh(cube_obj_path)\n",
    "cube_mesh.compute_vertex_normals()  # Compute normals for better visualization\n",
    "# cube_point_cloud = cube_mesh.sample_points_uniformly(number_of_points=50000)  # Convert to point cloud\n",
    "# cube_point_cloud = cube_mesh.sample_points_poisson_disk(number_of_points=1000)\n",
    "\n",
    "# Remove the lower part of the cube to prevent flipping along the z-axis\n",
    "# cube_point_cloud = filter_point_cloud_by_depth(cube_point_cloud, depth_threshold=-0.015)\n",
    "# o3d.visualization.draw_geometries([cube_point_cloud])\n",
    "\n",
    "\n",
    "coordinate_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "    size=0.1,  # Size of the coordinate axes, can be adjusted as needed\n",
    "    origin=[0, 0, 0]  # Origin of the coordinate axes\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54f3fe34-f397-4e76-8452-b24a6cf4e9f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_transform_z_axis_alignment(transform, tolerance=0.1):\n",
    "    \"\"\"\n",
    "    Check if the Z-axis of the transform is parallel to the Z-axis of the world coordinate system.\n",
    "    Allows a certain tolerance range to check if it is parallel or anti-parallel.\n",
    "    \n",
    "    Args:\n",
    "    - transform: 4x4 transformation matrix\n",
    "    - tolerance: Tolerance range for checking, default is 0.1\n",
    "    \n",
    "    Returns:\n",
    "    - True: If the Z-axis is parallel or anti-parallel\n",
    "    - False: If the Z-axis is not parallel\n",
    "    - The corrected transform\n",
    "    \"\"\"\n",
    "    z_axis = np.array([0, 0, 1])  # Z-axis of the world coordinate system\n",
    "    transform_z_axis = transform[:3, 2]  # Get the Z-axis of the transform (i.e., the third column of the rotation matrix)\n",
    "\n",
    "    # Compute the angle between the transform's Z-axis and the world coordinate system's Z-axis\n",
    "    dot_product = np.dot(transform_z_axis, z_axis)\n",
    "    # Compute the cosine of the angle, if close to 1 or -1, it means parallel or anti-parallel\n",
    "    if np.abs(dot_product) > (1 - tolerance):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def align_transform_z_axis(transform):\n",
    "    \"\"\"\n",
    "    If the Z-axis of the transform is anti-parallel to the Z-axis of the world coordinate system,\n",
    "    rotate by 180 degrees around the X-axis (np.pi) to flip the direction of the Z-axis.\n",
    "    \n",
    "    Args:\n",
    "    - transform: 4x4 transformation matrix\n",
    "    \n",
    "    Returns:\n",
    "    - The corrected transform matrix\n",
    "    \"\"\"\n",
    "    z_axis_world = np.array([0, 0, 1])  # Z-axis of the world coordinate system\n",
    "    transform_z_axis = transform[:3, 2]  # Get the Z-axis of the transform (the third column of the rotation matrix)\n",
    "\n",
    "    # Check if the Z-axis is anti-parallel to the world coordinate system's Z-axis\n",
    "    if np.dot(transform_z_axis, z_axis_world) < 0:  # Z-axis is anti-parallel\n",
    "        print(\"Correcting Z axis\")\n",
    "        # Create a rotation matrix to rotate 180 degrees around the X-axis\n",
    "        rotation_matrix = np.eye(4)\n",
    "        rotation_matrix[1, 1] = -1  # Rotate the matrix by 180 degrees around the X-axis\n",
    "        rotation_matrix[2, 2] = -1  # Rotate the matrix by 180 degrees around the X-axis\n",
    "        \n",
    "        # Perform matrix multiplication, applying the rotation matrix to the original transform\n",
    "        transform = np.dot(rotation_matrix, transform)\n",
    "\n",
    "    return transform\n",
    "\n",
    "def align_transform_z_axis_any_orientation(transform):\n",
    "    \"\"\"\n",
    "    Aligns the Z-axis of the transform with the negative Z-axis of the world coordinate system,\n",
    "    no matter what the original orientation is.\n",
    "    \n",
    "    Args:\n",
    "    - transform: 4x4 transformation matrix\n",
    "    \n",
    "    Returns:\n",
    "    - The corrected transform matrix with Z-axis pointing downward\n",
    "    \"\"\"\n",
    "    # Extract the original rotation matrix and translation vector\n",
    "    rotation = transform[:3, :3]\n",
    "    translation = transform[:3, 3]\n",
    "    \n",
    "    # Extract the current z-axis direction (third column of rotation matrix)\n",
    "    current_z = rotation[:, 2]\n",
    "    \n",
    "    # Target z-axis direction (downward in world coordinates)\n",
    "    target_z = np.array([0, 0, -1])\n",
    "    \n",
    "    # Check if already aligned within a small tolerance\n",
    "    if np.allclose(current_z, target_z, atol=1e-6):\n",
    "        return transform\n",
    "    \n",
    "    # For completely anti-aligned case (pointing directly up), simple 180° rotation works\n",
    "    if np.allclose(current_z, -target_z, atol=1e-6):\n",
    "        # Rotate 180 degrees around x-axis\n",
    "        r = np.eye(3)\n",
    "        r[1, 1] = -1\n",
    "        r[2, 2] = -1\n",
    "        new_rotation = rotation @ r\n",
    "    else:\n",
    "        # For any other orientation, we need to find the rotation that aligns vectors\n",
    "        # Compute the rotation axis (cross product of current and target z-axes)\n",
    "        rotation_axis = np.cross(current_z, target_z)\n",
    "        \n",
    "        # If current_z and target_z are parallel or anti-parallel, rotation_axis might be zero\n",
    "        # In that case, choose any perpendicular axis\n",
    "        if np.allclose(rotation_axis, 0, atol=1e-10):\n",
    "            # Find a non-zero component in current_z\n",
    "            if abs(current_z[0]) > 1e-10:\n",
    "                rotation_axis = np.array([current_z[1], -current_z[0], 0])\n",
    "            else:\n",
    "                rotation_axis = np.array([0, current_z[2], -current_z[1]])\n",
    "        \n",
    "        # Normalize the rotation axis\n",
    "        rotation_axis = rotation_axis / np.linalg.norm(rotation_axis)\n",
    "        \n",
    "        # Compute the rotation angle (dot product gives cosine of angle)\n",
    "        # We want the shorter arc between the vectors\n",
    "        cos_angle = np.dot(current_z, target_z)\n",
    "        angle = np.arccos(np.clip(cos_angle, -1.0, 1.0))\n",
    "        \n",
    "        # Rodrigues' rotation formula to get rotation matrix\n",
    "        K = np.array([\n",
    "            [0, -rotation_axis[2], rotation_axis[1]],\n",
    "            [rotation_axis[2], 0, -rotation_axis[0]],\n",
    "            [-rotation_axis[1], rotation_axis[0], 0]\n",
    "        ])\n",
    "        R = np.eye(3) + np.sin(angle) * K + (1 - np.cos(angle)) * (K @ K)\n",
    "        \n",
    "        # Apply the rotation to the original rotation matrix\n",
    "        new_rotation = rotation @ R\n",
    "    \n",
    "    # Create the new transformation matrix\n",
    "    new_transform = np.eye(4)\n",
    "    new_transform[:3, :3] = new_rotation\n",
    "    new_transform[:3, 3] = translation\n",
    "    \n",
    "    # Validate the result\n",
    "    result_z = new_transform[:3, :3][:, 2]\n",
    "    alignment_quality = np.dot(result_z, target_z)\n",
    "    print(f\"Z-axis alignment quality: {alignment_quality:.6f} (closer to 1 is better)\")\n",
    "    \n",
    "    return new_transform\n",
    "\n",
    "def align_transform_z_axis_preserving_xy(transform):\n",
    "    \"\"\"\n",
    "    Align the Z-axis of the transformation matrix to point downward (world -Z axis),\n",
    "    while preserving the original XY plane orientation as much as possible.\n",
    "\n",
    "    This function ensures:\n",
    "    1. The Z-axis points downward (aligned with the world -Z axis)\n",
    "    2. The XY plane is preserved as much as possible to minimize disruption to the original grasp direction\n",
    "\n",
    "    Args:\n",
    "        transform: A 4x4 transformation matrix\n",
    "\n",
    "    Returns:\n",
    "        A corrected transformation matrix with the Z-axis pointing downward and XY directions as close as possible to the original\n",
    "    \"\"\"\n",
    "    # Extract the original rotation matrix and translation vector\n",
    "    rotation = transform[:3, :3]\n",
    "    translation = transform[:3, 3]\n",
    "\n",
    "    # Extract current axes directions from the rotation matrix\n",
    "    x_axis = rotation[:, 0]  # X-axis is the first column\n",
    "    y_axis = rotation[:, 1]  # Y-axis is the second column\n",
    "    z_axis = rotation[:, 2]  # Z-axis is the third column\n",
    "\n",
    "    # Target direction for Z-axis (world -Z direction)\n",
    "    target_z = np.array([0, 0, -1])\n",
    "\n",
    "    # Check if the current Z-axis is already aligned with the target\n",
    "    aligned = np.isclose(np.abs(np.dot(z_axis, target_z)), 1.0, atol=1e-6)\n",
    "    if aligned and np.dot(z_axis, target_z) > 0:\n",
    "        # Already aligned, no changes needed\n",
    "        return transform\n",
    "\n",
    "    # Set new Z-axis to point down\n",
    "    new_z = target_z\n",
    "\n",
    "    # Compute a new X-axis that is orthogonal to the new Z-axis\n",
    "    # Do this by projecting the original X-axis onto the plane perpendicular to new Z\n",
    "\n",
    "    new_x = x_axis - np.dot(x_axis, new_z) * new_z\n",
    "\n",
    "    # If the projection is too small (i.e., X was almost aligned with Z), try using original Y\n",
    "    if np.linalg.norm(new_x) < 1e-6:\n",
    "        new_x = y_axis - np.dot(y_axis, new_z) * new_z\n",
    "\n",
    "    # If still too small, pick an arbitrary vector that's not parallel to Z\n",
    "    if np.linalg.norm(new_x) < 1e-6:\n",
    "        temp = np.array([1, 0, 0]) if abs(new_z[0]) < 0.9 else np.array([0, 1, 0])\n",
    "        new_x = temp - np.dot(temp, new_z) * new_z\n",
    "\n",
    "    # Normalize the new X-axis\n",
    "    new_x = new_x / np.linalg.norm(new_x)\n",
    "\n",
    "    # Calculate the new Y-axis using the cross product (ensures orthogonality)\n",
    "    new_y = np.cross(new_z, new_x)\n",
    "\n",
    "    # Construct the new rotation matrix from the orthonormal axes\n",
    "    new_rotation = np.column_stack((new_x, new_y, new_z))\n",
    "\n",
    "    # Assemble the final transformation matrix\n",
    "    new_transform = np.eye(4)\n",
    "    new_transform[:3, :3] = new_rotation\n",
    "    new_transform[:3, 3] = translation\n",
    "\n",
    "    # Evaluate alignment quality of the new Z-axis\n",
    "    result_z = new_transform[:3, :3][:, 2]\n",
    "    alignment_quality = np.dot(result_z, target_z)\n",
    "    print(f\"Z-axis alignment quality: {alignment_quality:.6f} (closer to 1 is better)\")\n",
    "\n",
    "    # Evaluate how well the XY plane orientation is preserved\n",
    "    original_xy_normal = np.cross(x_axis, y_axis)\n",
    "    original_xy_normal = original_xy_normal / np.linalg.norm(original_xy_normal)\n",
    "\n",
    "    new_xy_normal = np.cross(new_x, new_y)\n",
    "    new_xy_normal = new_xy_normal / np.linalg.norm(new_xy_normal)\n",
    "\n",
    "    xy_preservation = np.abs(np.dot(original_xy_normal, new_xy_normal))\n",
    "    print(f\"XY plane preservation quality: {xy_preservation:.6f} (closer to 1 is better)\")\n",
    "\n",
    "    return new_transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76d4d048-43c7-4a8a-ba1b-9c8e9fadcfa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import rospy\n",
    "import tf\n",
    "import numpy as np\n",
    "from geometry_msgs.msg import TransformStamped\n",
    "\n",
    "class TransformBroadcaster:\n",
    "    def __init__(self):\n",
    "        # Try to initialize the ROS node, avoid initializing multiple times\n",
    "        try:\n",
    "            rospy.init_node('tf_broadcaster_node')\n",
    "        except rospy.exceptions.ROSException:\n",
    "            pass  # If the node is already initialized, do nothing\n",
    "\n",
    "        # Create a TransformBroadcaster instance\n",
    "        self.br = tf.TransformBroadcaster()\n",
    "\n",
    "        # Assume T is the given 4x4 transformation matrix\n",
    "        self.T = np.ones((4, 4))  # Set to a 4x4 matrix\n",
    "\n",
    "        # Set a timer to call the broadcast_transform function every 100 milliseconds\n",
    "        self.timer = rospy.Timer(rospy.Duration(0.1), self.broadcast_transform)\n",
    "\n",
    "        # Store the timestamp of the last sent transformation\n",
    "        self.last_sent_time = None\n",
    "\n",
    "    def broadcast_transform(self, event):\n",
    "        try:\n",
    "            # Extract the translation and rotation parts from the 4x4 matrix\n",
    "            translation = self.T[0:3, 3]  # Translation part (x, y, z)\n",
    "            rotation_matrix = self.T[0:3, 0:3]  # Rotation matrix part\n",
    "\n",
    "            # Create a complete 4x4 matrix, including rotation and homogeneous coordinates\n",
    "            full_matrix = np.eye(4)\n",
    "            full_matrix[0:3, 0:3] = rotation_matrix\n",
    "            full_matrix[0:3, 3] = translation\n",
    "\n",
    "            # Create a quaternion to represent the rotation\n",
    "            quaternion = tf.transformations.quaternion_from_matrix(full_matrix)\n",
    "\n",
    "            # Get the current timestamp\n",
    "            current_time = rospy.Time.now()\n",
    "\n",
    "            # Check if the last sent timestamp and the current timestamp are the same\n",
    "            if self.last_sent_time is None or current_time != self.last_sent_time:\n",
    "                # Publish the transformation\n",
    "                self.br.sendTransform(\n",
    "                    (translation[0], translation[1], translation[2]),  # Translation part\n",
    "                    (quaternion[0], quaternion[1], quaternion[2], quaternion[3]),  # Rotation part (quaternion)\n",
    "                    current_time,  # Use the current timestamp\n",
    "                    \"cube\",  # Child frame name\n",
    "                    \"world\"   # Parent frame name\n",
    "                )\n",
    "                # Update the last sent timestamp\n",
    "                self.last_sent_time = current_time\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def update(self, T):\n",
    "        self.T = T\n",
    "        \n",
    "    def stop(self):\n",
    "        # Stop the timer\n",
    "        self.timer.shutdown()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4cef69-b1d4-40d5-92e0-ad3c6f59fc93",
   "metadata": {},
   "source": [
    "## 2.2 Grasp Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "155cbbb8-ad8b-4146-a453-4cdaf9afbad5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import *  # Assuming the create_grasp_mesh function is in utils.py\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "def generate_gripper_from_transform(T: np.ndarray):\n",
    "    \"\"\"\n",
    "    Generates a robotic gripper mesh from a given 4x4 transformation matrix,\n",
    "    with additional rotations around x and y axes.\n",
    "\n",
    "    Args:\n",
    "        T: 4x4 transformation matrix (numpy array).\n",
    "        \n",
    "    Returns:\n",
    "        gripper_meshes: List of meshes representing the gripper.\n",
    "    \"\"\"\n",
    "    # Extract the rotation matrix (3x3)\n",
    "    rotation_matrix = T[:3, :3]\n",
    "\n",
    "    # Extract the translation vector\n",
    "    translation = T[:3, 3]\n",
    "\n",
    "    # Set the gripper's center point position, usually the translation vector\n",
    "    center_point = translation\n",
    "\n",
    "    # Create a rotation matrix for -90 degrees around the x-axis\n",
    "    R_x = np.array([\n",
    "        [1, 0, 0],\n",
    "        [0, np.cos(-np.pi/2), -np.sin(-np.pi/2)],\n",
    "        [0, np.sin(-np.pi/2), np.cos(-np.pi/2)]\n",
    "    ])\n",
    "\n",
    "    # Create a rotation matrix for 90 degrees around the y-axis\n",
    "    R_y = np.array([\n",
    "        [np.cos(np.pi/2), 0, np.sin(np.pi/2)],\n",
    "        [0, 1, 0],\n",
    "        [-np.sin(np.pi/2), 0, np.cos(np.pi/2)]\n",
    "    ])\n",
    "    \n",
    "    R_z = np.array([\n",
    "        [0, -1, 0],\n",
    "        [1, 0, 0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    # Combine rotation matrices, first rotate around the x-axis, then around the y-axis\n",
    "    combined_rotation = R_z @ rotation_matrix @ R_x \n",
    "\n",
    "    # Call create_grasp_mesh function to generate the gripper\n",
    "    gripper_meshes = create_grasp_mesh(\n",
    "        center_point=center_point, \n",
    "        rotation_matrix=combined_rotation,\n",
    "        width=0.25\n",
    "    )\n",
    "    # Call create_grasp_mesh function to generate the gripper with a different rotation\n",
    "    gripper_meshes_rotate = create_grasp_mesh(\n",
    "        center_point=center_point, \n",
    "        rotation_matrix=rotation_matrix @ R_x,\n",
    "        width=0.25\n",
    "    )\n",
    "\n",
    "    return gripper_meshes, gripper_meshes_rotate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47315293-9f5e-4dd0-a1aa-9efab7885c1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test code: Pass in a 4x4 transformation matrix\n",
    "T = np.array([\n",
    "    [1, 0, 0, 0.1],  # Rotation matrix and translation\n",
    "    [0, 1, 0, 0.2],\n",
    "    [0, 0, 1, 0.3],\n",
    "    [0, 0, 0, 1]\n",
    "])\n",
    "\n",
    "# Call the function to generate the gripper\n",
    "gripper_meshes, _ = generate_gripper_from_transform(T)\n",
    "\n",
    "# Visualize the generated gripper\n",
    "# o3d.visualization.draw_geometries(gripper_meshes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8067b9a2-8d15-4f9e-9842-e1d6815c3d34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_grasp_collision(\n",
    "    grasp_meshes: Sequence[o3d.geometry.TriangleMesh],\n",
    "    object_pcd: o3d.geometry.TriangleMesh,\n",
    "    num_colisions: int = 10,\n",
    "    tolerance: float = 0.00001\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Checks for collisions between a gripper grasp pose and target object\n",
    "    using point cloud sampling.\n",
    "\n",
    "    Args:\n",
    "        grasp_meshes: List of mesh geometries representing the gripper components\n",
    "        object_mesh: Triangle mesh of the target object\n",
    "        num_collisions: Threshold on how many points to check\n",
    "        tolerance: Distance threshold for considering a collision (in meters)\n",
    "\n",
    "    Returns:\n",
    "        bool: True if collision detected between gripper and object, False otherwise\n",
    "    \"\"\"\n",
    "    # Combine gripper meshes\n",
    "    combined_gripper = o3d.geometry.TriangleMesh()\n",
    "    for mesh in grasp_meshes:\n",
    "        combined_gripper += mesh  # Combine multiple gripper meshes\n",
    "\n",
    "    # Sample points from both meshes\n",
    "    num_points = 5000  # Sample 5000 points from both gripper and target object\n",
    "    #######################TODO#######################\n",
    "    # Uniformly sample point clouds from both the gripper and object meshes\n",
    "    gripper_pcd = combined_gripper.sample_points_uniformly(number_of_points=num_points)\n",
    "    gripper_points = np.asarray(gripper_pcd.points)  # Point coordinates of the gripper point cloud\n",
    "    object_points = np.asarray(object_pcd.points)  # Point coordinates of the target object point cloud\n",
    "    ##################################################\n",
    "    \n",
    "    # Build KDTree for object points\n",
    "    is_collision = False\n",
    "    #######################TODO#######################\n",
    "    collision_count = 0\n",
    "    # Build a KDTree for the target object point cloud\n",
    "    object_kdtree = o3d.geometry.KDTreeFlann(object_pcd)\n",
    "    for gripper_point in gripper_points:\n",
    "        # For each gripper point, find the nearest point in the target object point cloud\n",
    "        _, _, distances = object_kdtree.search_knn_vector_3d(gripper_point, 1)  # Find the nearest neighbor\n",
    "        \n",
    "        # If the distance to the nearest neighbor is less than the tolerance, consider it a collision\n",
    "        if distances[0] <= tolerance:\n",
    "            collision_count += 1\n",
    "            \n",
    "            # Exit early if enough collisions are detected\n",
    "            if collision_count >= num_colisions:\n",
    "                is_collision = True\n",
    "                break\n",
    "    #######################TODO#######################\n",
    "\n",
    "    return is_collision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed7a038-40aa-4a06-a50d-9abae0aba06f",
   "metadata": {},
   "source": [
    "## 2.3 identify image of cubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9fcf074-462c-450a-921d-b9589f4b627f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "# from io import BytesIO\n",
    "# from PIL import Image\n",
    "# import base64\n",
    "# import json\n",
    "# SYSTEM_PROMPT = \"\"\"Please act as an image recognition agent. \n",
    "# You will be given a square face of a block, \n",
    "# which is projected from a point cloud. \n",
    "# Your task is to recognize the following:\n",
    "\n",
    "# Determine if this is a block face.\n",
    "# Each face contains only one letter, \n",
    "# one pattern (just detect whether it's a pattern, no need to identify the exact pattern), \n",
    "# or is blank (only wood texture). \n",
    "# Please detect whether it is a letter, \n",
    "# a pattern, or blank. \n",
    "# Each of these may be rotated. \n",
    "# Please analyze all possible rotations in a clockwise direction: 0°, 90°, 180°, and 270°.\n",
    "# There might be a circular border around the face. \n",
    "# Please detect if this border exists. \n",
    "# It's confirmed that the color of the border matches the color of the letter or pattern.\n",
    "# The expected output is a JSON in the following format:\n",
    "# {\n",
    "#     \"check\": true/false, \n",
    "#     \"c\": char/\"pattern\"/\"blank\", \n",
    "#     \"color\": \"green\"/\"yellow\"/\"red\"/\"blue\"/\"None\", \n",
    "#     \"rotation\": 0/90/180/270, \n",
    "#     \"circle\": true/false\n",
    "# }\n",
    "# \"\"\"\n",
    "\n",
    "# api_key=\"\"\n",
    "# client = OpenAI(api_key=api_key)\n",
    "\n",
    "# def encode_image(image, quality=100):\n",
    "#     if image.mode != 'RGB':\n",
    "#         image = image.convert('RGB')  # Convert to RGB\n",
    "#     buffered = BytesIO()\n",
    "#     image.save(buffered, format=\"JPEG\", quality=quality) \n",
    "#     return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "# def gpt4o_analysis(image_path, quality=50):\n",
    "#     with Image.open(image_path) as img:\n",
    "#         img_b64_str = encode_image(img, quality=quality)\n",
    "#     img_type = \"image/jpeg\"\n",
    "#     response = client.chat.completions.create(\n",
    "#         model=\"gpt-4o-mini\",\n",
    "#         messages=[\n",
    "#             {\n",
    "#                 \"role\": \"user\",\n",
    "#                 \"content\": [\n",
    "#                     {\"type\": \"text\", \"text\": SYSTEM_PROMPT},\n",
    "#                     {\n",
    "#                         \"type\": \"image_url\",\n",
    "#                         \"image_url\": {\"url\": f\"data:{img_type};base64,{img_b64_str}\"},\n",
    "#                     },\n",
    "#                 ],\n",
    "#             }from openai import OpenAI\n",
    "# from io import BytesIO\n",
    "# from PIL import Image\n",
    "# import base64\n",
    "# import json\n",
    "# SYSTEM_PROMPT = \"\"\"Please act as an image recognition agent. \n",
    "# You will be given a square face of a block, \n",
    "# which is projected from a point cloud. \n",
    "# Your task is to recognize the following:\n",
    "\n",
    "# Determine if this is a block face.\n",
    "# Each face contains only one letter, \n",
    "# one pattern (just detect whether it's a pattern, no need to identify the exact pattern), \n",
    "# or is blank (only wood texture). \n",
    "# Please detect whether it is a letter, \n",
    "# a pattern, or blank. \n",
    "# Each of these may be rotated. \n",
    "# Please analyze all possible rotations in a clockwise direction: 0°, 90°, 180°, and 270°.\n",
    "# There might be a circular border around the face. \n",
    "# Please detect if this border exists. \n",
    "# It's confirmed that the color of the border matches the color of the letter or pattern.\n",
    "# The expected output is a JSON in the following format:\n",
    "# {\n",
    "#     \"check\": true/false, \n",
    "#     \"c\": char/\"pattern\"/\"blank\", \n",
    "#     \"color\": \"green\"/\"yellow\"/\"red\"/\"blue\"/\"None\", \n",
    "#     \"rotation\": 0/90/180/270, \n",
    "#     \"circle\": true/false\n",
    "# }\n",
    "# \"\"\"\n",
    "\n",
    "# api_key=\"\"\n",
    "# client = OpenAI(api_key=api_key)\n",
    "\n",
    "# def encode_image(image, quality=100):\n",
    "#     if image.mode != 'RGB':\n",
    "#         image = image.convert('RGB')  # Convert to RGB\n",
    "#     buffered = BytesIO()\n",
    "#     image.save(buffered, format=\"JPEG\", quality=quality) \n",
    "#     return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "# def gpt4o_analysis(image_path, quality=50):\n",
    "#     with Image.open(image_path) as img:\n",
    "#         img_b64_str = encode_image(img, quality=quality)\n",
    "#     img_type = \"image/jpeg\"\n",
    "#     response = client.chat.completions.create(\n",
    "#         model=\"gpt-4o-mini\",\n",
    "#         messages=[\n",
    "#             {\n",
    "#                 \"role\": \"user\",\n",
    "#                 \"content\": [\n",
    "#                     {\"type\": \"text\", \"text\": SYSTEM_PROMPT},\n",
    "#                     {\n",
    "#                         \"type\": \"image_url\",\n",
    "#                         \"image_url\": {\"url\": f\"data:{img_type};base64,{img_b64_str}\"},\n",
    "#                     },\n",
    "#                 ],\n",
    "#             }\n",
    "#         ],\n",
    "#     )\n",
    "#     return response.choices[0].message.content\n",
    "#         ],\n",
    "#     )\n",
    "#     return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "348b83d4-ff09-4bbd-a7f0-b5a606c423ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8179587526400796\n",
      "0\n",
      "[[ 4.38259844e-02 -9.99037767e-01 -1.67999712e-03  5.97930303e-01]\n",
      " [-9.98841455e-01 -4.38507035e-02  1.98208077e-02  3.69790012e-01]\n",
      " [-1.98754045e-02  8.09384358e-04 -9.99802137e-01  2.22112274e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "[0.5979303030658479, 0.36979001166844633, 0.12221122735515641] [3.1407831092297234, 0.019876713333704332, -1.5269476334677399]\n",
      "0.7434186132740082\n",
      "0.7347262382240463\n",
      "0.8167718273086129\n",
      "1\n",
      "[[ 0.03674522 -0.99932316  0.00173772  0.59801578]\n",
      " [-0.99908252 -0.03669799  0.02207643  0.1298582 ]\n",
      " [-0.02199771 -0.00254732 -0.99975478  0.02223913]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "[0.5980157750702272, 0.12985820163686562, 0.1222391338536466] [-3.1390447095189127, 0.021999488251177812, -1.534033930286436]\n",
      "0.7154297420616444\n",
      "Correcting Z axis\n",
      "0.8271129603179532\n",
      "2\n",
      "[[-0.04285631 -0.99891833  0.01804187  0.59952656]\n",
      " [-0.99907866  0.0428903   0.0015007   0.20850403]\n",
      " [-0.0022729  -0.01796093 -0.99983611  0.02229985]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "[0.5995265616507968, 0.20850403034644716, 0.12229985352413258] [-3.1236307076739243, 0.002272898630468534, -1.613665880456978]\n",
      "0.8241904939306448\n",
      "3\n",
      "[[-0.03025034 -0.99943026  0.01496937  0.59946423]\n",
      " [-0.99953686  0.03029646  0.00286342  0.28832629]\n",
      " [-0.00331531 -0.01487582 -0.99988385  0.02227341]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "[0.5994642308382462, 0.2883262941633688, 0.12227341332262778] [-3.126716207716669, 0.003315314053736085, -1.6010514500011193]\n",
      "0.8141260478112388\n",
      "4\n",
      "[[ 0.04147818 -0.99913766 -0.001871    0.59790764]\n",
      " [-0.99907257 -0.04149699  0.01148939  0.04982466]\n",
      " [-0.01155712  0.0013927  -0.99993224  0.02226342]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "[0.5979076357800378, 0.049824663007881395, 0.12226342258150172] [3.140199856887071, 0.011557379112179245, -1.529303471808745]\n",
      "0.7157358830285909\n",
      "Correcting Z axis\n",
      "0.8366465801080947\n",
      "5\n",
      "[[-4.80781106e-02  9.98841966e-01  1.79509681e-03  5.99326677e-01]\n",
      " [ 9.98843579e-01  4.80780254e-02  9.06282931e-05 -2.68577816e-01]\n",
      " [ 4.21863254e-06  1.79737816e-03 -9.99998385e-01  2.23413932e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "[0.5993266766115707, -0.2685778157893077, 0.12234139319875062] [3.1397952744636584, -4.21863253907695e-06, 1.618892978827248]\n",
      "0.8372763635236117\n",
      "6\n",
      "[[-4.13912212e-02  9.99141734e-01 -1.60097669e-03  5.99507071e-01]\n",
      " [ 9.99142646e-01  4.13897730e-02 -9.27374946e-04 -3.48351417e-01]\n",
      " [-8.60314950e-04 -1.63798927e-03 -9.99998288e-01  2.23075017e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "[0.5995070709378694, -0.34835141673931524, 0.12230750166220108] [-3.1399546629838535, 0.000860315055774219, 1.612199391278666]\n",
      "0.561489526764934\n",
      "0.8291582386805664\n",
      "7\n",
      "[[-0.03778534 -0.99925756 -0.0075229   0.59782996]\n",
      " [-0.99917169  0.03789376 -0.014832   -0.18992582]\n",
      " [ 0.01510606  0.00695624 -0.9998617   0.02230128]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "[0.5978299571381572, -0.18992582301247646, 0.1223012771438195] [3.134635564188757, -0.01510663049611316, -1.6085949799773145]\n",
      "0.6200984975999002\n",
      "Correcting Z axis\n",
      "0.7520414816654765\n",
      "8\n",
      "[[ 0.00245458 -0.99992054  0.01236506  0.59935563]\n",
      " [-0.99999611 -0.00247073 -0.00129102 -0.10969593]\n",
      " [ 0.00132147 -0.01236184 -0.99992272  0.02242817]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "[0.599355633686584, -0.10969593237526254, 0.12242816781163934] [-3.1292304854079798, -0.001321472275826796, -1.568341743205685]\n",
      "0.7422897921191437\n",
      "9\n",
      "[[ 1.64893485e-03 -9.99893833e-01  1.44777025e-02  5.99376774e-01]\n",
      " [-9.99998575e-01 -1.64350960e-03  3.86621085e-04 -3.00879562e-02]\n",
      " [-3.62785796e-04 -1.44783194e-02 -9.99895118e-01  2.24589012e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "[0.5993767735079396, -0.030087956237759502, 0.12245890122198383] [-3.1271138273976926, 0.00036278580382842485, -1.5691473910903841]\n",
      "[array([[ 4.38259844e-02, -9.99037767e-01, -1.67999712e-03,\n",
      "         5.97930303e-01],\n",
      "       [-9.98841455e-01, -4.38507035e-02,  1.98208077e-02,\n",
      "         3.69790012e-01],\n",
      "       [-1.98754045e-02,  8.09384358e-04, -9.99802137e-01,\n",
      "         2.22112274e-02],\n",
      "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "         1.00000000e+00]]), array([[ 0.03674522, -0.99932316,  0.00173772,  0.59801578],\n",
      "       [-0.99908252, -0.03669799,  0.02207643,  0.1298582 ],\n",
      "       [-0.02199771, -0.00254732, -0.99975478,  0.02223913],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]]), array([[-0.04285631, -0.99891833,  0.01804187,  0.59952656],\n",
      "       [-0.99907866,  0.0428903 ,  0.0015007 ,  0.20850403],\n",
      "       [-0.0022729 , -0.01796093, -0.99983611,  0.02229985],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]]), array([[-0.03025034, -0.99943026,  0.01496937,  0.59946423],\n",
      "       [-0.99953686,  0.03029646,  0.00286342,  0.28832629],\n",
      "       [-0.00331531, -0.01487582, -0.99988385,  0.02227341],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]]), array([[ 0.04147818, -0.99913766, -0.001871  ,  0.59790764],\n",
      "       [-0.99907257, -0.04149699,  0.01148939,  0.04982466],\n",
      "       [-0.01155712,  0.0013927 , -0.99993224,  0.02226342],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]]), array([[-4.80781106e-02,  9.98841966e-01,  1.79509681e-03,\n",
      "         5.99326677e-01],\n",
      "       [ 9.98843579e-01,  4.80780254e-02,  9.06282931e-05,\n",
      "        -2.68577816e-01],\n",
      "       [ 4.21863254e-06,  1.79737816e-03, -9.99998385e-01,\n",
      "         2.23413932e-02],\n",
      "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "         1.00000000e+00]]), array([[-4.13912212e-02,  9.99141734e-01, -1.60097669e-03,\n",
      "         5.99507071e-01],\n",
      "       [ 9.99142646e-01,  4.13897730e-02, -9.27374946e-04,\n",
      "        -3.48351417e-01],\n",
      "       [-8.60314950e-04, -1.63798927e-03, -9.99998288e-01,\n",
      "         2.23075017e-02],\n",
      "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "         1.00000000e+00]]), array([[-0.03778534, -0.99925756, -0.0075229 ,  0.59782996],\n",
      "       [-0.99917169,  0.03789376, -0.014832  , -0.18992582],\n",
      "       [ 0.01510606,  0.00695624, -0.9998617 ,  0.02230128],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]]), array([[ 0.00245458, -0.99992054,  0.01236506,  0.59935563],\n",
      "       [-0.99999611, -0.00247073, -0.00129102, -0.10969593],\n",
      "       [ 0.00132147, -0.01236184, -0.99992272,  0.02242817],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]]), array([[ 1.64893485e-03, -9.99893833e-01,  1.44777025e-02,\n",
      "         5.99376774e-01],\n",
      "       [-9.99998575e-01, -1.64350960e-03,  3.86621085e-04,\n",
      "        -3.00879562e-02],\n",
      "       [-3.62785796e-04, -1.44783194e-02, -9.99895118e-01,\n",
      "         2.24589012e-02],\n",
      "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "         1.00000000e+00]])]\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PointCloud2Image import enlarge_points_as_cubes, max_downsample_image, pointcloud_to_top_view_image_color, interpolate_sparse_image, pointcloud_to_colored_image_with_filling, triangle_mesh_to_image\n",
    "\n",
    "try:\n",
    "    broadcaster\n",
    "except NameError:\n",
    "    broadcaster = TransformBroadcaster()           \n",
    "    \n",
    "cube_num = 26\n",
    "def pointcloud_process(point_cloud, slice_tolerance=0.005):\n",
    "    '''\n",
    "        Identify the cubes\n",
    "        Returns:\n",
    "            [\n",
    "                json,\n",
    "                T\n",
    "            ]\n",
    "    '''\n",
    "    orignal_point_cloud = copy.deepcopy(point_cloud)\n",
    "    T = []\n",
    "    remaining_pointcloud_count = 10000\n",
    "    countdown = 50\n",
    "    # Use open3d to visualize the point cloud\n",
    "    # o3d.visualization.draw_geometries([layer_point_cloud], window_name=f\"Layer {layer} (Z range: {z_min:.4f} to {z_max:.4f})\")\n",
    "    movecount = 0\n",
    "    while remaining_pointcloud_count > 50 and countdown > 0:\n",
    "        cube_point_cloud = cube_mesh.sample_points_uniformly(number_of_points=50000) \n",
    "        cube_point_cloud = filter_point_cloud_by_depth(cube_point_cloud, depth_threshold=-0.01)\n",
    "        transform, remaining_pointcloud, deleted_pointcloud, fitness = register_and_filter(point_cloud, cube_point_cloud)\n",
    "        remaining_pointcloud_count = len(remaining_pointcloud.points)\n",
    "        # return transform, remaining_pointcloud, deleted_pointcloud\n",
    "        if fitness > 0.01:\n",
    "            countdown = countdown - 1\n",
    "        print(fitness)\n",
    "        if check_transform_z_axis_alignment(transform) and fitness > 0.50 and np.array_equal(transform, align_transform_z_axis(transform)):\n",
    "        # if fitness > 0.70:\n",
    "            if movecount >= cube_num:\n",
    "                break\n",
    "            print(movecount)\n",
    "            \n",
    "\n",
    "            broadcaster.update(transform)\n",
    "            cube_coordinate_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "                size=0.1,  # Coordinate axis size, can be adjusted as needed\n",
    "                origin=[0, 0, 0]  # Origin of the coordinate axis\n",
    "            )\n",
    "            theta = np.radians(45)  # Convert angle to radians\n",
    "            transform_matrix_x_180 = np.array([\n",
    "                [1, 0, 0, 0],\n",
    "                [0, -1, 0, 0],\n",
    "                [0, 0, -1, 0],\n",
    "                [0, 0, 0, 1]\n",
    "            ])\n",
    "            transform_matrix_z_90 = np.array([\n",
    "                [0, -1, 0, 0],\n",
    "                [1, 0, 0, 0],\n",
    "                [0, 0, 1, 0],\n",
    "                [0, 0, 0, 1]\n",
    "            ])\n",
    "            graps_transform = transform @ transform_matrix_x_180\n",
    "            graps_transform_rotate = transform @ transform_matrix_x_180 @ transform_matrix_z_90\n",
    "                        # o3d.visualization.draw_geometries([coordinate_frame, remaining_pointcloud], window_name=\"remaining_pointcloud\")\n",
    "            cube_point_cloud_transormed = copy.deepcopy(deleted_pointcloud)\n",
    "            cube_point_cloud_transormed = cube_point_cloud_transormed.transform(np.linalg.inv(graps_transform))\n",
    "            cube_point_cloud_transormed_cubes = enlarge_points_as_cubes(cube_point_cloud_transormed)\n",
    "\n",
    "            cube_top_image = triangle_mesh_to_image(cube_point_cloud_transormed_cubes, image_size=(100, 100))\n",
    "            cube_top_image = (cube_top_image / cube_top_image.max() * 255).astype(np.uint8)\n",
    "            grasp_coordinate_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "                size=0.1,  # Coordinate axis size, can be adjusted as needed\n",
    "                origin=[0, 0, 0]  # Origin of the coordinate axis\n",
    "            )\n",
    "            grasp_mesh, gripper_meshes_rotate = generate_gripper_from_transform(graps_transform)\n",
    "            # Apply transformation matrix to the coordinate frame\n",
    "            grasp_coordinate_frame.transform(graps_transform)\n",
    "            grasp_final_matrix = None\n",
    "            # o3d.visualization.draw_geometries(grasp_mesh+gripper_meshes_rotate+[orignal_point_cloud, coordinate_frame], window_name=\"remaining_pointcloud\")\n",
    "            if check_grasp_collision(grasp_mesh, orignal_point_cloud):\n",
    "            # if check_grasp_collision(grasp_mesh, deleted_pointcloud):\n",
    "                # If collision\n",
    "                grasp_mesh = []\n",
    "            else:\n",
    "                grasp_final_matrix = graps_transform\n",
    "            if check_grasp_collision(gripper_meshes_rotate, orignal_point_cloud):\n",
    "            # if check_grasp_collision(gripper_meshes_rotate, deleted_pointcloud):\n",
    "                gripper_meshes_rotate = []\n",
    "            else:\n",
    "                grasp_final_matrix = graps_transform_rotate\n",
    "            # o3d.visualization.draw_geometries(grasp_mesh+gripper_meshes_rotate+[grasp_coordinate_frame, deleted_pointcloud, coordinate_frame], window_name=\"deleted_pointcloud\")\n",
    "            # o3d.visualization.draw_geometries(grasp_mesh+gripper_meshes_rotate+[grasp_coordinate_frame, remaining_pointcloud, coordinate_frame], window_name=\"deleted_pointcloud\")\n",
    "            if grasp_final_matrix is not None: # Can move\n",
    "                countdown = 50\n",
    "                print(grasp_final_matrix)\n",
    "                movecount += 1\n",
    "                pick_rpy, pick_pos = matrix_to_rpy_and_translation(grasp_final_matrix)\n",
    "                pick_pos_ = [a + b for a, b in zip(pick_pos, [0, 0, 0.10])]\n",
    "                pick_rpy = [a + b for a, b in zip(pick_rpy, [0, 0, 0])]\n",
    "                # pick_place.move(pick_pos_, pick_rpy)\n",
    "                print(pick_pos_, pick_rpy)\n",
    "                # cube_top_image = point_cloud_to_image(cube_point_cloud_transormed)\n",
    "                plt.imsave(f\"test_{movecount}.png\", cube_top_image)\n",
    "                plt.show()\n",
    "                point_cloud = remaining_pointcloud\n",
    "                # TODO: Identify the first face\n",
    "            \n",
    "                T.append(grasp_final_matrix)\n",
    "        else:\n",
    "            cube_point_cloud = cube_mesh.sample_points_uniformly(number_of_points=50000)\n",
    "            cube_point_cloud = filter_point_cloud_by_depth(cube_point_cloud, depth_threshold=-0.01)\n",
    "    print(T)\n",
    "    return T\n",
    "\n",
    "# def pointcloud_process(point_cloud, slice_tolerance=0.005, cube_num=cube_num):\n",
    "#     '''\n",
    "#     Identify the cubes in a point cloud and determine their transformation matrices for grasping.\n",
    "#     Handles alignment of Z-axis in any orientation for proper grasping.\n",
    "    \n",
    "#     Args:\n",
    "#         point_cloud: The input point cloud containing cubes to be identified\n",
    "#         slice_tolerance: Tolerance for slicing the point cloud\n",
    "#         cube_num: Maximum number of cubes to detect\n",
    "        \n",
    "#     Returns:\n",
    "#         A list of transformation matrices for grasping the identified cubes\n",
    "#     '''\n",
    "#     original_point_cloud = copy.deepcopy(point_cloud)\n",
    "#     T = []\n",
    "#     remaining_pointcloud = point_cloud\n",
    "#     remaining_pointcloud_count = len(point_cloud.points)\n",
    "#     countdown = 50\n",
    "#     movecount = 0\n",
    "    \n",
    "#     # Define standard transformation matrices for grasping\n",
    "#     transform_matrix_x_180 = np.array([\n",
    "#         [1, 0, 0, 0],\n",
    "#         [0, -1, 0, 0],\n",
    "#         [0, 0, -1, 0],\n",
    "#         [0, 0, 0, 1]\n",
    "#     ])\n",
    "    \n",
    "#     transform_matrix_z_90 = np.array([\n",
    "#         [0, -1, 0, 0],\n",
    "#         [1, 0, 0, 0],\n",
    "#         [0, 0, 1, 0],\n",
    "#         [0, 0, 0, 1]\n",
    "#     ])\n",
    "    \n",
    "#     # Function to check if a cube's z-axis points approximately downward\n",
    "#     def is_z_axis_pointing_down(transform):\n",
    "#         z_axis = transform[:3, 2]  # Extract z-axis vector\n",
    "#         return np.dot(z_axis, np.array([0, 0, -1])) > 0.8  # Check if close to pointing down\n",
    "    \n",
    "#     while remaining_pointcloud_count > 50 and countdown > 0 and movecount < cube_num:\n",
    "#         # Sample points from the cube mesh model\n",
    "#         cube_point_cloud = cube_mesh.sample_points_uniformly(number_of_points=50000) \n",
    "#         cube_point_cloud = filter_point_cloud_by_depth(cube_point_cloud, depth_threshold=-0.01)\n",
    "        \n",
    "#         # Register the cube in the point cloud\n",
    "#         transform, remaining_pointcloud, deleted_pointcloud, fitness = register_and_filter(\n",
    "#             remaining_pointcloud, cube_point_cloud\n",
    "#         )\n",
    "        \n",
    "#         remaining_pointcloud_count = len(remaining_pointcloud.points)\n",
    "        \n",
    "#         # Decrement countdown if the fitness is above a minimum threshold\n",
    "#         if fitness > 0.01:\n",
    "#             countdown -= 1\n",
    "            \n",
    "#         print(f\"Iteration {50-countdown}: Fitness = {fitness:.4f}, Remaining points: {remaining_pointcloud_count}\")\n",
    "        \n",
    "#         # Check if the fitness is above the acceptable threshold\n",
    "#         if fitness > 0.40:  # Lowered threshold slightly for more detections\n",
    "#             print(f\"Processing cube #{movecount+1}\")\n",
    "            \n",
    "#             # Align the Z-axis to point downward regardless of original orientation\n",
    "#             aligned_transform = align_transform_z_axis_any_orientation(transform)\n",
    "            \n",
    "#             # Update the transform broadcaster for visualization\n",
    "#             if 'broadcaster' in globals():\n",
    "#                 broadcaster.update(aligned_transform)\n",
    "            \n",
    "#             # Create grasp transforms\n",
    "#             grasp_transform = aligned_transform @ transform_matrix_x_180\n",
    "#             grasp_transform_rotate = aligned_transform @ transform_matrix_x_180 @ transform_matrix_z_90\n",
    "            \n",
    "#             # Transform the detected cube point cloud for visualization\n",
    "#             cube_point_cloud_transformed = copy.deepcopy(deleted_pointcloud)\n",
    "#             cube_point_cloud_transformed = cube_point_cloud_transformed.transform(np.linalg.inv(grasp_transform))\n",
    "            \n",
    "#             # For generating a visual representation as a top-down view\n",
    "#             try:\n",
    "#                 cube_point_cloud_transformed_cubes = enlarge_points_as_cubes(cube_point_cloud_transformed)\n",
    "#                 cube_top_image = triangle_mesh_to_image(cube_point_cloud_transformed_cubes, image_size=(100, 100))\n",
    "#                 cube_top_image = (cube_top_image / cube_top_image.max() * 255).astype(np.uint8)\n",
    "#                 plt.imsave(f\"cube_{movecount+1}_top_view.png\", cube_top_image)\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Warning: Could not generate top view image: {e}\")\n",
    "            \n",
    "#             # Generate gripper meshes for collision checking\n",
    "#             grasp_mesh, gripper_meshes_rotate = generate_gripper_from_transform(grasp_transform)\n",
    "            \n",
    "#             # Find a valid grasp without collisions\n",
    "#             grasp_final_matrix = None\n",
    "            \n",
    "#             # Check first grasping orientation\n",
    "#             if not check_grasp_collision(grasp_mesh, original_point_cloud):\n",
    "#                 grasp_final_matrix = grasp_transform\n",
    "#                 print(\"Using standard grasp orientation\")\n",
    "#             # Check alternative grasping orientation (rotated by 90° around Z)\n",
    "#             elif not check_grasp_collision(gripper_meshes_rotate, original_point_cloud):\n",
    "#                 grasp_final_matrix = grasp_transform_rotate\n",
    "#                 print(\"Using 90° rotated grasp orientation\")\n",
    "#             else:\n",
    "#                 print(\"Both grasp orientations have collisions, skipping this cube\")\n",
    "                \n",
    "#             # If a valid grasp pose was found\n",
    "#             if grasp_final_matrix is not None:\n",
    "#                 # Reset countdown\n",
    "#                 countdown = 50\n",
    "                \n",
    "#                 # Calculate RPY and position for robot movement\n",
    "#                 pick_rpy, pick_pos = matrix_to_rpy_and_translation(grasp_final_matrix)\n",
    "#                 approach_offset = [0, 0, 0.10]  # 10cm above the cube for approach\n",
    "#                 pick_pos_approach = [a + b for a, b in zip(pick_pos, approach_offset)]\n",
    "                \n",
    "#                 print(f\"Cube #{movecount+1} grasp position: {pick_pos}\")\n",
    "#                 print(f\"Approach position: {pick_pos_approach}\")\n",
    "#                 print(f\"RPY orientation: {pick_rpy}\")\n",
    "                \n",
    "#                 # Add the transform to our results\n",
    "#                 T.append(grasp_final_matrix)\n",
    "#                 movecount += 1\n",
    "                \n",
    "#                 # Optional visualization of the detected cube\n",
    "#                 # o3d.visualization.draw_geometries([deleted_pointcloud], window_name=f\"Detected Cube #{movecount}\")\n",
    "                \n",
    "#                 # Optional visualization of the grasp\n",
    "#                 # vis_geometries = grasp_mesh + [create_coordinate_frame(0.1)]\n",
    "#                 # o3d.visualization.draw_geometries(vis_geometries, window_name=f\"Grasp Visualization #{movecount}\")\n",
    "#         else:\n",
    "#             # If fitness is too low, don't change the countdown\n",
    "#             pass\n",
    "    \n",
    "#     print(f\"Found {len(T)} cubes from {50-countdown} iterations\")\n",
    "    \n",
    "#     # Print the final transforms\n",
    "#     for i, transform in enumerate(T):\n",
    "#         print(f\"Cube #{i+1} Transform:\")\n",
    "#         print(transform)\n",
    "        \n",
    "#     return T\n",
    "def pointcloud_process_2(point_cloud, slice_tolerance=0.005, cube_num=4):\n",
    "    '''\n",
    "    在点云中识别立方体并确定抓取的变换矩阵。\n",
    "    使用改进的Z轴对齐方法，保持XY平面的一致性，以减少对齐误差。\n",
    "    \n",
    "    参数：\n",
    "        point_cloud: 输入的点云，包含要检测的立方体\n",
    "        slice_tolerance: 用于切割点云的容差值\n",
    "        cube_num: 最大检测的立方体数量\n",
    "        \n",
    "    返回：\n",
    "        与检测到的可抓取立方体对应的变换矩阵列表\n",
    "    '''\n",
    "    original_point_cloud = copy.deepcopy(point_cloud)\n",
    "    T = []\n",
    "    remaining_pointcloud = point_cloud\n",
    "    remaining_pointcloud_count = len(point_cloud.points)\n",
    "    countdown = 50\n",
    "    movecount = 0\n",
    "\n",
    "    # 定义用于抓取方向的标准变换矩阵\n",
    "    transform_matrix_x_180 = np.array([\n",
    "        [1, 0, 0, 0],\n",
    "        [0, -1, 0, 0],\n",
    "        [0, 0, -1, 0],\n",
    "        [0, 0, 0, 1]\n",
    "    ])\n",
    "\n",
    "    transform_matrix_z_90 = np.array([\n",
    "        [0, -1, 0, 0],\n",
    "        [1,  0, 0, 0],\n",
    "        [0,  0, 1, 0],\n",
    "        [0,  0, 0, 1]\n",
    "    ])\n",
    "\n",
    "    # 添加一个额外的Z轴反转矩阵，用于确保Z轴朝下\n",
    "    transform_matrix_z_down = np.array([\n",
    "        [1, 0, 0, 0],\n",
    "        [0, 1, 0, 0],\n",
    "        [0, 0, -1, 0],\n",
    "        [0, 0, 0, 1]\n",
    "    ])\n",
    "\n",
    "    # 迭代查找并提取立方体\n",
    "    while remaining_pointcloud_count > 50 and countdown > 0 and movecount < cube_num:\n",
    "        # 从立方体网格模型中采样点\n",
    "        cube_point_cloud = cube_mesh.sample_points_uniformly(number_of_points=50000) \n",
    "        cube_point_cloud = filter_point_cloud_by_depth(cube_point_cloud, depth_threshold=-0.01)\n",
    "\n",
    "        # 将立方体与当前剩余的场景点云进行配准\n",
    "        transform, remaining_pointcloud, deleted_pointcloud, fitness = register_and_filter(\n",
    "            remaining_pointcloud, cube_point_cloud\n",
    "        )\n",
    "\n",
    "        remaining_pointcloud_count = len(remaining_pointcloud.points)\n",
    "\n",
    "        # 如果匹配度超过最小阈值，则减少倒计时\n",
    "        if fitness > 0.01:\n",
    "            countdown -= 1\n",
    "\n",
    "        print(f\"迭代 {50 - countdown}: 匹配度 = {fitness:.4f}, 剩余点数: {remaining_pointcloud_count}\")\n",
    "\n",
    "        # 仅在匹配足够好时继续\n",
    "        if fitness > 0.40:  # 略微降低阈值以检测更多立方体\n",
    "            print(f\"正在处理立方体 #{movecount+1}\")\n",
    "\n",
    "            # 对齐Z轴向下，同时保持XY方向\n",
    "            aligned_transform = align_transform_z_axis_preserving_xy(transform)\n",
    "\n",
    "            # 更新变换广播器（用于RViz等可视化）\n",
    "            if 'broadcaster' in globals():\n",
    "                broadcaster.update(aligned_transform)\n",
    "\n",
    "            # 创建抓取变换\n",
    "            grasp_transform = aligned_transform @ transform_matrix_x_180\n",
    "            grasp_transform_rotate = aligned_transform @ transform_matrix_x_180 @ transform_matrix_z_90\n",
    "            # 再次检查并确保最终的抓取变换Z轴朝下\n",
    "            z_axis_grasp = grasp_transform[:3, 2]\n",
    "            if z_axis_grasp[2] > 0:\n",
    "                grasp_transform = grasp_transform @ transform_matrix_z_down\n",
    "                print(\"已调整grasp_transform以确保Z轴朝下\")\n",
    "            \n",
    "            z_axis_grasp_rotate = grasp_transform_rotate[:3, 2]\n",
    "            if z_axis_grasp_rotate[2] > 0:\n",
    "                grasp_transform_rotate = grasp_transform_rotate @ transform_matrix_z_down\n",
    "                print(\"已调整grasp_transform_rotate以确保Z轴朝下\")\n",
    "\n",
    "            # 转换检测到的立方体点云（用于可视化或检查）\n",
    "            cube_point_cloud_transformed = copy.deepcopy(deleted_pointcloud)\n",
    "            cube_point_cloud_transformed = cube_point_cloud_transformed.transform(np.linalg.inv(grasp_transform))\n",
    "\n",
    "            # 尝试生成检测到的立方体的顶部视图图像\n",
    "            try:\n",
    "                cube_point_cloud_transformed_cubes = enlarge_points_as_cubes(cube_point_cloud_transformed)\n",
    "                cube_top_image = triangle_mesh_to_image(cube_point_cloud_transformed_cubes, image_size=(100, 100))\n",
    "                cube_top_image = (cube_top_image / cube_top_image.max() * 255).astype(np.uint8)\n",
    "                plt.imsave(f\"cube_{movecount+1}_top_view.png\", cube_top_image)\n",
    "            except Exception as e:\n",
    "                print(f\"警告: 无法生成顶部视图图像: {e}\")\n",
    "\n",
    "            # 为碰撞检查生成抓取器网格\n",
    "            grasp_mesh, gripper_meshes_rotate = generate_gripper_from_transform(grasp_transform)\n",
    "\n",
    "            # 尝试两种抓取方向，并选择没有碰撞的一种\n",
    "            grasp_final_matrix = None\n",
    "            \n",
    "            # 尝试标准抓取方向\n",
    "            if not check_grasp_collision(grasp_mesh, original_point_cloud):\n",
    "                grasp_final_matrix = grasp_transform\n",
    "                print(\"使用标准抓取方向\")\n",
    "            # 尝试旋转90°的抓取方向\n",
    "            elif not check_grasp_collision(gripper_meshes_rotate, original_point_cloud):\n",
    "                grasp_final_matrix = grasp_transform_rotate\n",
    "                print(\"使用旋转90°的抓取方向\")\n",
    "            else:\n",
    "                print(\"两种抓取方向都发生碰撞，跳过此立方体\")\n",
    "\n",
    "            # 如果找到有效的抓取，则保存该变换矩阵\n",
    "            if grasp_final_matrix is not None:\n",
    "                countdown = 50  # 重置倒计时\n",
    "\n",
    "                # 计算用于运动规划的RPY和位置\n",
    "                pick_rpy, pick_pos = matrix_to_rpy_and_translation(grasp_final_matrix)\n",
    "                approach_offset = [0, 0, 0.10]  # 立方体上方10cm处\n",
    "                pick_pos_approach = [a + b for a, b in zip(pick_pos, approach_offset)]\n",
    "\n",
    "                print(f\"立方体 #{movecount+1} 抓取位置: {pick_pos}\")\n",
    "                print(f\"接近位置: {pick_pos_approach}\")\n",
    "                print(f\"RPY方向: {pick_rpy}\")\n",
    "\n",
    "                # 将变换矩阵添加到结果列表\n",
    "                T.append(grasp_final_matrix)\n",
    "                movecount += 1\n",
    "\n",
    "                # 可选：显示抓取变换矩阵\n",
    "                print(\"抓取变换矩阵:\")\n",
    "                print(grasp_final_matrix)\n",
    "\n",
    "                # 可选：可视化抓取\n",
    "                vis_geometries = grasp_mesh\n",
    "                vis_geometries.append(create_coordinate_frame(0.1))\n",
    "                aligned_coordinate_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1)\n",
    "                # aligned_coordinate_frame.transform(aligned_transform)\n",
    "                aligned_coordinate_frame.transform(grasp_transform_rotate)\n",
    "                vis_geometries.append(aligned_coordinate_frame)\n",
    "                # vis_geometries.append(deleted_pointcloud)\n",
    "                # vis_geometries.append(remaining_pointcloud)\n",
    "                vis_geometries.append(original_point_cloud)\n",
    "\n",
    "                # 调用Open3D的可视化函数，传入正确格式的列表\n",
    "                o3d.visualization.draw_geometries(vis_geometries, window_name=f\"grasp visualization #{movecount}\")\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"在 {50 - countdown} 次迭代中找到 {len(T)} 个立方体\")\n",
    "\n",
    "    # 打印最终的抓取变换矩阵\n",
    "    for i, transform in enumerate(T):\n",
    "        print(f\"立方体 #{i+1} 变换:\")\n",
    "        print(transform)\n",
    "\n",
    "    return T\n",
    "           \n",
    "Ts = pointcloud_process(filtered_point_cloud)\n",
    "broadcaster.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a266f54-a76e-4263-8be7-958b208f8df2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ts.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7be0151b-983a-4f9f-b066-f8220e1f2f6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import copy\n",
    "\n",
    "def generate_pascal_triangle_transforms(t, T):\n",
    "    \"\"\"\n",
    "    Generate a list of transformation matrices for a Pascal triangle arrangement.\n",
    "    Each cube's center position is used as the translation part of the transform matrix.\n",
    "    \"\"\"\n",
    "    level = 1\n",
    "    total = 1\n",
    "    while total < t:\n",
    "        level += 1\n",
    "        total += level\n",
    "\n",
    "    transforms = []\n",
    "    cube_size = 0.045  # 4.5 cm\n",
    "    spacing_xy = cube_size * 1.25  # Increase spacing to 1.25 times the cube size\n",
    "    spacing_z = cube_size * 1.05   # Use the same spacing in the vertical direction\n",
    "\n",
    "    current_pos = 0\n",
    "    for row in range(level-1, -1, -1):\n",
    "        for col in range(row + 1):\n",
    "            if current_pos >= t:\n",
    "                break\n",
    "\n",
    "            center_x = 0\n",
    "            center_y = (col - row/2) * spacing_xy\n",
    "            center_z = (level - 1 - row) * spacing_z\n",
    "\n",
    "            # Create local transformation matrix\n",
    "            local_transform = np.eye(4)\n",
    "            local_transform[:3, 3] = [center_x, center_y, center_z]\n",
    "\n",
    "            # Combine local transformation with T transformation\n",
    "            transform = np.dot(T, local_transform)\n",
    "            transforms.append(transform)\n",
    "            current_pos += 1\n",
    "\n",
    "        if current_pos >= t:\n",
    "            break\n",
    "\n",
    "    return transforms\n",
    "\n",
    "def create_coordinate_frame(size=0.1, transform=None):\n",
    "    frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=size)\n",
    "    if transform is not None:\n",
    "        frame.transform(transform)\n",
    "    return frame\n",
    "\n",
    "def visualize_pascal_triangle(transforms, T):\n",
    "    # Create a cube centered at the origin\n",
    "    cube = o3d.geometry.TriangleMesh.create_box(\n",
    "        width=0.045,\n",
    "        height=0.045, \n",
    "        depth=0.045\n",
    "    )\n",
    "    # Move the cube to be centered at the origin\n",
    "    cube.translate([-0.045/2, -0.045/2, -0.045/2])\n",
    "    cube.compute_vertex_normals()\n",
    "\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.create_window()\n",
    "\n",
    "    # Add world coordinate frame\n",
    "    world_frame = create_coordinate_frame(size=0.2)\n",
    "    vis.add_geometry(world_frame)\n",
    "\n",
    "    # Add T coordinate frame\n",
    "    t_frame = create_coordinate_frame(size=0.2, transform=T)\n",
    "    vis.add_geometry(t_frame)\n",
    "\n",
    "    # Add all cubes and their local coordinate frames\n",
    "    for transform in transforms:\n",
    "        # Add cube\n",
    "        cube_copy = copy.deepcopy(cube)\n",
    "        cube_copy.transform(transform)\n",
    "        vis.add_geometry(cube_copy)\n",
    "        \n",
    "        # Add local coordinate frame\n",
    "        local_frame = create_coordinate_frame(size=0.05, transform=transform)\n",
    "        vis.add_geometry(local_frame)\n",
    "\n",
    "    opt = vis.get_render_option()\n",
    "    opt.background_color = np.asarray([0.5, 0.5, 0.5])\n",
    "\n",
    "    ctr = vis.get_view_control()\n",
    "    ctr.set_zoom(0.2)  # Adjust zoom to fit larger spacing\n",
    "    ctr.set_front([-0.8, -0.5, 0.5])\n",
    "    ctr.set_lookat([0, 0, 0])\n",
    "    ctr.set_up([0, 0, 1])\n",
    "\n",
    "    vis.run()\n",
    "    vis.destroy_window()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f396100-4bfb-4740-a839-6a5cef0fbb07",
   "metadata": {},
   "source": [
    "# 3. Motion Planning, movement, and grasp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0ff91c9-6108-48f9-8132-1d623b646c89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import generate_pascal_triangle_transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67d90518-6b07-4d34-9b10-13a9a97c7c26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[ WARN] [1742776370.217938829, 717.669000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame target_frame (parent world) at time 717.665000 according to authority unknown_publisher\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "t = Ts.__len__()\n",
    "# t = 2\n",
    "# 创建T矩阵（示例：绕Z轴旋转45度并平移）\n",
    "T = np.eye(4)\n",
    "theta = 0\n",
    "T[:3, :3] = np.array([\n",
    "    [np.cos(theta), -np.sin(theta), 0],\n",
    "    [np.sin(theta), np.cos(theta), 0],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "T[:3, 3] = [0.3, 0.00, 0]\n",
    "\n",
    "aim_transforms = generate_pascal_triangle_transforms(t, T)\n",
    "visualize_pascal_triangle(aim_transforms, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed7bf932-3c72-44a4-90b3-559ba899174c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[ WARN] [1742776370.219714799, 717.671000000]: TF_REPEATED_DATA ignoring data with redundant timestamp for frame target_frame (parent world) at time 717.665000 according to authority /my_gripper_node_71928_1742776328347\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 1.      ,  0.      ,  0.      ,  0.3     ],\n",
       "        [ 0.      ,  1.      ,  0.      , -0.084375],\n",
       "        [ 0.      ,  0.      ,  1.      ,  0.      ],\n",
       "        [ 0.      ,  0.      ,  0.      ,  1.      ]]),\n",
       " array([[ 1.      ,  0.      ,  0.      ,  0.3     ],\n",
       "        [ 0.      ,  1.      ,  0.      , -0.028125],\n",
       "        [ 0.      ,  0.      ,  1.      ,  0.      ],\n",
       "        [ 0.      ,  0.      ,  0.      ,  1.      ]]),\n",
       " array([[1.      , 0.      , 0.      , 0.3     ],\n",
       "        [0.      , 1.      , 0.      , 0.028125],\n",
       "        [0.      , 0.      , 1.      , 0.      ],\n",
       "        [0.      , 0.      , 0.      , 1.      ]]),\n",
       " array([[1.      , 0.      , 0.      , 0.3     ],\n",
       "        [0.      , 1.      , 0.      , 0.084375],\n",
       "        [0.      , 0.      , 1.      , 0.      ],\n",
       "        [0.      , 0.      , 0.      , 1.      ]]),\n",
       " array([[ 1.     ,  0.     ,  0.     ,  0.3    ],\n",
       "        [ 0.     ,  1.     ,  0.     , -0.05625],\n",
       "        [ 0.     ,  0.     ,  1.     ,  0.04725],\n",
       "        [ 0.     ,  0.     ,  0.     ,  1.     ]]),\n",
       " array([[1.     , 0.     , 0.     , 0.3    ],\n",
       "        [0.     , 1.     , 0.     , 0.     ],\n",
       "        [0.     , 0.     , 1.     , 0.04725],\n",
       "        [0.     , 0.     , 0.     , 1.     ]]),\n",
       " array([[1.     , 0.     , 0.     , 0.3    ],\n",
       "        [0.     , 1.     , 0.     , 0.05625],\n",
       "        [0.     , 0.     , 1.     , 0.04725],\n",
       "        [0.     , 0.     , 0.     , 1.     ]]),\n",
       " array([[ 1.      ,  0.      ,  0.      ,  0.3     ],\n",
       "        [ 0.      ,  1.      ,  0.      , -0.028125],\n",
       "        [ 0.      ,  0.      ,  1.      ,  0.0945  ],\n",
       "        [ 0.      ,  0.      ,  0.      ,  1.      ]]),\n",
       " array([[1.      , 0.      , 0.      , 0.3     ],\n",
       "        [0.      , 1.      , 0.      , 0.028125],\n",
       "        [0.      , 0.      , 1.      , 0.0945  ],\n",
       "        [0.      , 0.      , 0.      , 1.      ]]),\n",
       " array([[1.     , 0.     , 0.     , 0.3    ],\n",
       "        [0.     , 1.     , 0.     , 0.     ],\n",
       "        [0.     , 0.     , 1.     , 0.14175],\n",
       "        [0.     , 0.     , 0.     , 1.     ]])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aim_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcf7d104-3c62-454c-8cdc-25427abc1061",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 4.38259844e-02, -9.99037767e-01, -1.67999712e-03,\n",
       "          5.97930303e-01],\n",
       "        [-9.98841455e-01, -4.38507035e-02,  1.98208077e-02,\n",
       "          3.69790012e-01],\n",
       "        [-1.98754045e-02,  8.09384358e-04, -9.99802137e-01,\n",
       "          2.22112274e-02],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          1.00000000e+00]]),\n",
       " array([[ 0.03674522, -0.99932316,  0.00173772,  0.59801578],\n",
       "        [-0.99908252, -0.03669799,  0.02207643,  0.1298582 ],\n",
       "        [-0.02199771, -0.00254732, -0.99975478,  0.02223913],\n",
       "        [ 0.        ,  0.        ,  0.        ,  1.        ]]),\n",
       " array([[-0.04285631, -0.99891833,  0.01804187,  0.59952656],\n",
       "        [-0.99907866,  0.0428903 ,  0.0015007 ,  0.20850403],\n",
       "        [-0.0022729 , -0.01796093, -0.99983611,  0.02229985],\n",
       "        [ 0.        ,  0.        ,  0.        ,  1.        ]]),\n",
       " array([[-0.03025034, -0.99943026,  0.01496937,  0.59946423],\n",
       "        [-0.99953686,  0.03029646,  0.00286342,  0.28832629],\n",
       "        [-0.00331531, -0.01487582, -0.99988385,  0.02227341],\n",
       "        [ 0.        ,  0.        ,  0.        ,  1.        ]]),\n",
       " array([[ 0.04147818, -0.99913766, -0.001871  ,  0.59790764],\n",
       "        [-0.99907257, -0.04149699,  0.01148939,  0.04982466],\n",
       "        [-0.01155712,  0.0013927 , -0.99993224,  0.02226342],\n",
       "        [ 0.        ,  0.        ,  0.        ,  1.        ]]),\n",
       " array([[-4.80781106e-02,  9.98841966e-01,  1.79509681e-03,\n",
       "          5.99326677e-01],\n",
       "        [ 9.98843579e-01,  4.80780254e-02,  9.06282931e-05,\n",
       "         -2.68577816e-01],\n",
       "        [ 4.21863254e-06,  1.79737816e-03, -9.99998385e-01,\n",
       "          2.23413932e-02],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          1.00000000e+00]]),\n",
       " array([[-4.13912212e-02,  9.99141734e-01, -1.60097669e-03,\n",
       "          5.99507071e-01],\n",
       "        [ 9.99142646e-01,  4.13897730e-02, -9.27374946e-04,\n",
       "         -3.48351417e-01],\n",
       "        [-8.60314950e-04, -1.63798927e-03, -9.99998288e-01,\n",
       "          2.23075017e-02],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          1.00000000e+00]]),\n",
       " array([[-0.03778534, -0.99925756, -0.0075229 ,  0.59782996],\n",
       "        [-0.99917169,  0.03789376, -0.014832  , -0.18992582],\n",
       "        [ 0.01510606,  0.00695624, -0.9998617 ,  0.02230128],\n",
       "        [ 0.        ,  0.        ,  0.        ,  1.        ]]),\n",
       " array([[ 0.00245458, -0.99992054,  0.01236506,  0.59935563],\n",
       "        [-0.99999611, -0.00247073, -0.00129102, -0.10969593],\n",
       "        [ 0.00132147, -0.01236184, -0.99992272,  0.02242817],\n",
       "        [ 0.        ,  0.        ,  0.        ,  1.        ]]),\n",
       " array([[ 1.64893485e-03, -9.99893833e-01,  1.44777025e-02,\n",
       "          5.99376774e-01],\n",
       "        [-9.99998575e-01, -1.64350960e-03,  3.86621085e-04,\n",
       "         -3.00879562e-02],\n",
       "        [-3.62785796e-04, -1.44783194e-02, -9.99895118e-01,\n",
       "          2.24589012e-02],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          1.00000000e+00]])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8276ec04-7fa0-42e1-ae1c-32d03f30fbd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [1742776370.244206, 717.691000]: Table added to the scene to prevent collision below z = 0.001\n",
      "[INFO] [1742776370.245345, 717.692000]: Target position set to: [0.5979303030658479, 0.36979001166844633, 0.12221122735515641] and RPY: [3.1407831092297234, 0.019876713333704332, -1.5269476334677399]\n",
      "[INFO] [1742776372.740891, 720.176000]: Table 'constraint_table' removed from the planning scene.\n",
      "[INFO] [1742776372.743284, 720.179000]: Table 'constraint_table' removed from the planning scene.\n",
      "[INFO] [1742776372.743932, 720.181000]: Move successful to position: [0.5979303030658479, 0.36979001166844633, 0.12221122735515641] and RPY: [3.1407831092297234, 0.019876713333704332, -1.5269476334677399]\n",
      "Successfully moved to approach position for cube #1\n",
      "[INFO] [1742776372.745722, 720.181000]: Table added to the scene to prevent collision below z = 0.001\n",
      "[INFO] [1742776372.746302, 720.182000]: Target position set to: [0.5980157750702272, 0.12985820163686562, 0.1222391338536466] and RPY: [-3.1390447095189127, 0.021999488251177812, -1.534033930286436]\n",
      "[INFO] [1742776373.808622, 721.237000]: Table 'constraint_table' removed from the planning scene.\n",
      "[INFO] [1742776373.810701, 721.239000]: Table 'constraint_table' removed from the planning scene.\n",
      "[INFO] [1742776373.811249, 721.241000]: Move successful to position: [0.5980157750702272, 0.12985820163686562, 0.1222391338536466] and RPY: [-3.1390447095189127, 0.021999488251177812, -1.534033930286436]\n",
      "Successfully moved to approach position for cube #2\n",
      "[INFO] [1742776373.813290, 721.242000]: Table added to the scene to prevent collision below z = 0.001\n",
      "[INFO] [1742776373.814057, 721.244000]: Target position set to: [0.5995265616507968, 0.20850403034644716, 0.12229985352413258] and RPY: [-3.1236307076739243, 0.002272898630468534, -1.613665880456978]\n",
      "[INFO] [1742776374.417883, 721.844000]: Table 'constraint_table' removed from the planning scene.\n",
      "[INFO] [1742776374.420225, 721.846000]: Table 'constraint_table' removed from the planning scene.\n",
      "[INFO] [1742776374.420842, 721.848000]: Move successful to position: [0.5995265616507968, 0.20850403034644716, 0.12229985352413258] and RPY: [-3.1236307076739243, 0.002272898630468534, -1.613665880456978]\n",
      "Successfully moved to approach position for cube #3\n",
      "[INFO] [1742776374.422818, 721.849000]: Table added to the scene to prevent collision below z = 0.001\n",
      "[INFO] [1742776374.423480, 721.849000]: Target position set to: [0.5994642308382462, 0.2883262941633688, 0.12227341332262778] and RPY: [-3.126716207716669, 0.003315314053736085, -1.6010514500011193]\n",
      "[INFO] [1742776374.981148, 722.404000]: Table 'constraint_table' removed from the planning scene.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError processing cube #\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Use the modified function\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[43mdemonstrate_movement_to_cubes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpick_place\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 16\u001b[0m, in \u001b[0;36mdemonstrate_movement_to_cubes\u001b[0;34m(Ts, pick_place, offset)\u001b[0m\n\u001b[1;32m     13\u001b[0m pick_pos_approach \u001b[38;5;241m=\u001b[39m [a \u001b[38;5;241m+\u001b[39m b \u001b[38;5;28;01mfor\u001b[39;00m a, b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(pick_pos, offset)]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 16\u001b[0m     \u001b[43mpick_place\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpick_pos_approach\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpick_rpy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccessfully moved to approach position for cube #\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/ros_ws/src/franka_zed_gazebo/scripts/mycode_clean/3_move/PickAndPlace.py:101\u001b[0m, in \u001b[0;36mPickAndPlace.move\u001b[0;34m(self, position, rpy)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmove\u001b[39m(\u001b[38;5;28mself\u001b[39m, position, rpy):\n\u001b[1;32m    100\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Move the robot based on target position and orientation\"\"\"\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrobot_mover\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrpy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/ros_ws/src/franka_zed_gazebo/scripts/mycode_clean/3_move/mymove.py:232\u001b[0m, in \u001b[0;36mMoveRobot.move\u001b[0;34m(self, position, rpy, add_privant_table, retry_init)\u001b[0m\n\u001b[1;32m    229\u001b[0m     rnt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# Execute the planned path\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove_group\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m success:\n\u001b[1;32m    235\u001b[0m     rospy\u001b[38;5;241m.\u001b[39mlogerr(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMove execution failed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/ros/noetic/lib/python3/dist-packages/moveit_commander/move_group.py:615\u001b[0m, in \u001b[0;36mMoveGroupCommander.go\u001b[0;34m(self, joints, wait)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_joint_value_target(joints)\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m--> 615\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_g\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_g\u001b[38;5;241m.\u001b[39masync_move()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# demostrate the movement to the head of identified cubes\n",
    "# for T in Ts:\n",
    "#     pick_rpy, pick_pos = matrix_to_rpy_and_translation(T)\n",
    "#     pick_pos_ = [a + b for a, b in zip(pick_pos, [0.04, 0.00, 0.10])]\n",
    "#     pick_rpy = [a + b for a, b in zip(pick_rpy, [0, 0, 0])]\n",
    "#     print(pick_rpy, pick_pos)\n",
    "#     pick_place.move(pick_pos_, pick_rpy)\n",
    "# Modified movement demonstration code\n",
    "def demonstrate_movement_to_cubes(Ts, pick_place, offset=[0.00, 0.00, 0.10]):\n",
    "    for i, T in enumerate(Ts):\n",
    "        try:\n",
    "            pick_rpy, pick_pos = matrix_to_rpy_and_translation(T)\n",
    "            pick_pos_approach = [a + b for a, b in zip(pick_pos, offset)]\n",
    "            \n",
    "            try:\n",
    "                pick_place.move(pick_pos_approach, pick_rpy)\n",
    "                print(f\"Successfully moved to approach position for cube #{i+1}\")\n",
    "            except ValueError as e:\n",
    "                if \"too many values to unpack\" in str(e):\n",
    "                    print(f\"Note: Handled unpacking error in move operation for cube #{i+1}\")\n",
    "                else:\n",
    "                    raise\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing cube #{i+1}: {e}\")\n",
    "\n",
    "# Use the modified function\n",
    "demonstrate_movement_to_cubes(Ts, pick_place)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1ff911-c41c-4330-be82-95130ec626fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [1742775882.787234, 233.940000]: Table added to the scene to prevent collision below z = 0.001\n",
      "[INFO] [1742775882.788606, 233.942000]: Target position set to: [0.3, -0.08437499999999999, 0.13] and RPY: [3.141592653589793, 0.0, -1.5707963267948966]\n",
      "[INFO] [1742775884.055832, 235.200000]: Table 'constraint_table' removed from the planning scene.\n",
      "[INFO] [1742775884.058332, 235.208000]: Table 'constraint_table' removed from the planning scene.\n",
      "[INFO] [1742775884.058954, 235.210000]: Move successful to position: [0.3, -0.08437499999999999, 0.13] and RPY: [3.141592653589793, 0.0, -1.5707963267948966]\n",
      "[INFO] [1742775884.060978, 235.211000]: Table added to the scene to prevent collision below z = 0.001\n",
      "[INFO] [1742775884.061651, 235.213000]: Target position set to: [0.3, -0.028124999999999997, 0.13] and RPY: [3.141592653589793, 0.0, -1.5707963267948966]\n",
      "[INFO] [1742775884.623352, 235.770000]: Table 'constraint_table' removed from the planning scene.\n",
      "[INFO] [1742775884.626009, 235.772000]: Table 'constraint_table' removed from the planning scene.\n",
      "[INFO] [1742775884.627075, 235.773000]: Move successful to position: [0.3, -0.028124999999999997, 0.13] and RPY: [3.141592653589793, 0.0, -1.5707963267948966]\n",
      "[INFO] [1742775884.629103, 235.773000]: Table added to the scene to prevent collision below z = 0.001\n",
      "[INFO] [1742775884.629658, 235.773000]: Target position set to: [0.3, 0.028124999999999997, 0.13] and RPY: [3.141592653589793, 0.0, -1.5707963267948966]\n",
      "[INFO] [1742775885.173802, 236.316000]: Table 'constraint_table' removed from the planning scene.\n",
      "[INFO] [1742775885.176710, 236.320000]: Table 'constraint_table' removed from the planning scene.\n",
      "[INFO] [1742775885.177741, 236.323000]: Move successful to position: [0.3, 0.028124999999999997, 0.13] and RPY: [3.141592653589793, 0.0, -1.5707963267948966]\n",
      "[INFO] [1742775885.179895, 236.324000]: Table added to the scene to prevent collision below z = 0.001\n",
      "[INFO] [1742775885.180714, 236.326000]: Target position set to: [0.3, 0.08437499999999999, 0.13] and RPY: [3.141592653589793, 0.0, -1.5707963267948966]\n",
      "[INFO] [1742775885.669928, 236.810000]: Table 'constraint_table' removed from the planning scene.\n",
      "[INFO] [1742775885.672706, 236.813000]: Table 'constraint_table' removed from the planning scene.\n",
      "[INFO] [1742775885.673755, 236.816000]: Move successful to position: [0.3, 0.08437499999999999, 0.13] and RPY: [3.141592653589793, 0.0, -1.5707963267948966]\n",
      "[INFO] [1742775885.676298, 236.817000]: Table added to the scene to prevent collision below z = 0.001\n",
      "[INFO] [1742775885.677036, 236.819000]: Target position set to: [0.3, -0.056249999999999994, 0.17725000000000002] and RPY: [3.141592653589793, 0.0, -1.5707963267948966]\n",
      "[INFO] [1742775886.563699, 237.701000]: Table 'constraint_table' removed from the planning scene.\n",
      "[INFO] [1742775886.566457, 237.704000]: Table 'constraint_table' removed from the planning scene.\n",
      "[INFO] [1742775886.567174, 237.706000]: Move successful to position: [0.3, -0.056249999999999994, 0.17725000000000002] and RPY: [3.141592653589793, 0.0, -1.5707963267948966]\n",
      "[INFO] [1742775886.569172, 237.707000]: Table added to the scene to prevent collision below z = 0.001\n",
      "[INFO] [1742775886.569708, 237.707000]: Target position set to: [0.3, 0.0, 0.17725000000000002] and RPY: [3.141592653589793, 0.0, -1.5707963267948966]\n",
      "[INFO] [1742775887.137348, 238.268000]: Table 'constraint_table' removed from the planning scene.\n",
      "[INFO] [1742775887.139779, 238.274000]: Table 'constraint_table' removed from the planning scene.\n",
      "[INFO] [1742775887.140368, 238.276000]: Move successful to position: [0.3, 0.0, 0.17725000000000002] and RPY: [3.141592653589793, 0.0, -1.5707963267948966]\n",
      "[INFO] [1742775887.142311, 238.277000]: Table added to the scene to prevent collision below z = 0.001\n",
      "[INFO] [1742775887.142890, 238.279000]: Target position set to: [0.3, 0.056249999999999994, 0.17725000000000002] and RPY: [3.141592653589793, 0.0, -1.5707963267948966]\n",
      "[INFO] [1742775887.635925, 238.767000]: Table 'constraint_table' removed from the planning scene.\n",
      "[INFO] [1742775887.638179, 238.770000]: Table 'constraint_table' removed from the planning scene.\n",
      "[INFO] [1742775887.638813, 238.772000]: Move successful to position: [0.3, 0.056249999999999994, 0.17725000000000002] and RPY: [3.141592653589793, 0.0, -1.5707963267948966]\n",
      "[INFO] [1742775887.640828, 238.772000]: Table added to the scene to prevent collision below z = 0.001\n",
      "[INFO] [1742775887.641433, 238.774000]: Target position set to: [0.3, -0.028124999999999997, 0.2245] and RPY: [3.141592653589793, 0.0, -1.5707963267948966]\n",
      "[INFO] [1742775888.448758, 239.577000]: Table 'constraint_table' removed from the planning scene.\n",
      "[INFO] [1742775888.451114, 239.579000]: Table 'constraint_table' removed from the planning scene.\n",
      "[INFO] [1742775888.451857, 239.580000]: Move successful to position: [0.3, -0.028124999999999997, 0.2245] and RPY: [3.141592653589793, 0.0, -1.5707963267948966]\n",
      "[INFO] [1742775888.454014, 239.580000]: Table added to the scene to prevent collision below z = 0.001\n",
      "[INFO] [1742775888.455060, 239.580000]: Target position set to: [0.3, 0.028124999999999997, 0.2245] and RPY: [3.141592653589793, 0.0, -1.5707963267948966]\n",
      "[INFO] [1742775888.950130, 240.077000]: Table 'constraint_table' removed from the planning scene.\n",
      "[INFO] [1742775888.952478, 240.079000]: Table 'constraint_table' removed from the planning scene.\n",
      "[INFO] [1742775888.953110, 240.081000]: Move successful to position: [0.3, 0.028124999999999997, 0.2245] and RPY: [3.141592653589793, 0.0, -1.5707963267948966]\n",
      "[INFO] [1742775888.955098, 240.082000]: Table added to the scene to prevent collision below z = 0.001\n",
      "[INFO] [1742775888.955745, 240.084000]: Target position set to: [0.3, 0.0, 0.27175] and RPY: [3.141592653589793, 0.0, -1.5707963267948966]\n",
      "[INFO] [1742775889.614024, 240.737000]: Table 'constraint_table' removed from the planning scene.\n",
      "[INFO] [1742775889.617078, 240.740000]: Table 'constraint_table' removed from the planning scene.\n",
      "[INFO] [1742775889.618085, 240.743000]: Move successful to position: [0.3, 0.0, 0.27175] and RPY: [3.141592653589793, 0.0, -1.5707963267948966]\n"
     ]
    }
   ],
   "source": [
    "# move the minipulator to the aim position\n",
    "for T in aim_transforms:\n",
    "    transform_matrix_x_180 = np.array([\n",
    "        [1, 0, 0, 0],\n",
    "        [0, -1, 0, 0],\n",
    "        [0, 0, -1, 0],\n",
    "        [0, 0, 0, 1]\n",
    "    ])\n",
    "    transform_matrix_z_90 = np.array([\n",
    "        [0, -1, 0, 0],\n",
    "        [1, 0, 0, 0],\n",
    "        [0, 0, 1, 0],\n",
    "        [0, 0, 0, 1]\n",
    "    ])\n",
    "    pick_rpy, pick_pos = matrix_to_rpy_and_translation(T@transform_matrix_x_180@transform_matrix_z_90)\n",
    "    pick_pos_ = [a + b for a, b in zip(pick_pos, [0.0, 0, 0.13])]\n",
    "    pick_rpy = [a + b for a, b in zip(pick_rpy, [0, 0, 0])]\n",
    "    pick_place.move(pick_pos_, pick_rpy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da6b4027-9a96-484e-b6b0-c423c42cd075",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # pick and place the first cube \n",
    "# transform_matrix_x_180 = np.array([\n",
    "#     [1, 0, 0, 0],\n",
    "#     [0, -1, 0, 0],\n",
    "#     [0, 0, -1, 0],\n",
    "#     [0, 0, 0, 1]\n",
    "# ])\n",
    "# transform_matrix_z_90 = np.array([\n",
    "#     [0, -1, 0, 0],\n",
    "#     [1, 0, 0, 0],\n",
    "#     [0, 0, 1, 0],\n",
    "#     [0, 0, 0, 1]\n",
    "# ])\n",
    "\n",
    "# pick_rpy, pick_pos = matrix_to_rpy_and_translation(Ts[0])\n",
    "# pick_pos_ = [a + b for a, b in zip(pick_pos, [0.00, 0, 0.00])]\n",
    "# pick_rpy = [a + b for a, b in zip(pick_rpy, [0, 0, 0])]\n",
    "    \n",
    "# place_rpy, place_pos = matrix_to_rpy_and_translation(aim_transforms[0]@transform_matrix_x_180@transform_matrix_z_90)\n",
    "# place_pos_ = [a + b for a, b in zip(place_pos, [0.0, 0, 0.04])]\n",
    "\n",
    "# pick_place.pick_and_place(\n",
    "#     pick_pos=pick_pos_,\n",
    "#     pick_rpy=pick_rpy,\n",
    "#     place_pos=place_pos_,\n",
    "#     place_rpy=place_rpy\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a662392-36bb-46d1-a2b3-ac8562db28ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transform_matrix_x_180' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m pick_pos_ \u001b[38;5;241m=\u001b[39m [a \u001b[38;5;241m+\u001b[39m b \u001b[38;5;28;01mfor\u001b[39;00m a, b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(pick_pos, [\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0.008\u001b[39m])]\n\u001b[1;32m     18\u001b[0m pick_rpy \u001b[38;5;241m=\u001b[39m [a \u001b[38;5;241m+\u001b[39m b \u001b[38;5;28;01mfor\u001b[39;00m a, b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(pick_rpy, [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m])]\n\u001b[0;32m---> 20\u001b[0m place_rpy, place_pos \u001b[38;5;241m=\u001b[39m matrix_to_rpy_and_translation(aim_transforms[i]\u001b[38;5;129m@transform_matrix_x_180\u001b[39m\u001b[38;5;129m@transform_matrix_z_90\u001b[39m)\n\u001b[1;32m     21\u001b[0m place_pos_ \u001b[38;5;241m=\u001b[39m [a \u001b[38;5;241m+\u001b[39m b \u001b[38;5;28;01mfor\u001b[39;00m a, b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(place_pos, [\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0.02\u001b[39m])]\n\u001b[1;32m     23\u001b[0m pick_place\u001b[38;5;241m.\u001b[39mpick_and_place(\n\u001b[1;32m     24\u001b[0m     pick_pos\u001b[38;5;241m=\u001b[39mpick_pos_,\n\u001b[1;32m     25\u001b[0m     pick_rpy\u001b[38;5;241m=\u001b[39mpick_rpy,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     extra_pick_patch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     29\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transform_matrix_x_180' is not defined"
     ]
    }
   ],
   "source": [
    "# pick and place following cubes \n",
    "for i in range(0, Ts.__len__()):\n",
    "    transform_matrix_x_180 = np.array([\n",
    "    [1, 0, 0, 0],\n",
    "    [0, -1, 0, 0],\n",
    "    [0, 0, -1, 0],\n",
    "    [0, 0, 0, 1]\n",
    "    ])\n",
    "    transform_matrix_z_90 = np.array([\n",
    "        [0, -1, 0, 0],\n",
    "        [1, 0, 0, 0],\n",
    "        [0, 0, 1, 0],\n",
    "        [0, 0, 0, 1]\n",
    "    ])\n",
    "\n",
    "    pick_rpy, pick_pos = matrix_to_rpy_and_translation(Ts[i])\n",
    "    pick_pos_ = [a + b for a, b in zip(pick_pos, [0.0, 0, 0.008])]\n",
    "    pick_rpy = [a + b for a, b in zip(pick_rpy, [0, 0, 0])]\n",
    "\n",
    "    place_rpy, place_pos = matrix_to_rpy_and_translation(aim_transforms[i]@transform_matrix_x_180@transform_matrix_z_90)\n",
    "    place_pos_ = [a + b for a, b in zip(place_pos, [0.0, 0, 0.02])]\n",
    "\n",
    "    pick_place.pick_and_place(\n",
    "        pick_pos=pick_pos_,\n",
    "        pick_rpy=pick_rpy,\n",
    "        place_pos=place_pos_,\n",
    "        place_rpy=place_rpy,\n",
    "        extra_pick_patch = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae12895-f189-48d9-98a8-7f5b4ce8f8dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28a61a9-5a2d-46d9-85f8-6e0d2d2e66e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb28b7de-2a7b-447b-b92c-f9487c4a8977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344eea87-4f39-40cd-adcb-2d3490950865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b49a45-b76a-4109-a1b9-92473eb0cc5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90752b1-45fd-40c6-95e6-5c641111580b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e628f0-7d4c-4612-8453-cc769bb96ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0b93ec-fc14-4c5b-a51b-ddd187495ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cf24a9-2107-4c18-8b75-410152602d54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97c4cfa-2497-47fb-abcc-b4d8102d5a27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97a75a1-7a1b-4df9-87e5-f22fc098e059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916923c9-2c36-417b-bb2a-7a07e665e320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1aa9b1-890b-4a21-a656-5c54a75d5c01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8e1942-89b9-460e-8013-c3406e5ec660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f97b18-cf6e-4683-b2b0-b18f61f0c335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84bdaf3-eb89-4acf-aa35-34d10d9ff810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72f5be6-10ab-4a45-9860-f3cdf9737da3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc74575-a184-436e-b10f-6e5cbd701094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
